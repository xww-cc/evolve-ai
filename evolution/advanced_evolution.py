import asyncio
import time
import torch
import numpy as np
import random
from typing import List, Dict, Tuple, Any, Optional
from models.advanced_reasoning_net import AdvancedReasoningNet
from evaluators.enhanced_evaluator import EnhancedEvaluator
from config.optimized_logging import setup_optimized_logging
from utils.visualization import EvolutionVisualizer

logger = setup_optimized_logging()

class AdvancedEvolution:
    """é«˜çº§è¿›åŒ–ç®—æ³• - æ”¯æŒå¼‚æ„ç»“æ„å’Œå¯è§†åŒ–"""
    
    def __init__(self, population_size: int = 8, mutation_rate: float = 0.1, 
                 crossover_rate: float = 0.8, elite_size: int = 2):
        self.population_size = population_size
        self.mutation_rate = mutation_rate
        self.crossover_rate = crossover_rate
        self.elite_size = elite_size
        self.diversity_threshold = 0.1  # æ·»åŠ å¤šæ ·æ€§é˜ˆå€¼
        self.evolution_history = []
        self.visualizer = EvolutionVisualizer()
        
        # è‡ªé€‚åº”å‚æ•°
        self.adaptive_mutation_rate = mutation_rate
        self.adaptive_crossover_rate = crossover_rate
        
    async def evolve_population(self, population: List[AdvancedReasoningNet], 
                              fitness_scores: List[float]) -> List[AdvancedReasoningNet]:
        """è¿›åŒ–ç§ç¾¤ - å¼‚æ­¥ç‰ˆæœ¬"""
        # é€‰æ‹©
        selected = self._multi_objective_selection(population, fitness_scores)
        
        # äº¤å‰
        offspring = await self._advanced_crossover(selected)
        
        # å˜å¼‚
        offspring = self._intelligent_mutation(offspring)
        
        # ç²¾è‹±ä¿ç•™
        new_population = self._elitism_with_diversity(population, fitness_scores, offspring)
        
        return new_population
    
    def evolve(self, population: List[AdvancedReasoningNet], 
               evaluator: EnhancedEvaluator, generations: int = 5) -> List[AdvancedReasoningNet]:
        """æ‰§è¡Œé«˜çº§è¿›åŒ– - åŒæ­¥ç‰ˆæœ¬ï¼Œé›†æˆå¯è§†åŒ–"""
        logger.log_important("ğŸ”„ å¼€å§‹é«˜çº§è¿›åŒ–è¿‡ç¨‹...")
        
        for generation in range(generations):
            # è®¡ç®—é€‚åº”åº¦
            fitness_scores = []
            for individual in population:
                fitness = self._calculate_fitness(individual, evaluator)
                fitness_scores.append(fitness)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            best_fitness = max(fitness_scores)
            avg_fitness = np.mean(fitness_scores)
            diversity = self._calculate_diversity(population)
            
            # è®°å½•å¯è§†åŒ–æ•°æ®
            self.visualizer.record_generation(
                generation=generation + 1,
                population=population,
                fitness_scores=fitness_scores,
                diversity=diversity,
                best_fitness=best_fitness,
                avg_fitness=avg_fitness
            )
            
            # è‡ªé€‚åº”å‚æ•°è°ƒæ•´
            self._adaptive_parameter_adjustment(diversity, fitness_scores)
            
            # å¤šç›®æ ‡é€‰æ‹©
            selected_parents = self._multi_objective_selection(population, fitness_scores)
            
            # ç”Ÿæˆåä»£
            offspring = []
            for i in range(0, len(selected_parents), 2):
                if i + 1 < len(selected_parents):
                    parent1, parent2 = selected_parents[i], selected_parents[i + 1]
                    child1, child2 = self._advanced_parameter_crossover(parent1, parent2)
                    offspring.extend([child1, child2])
            
            logger.log_important(f"ğŸ”” é«˜çº§äº¤å‰å®Œæˆï¼Œç”Ÿæˆäº† {len(offspring)} ä¸ªåä»£")
            
            # æ™ºèƒ½å˜å¼‚
            mutated_count = 0
            for i, individual in enumerate(offspring):
                if random.random() < self.adaptive_mutation_rate:
                    offspring[i] = self._intelligent_parameter_mutation(individual)
                    mutated_count += 1
            
            logger.log_important(f"ğŸ”” æ™ºèƒ½å˜å¼‚å®Œæˆï¼Œå˜å¼‚äº† {mutated_count} ä¸ªä¸ªä½“")
            
            # ç²¾è‹±ä¿ç•™ä¸å¤šæ ·æ€§ç»´æŠ¤
            elite_indices = np.argsort(fitness_scores)[-self.elite_size:]
            elite_individuals = [population[i] for i in elite_indices]
            
            # åˆå¹¶ç²¾è‹±å’Œåä»£
            new_population = elite_individuals + offspring[:self.population_size - self.elite_size]
            
            # ç¡®ä¿ç§ç¾¤å¤§å°
            while len(new_population) < self.population_size:
                new_population.append(random.choice(offspring))
            
            population = new_population[:self.population_size]
            
            logger.log_important(f"ğŸ”” ç²¾è‹±ä¿ç•™ä¸å¤šæ ·æ€§ç»´æŠ¤å®Œæˆï¼Œä¿ç•™äº† {len(elite_individuals)} ä¸ªç²¾è‹±ä¸ªä½“")
            
            # è®°å½•è¿›åŒ–å†å²
            self.evolution_history.append({
                'generation': generation + 1,
                'best_fitness': best_fitness,
                'avg_fitness': avg_fitness,
                'diversity': diversity
            })
            
            logger.log_important(f"ğŸ”” é«˜çº§è¿›åŒ–å†å²è®°å½•: ç¬¬{generation + 1}ä»£, æœ€ä½³é€‚åº”åº¦: {best_fitness:.3f}, å¹³å‡é€‚åº”åº¦: {avg_fitness:.3f}, å¤šæ ·æ€§: {diversity:.3f}")
        
        # ç”Ÿæˆå¯è§†åŒ–
        self._generate_visualizations()
        
        return population
    
    def _generate_visualizations(self):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        try:
            # ç»˜åˆ¶è¿›åŒ–æ›²çº¿
            curves_file = self.visualizer.plot_evolution_curves()
            logger.log_important(f"ğŸ“Š è¿›åŒ–æ›²çº¿å·²ä¿å­˜: {curves_file}")
            
            # ç»˜åˆ¶å¤šæ ·æ€§çƒ­åŠ›å›¾
            heatmap_file = self.visualizer.plot_diversity_heatmap()
            logger.log_important(f"ğŸ“Š å¤šæ ·æ€§çƒ­åŠ›å›¾å·²ä¿å­˜: {heatmap_file}")
            
            # ç”Ÿæˆè¿›åŒ–æŠ¥å‘Š
            report_file = self.visualizer.generate_evolution_report()
            logger.log_important(f"ğŸ“Š è¿›åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
            # ä¿å­˜å¯è§†åŒ–æ•°æ®
            data_file = self.visualizer.save_visualization_data()
            logger.log_important(f"ğŸ“Š å¯è§†åŒ–æ•°æ®å·²ä¿å­˜: {data_file}")
            
        except Exception as e:
            logger.log_warning(f"å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
    
    def _calculate_fitness(self, model: AdvancedReasoningNet, evaluator: EnhancedEvaluator) -> float:
        """è®¡ç®—é€‚åº”åº¦åˆ†æ•°"""
        try:
            # å¼‚æ­¥è¯„ä¼°
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # å¦‚æœå·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œç›´æ¥è°ƒç”¨
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, evaluator.evaluate_enhanced_reasoning(model, max_tasks=5))
                    results = future.result()
            else:
                results = loop.run_until_complete(evaluator.evaluate_enhanced_reasoning(model, max_tasks=5))
            
            # ä½¿ç”¨ç»¼åˆæ¨ç†åˆ†æ•°ä½œä¸ºé€‚åº”åº¦
            fitness = results.get('comprehensive_reasoning', 0.0)
            return fitness
            
        except Exception as e:
            logger.log_warning(f"é€‚åº”åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def _calculate_diversity(self, population: List[AdvancedReasoningNet]) -> float:
        """ç»“æ„+å‚æ•°+è¡Œä¸ºå¤šæ ·æ€§åŠ æƒ"""
        try:
            # ç»“æ„å¤šæ ·æ€§
            def structure_vec(model):
                return np.array([
                    model.hidden_size,
                    model.reasoning_layers,
                    model.attention_heads,
                    model.memory_size,
                    model.reasoning_types
                ], dtype=np.float32)
            
            structure_distances = []
            for i in range(len(population)):
                for j in range(i+1, len(population)):
                    s1, s2 = structure_vec(population[i]), structure_vec(population[j])
                    structure_distances.append(np.linalg.norm(s1-s2))
            structure_div = np.mean(structure_distances) if structure_distances else 0.0
            
            # å‚æ•°å¤šæ ·æ€§
            feature_vectors = []
            for model in population:
                params = list(model.parameters())
                param_features = []
                for param in params:
                    param_features.extend([
                        param.mean().item(),
                        param.std().item(),
                        param.max().item(),
                        param.min().item()
                    ])
                feature_vectors.append(param_features)
            
            param_distances = []
            for i in range(len(feature_vectors)):
                for j in range(i+1, len(feature_vectors)):
                    if len(feature_vectors[i]) == len(feature_vectors[j]):
                        param_distances.append(np.linalg.norm(np.array(feature_vectors[i])-np.array(feature_vectors[j])))
            param_div = np.mean(param_distances) if param_distances else 0.0
            
            # è¡Œä¸ºå¤šæ ·æ€§ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…ç»´åº¦ä¸åŒ¹é…ï¼‰
            behavior_outputs = []
            test_input = torch.tensor([[1, 2, 3, 4]], dtype=torch.float32)
            
            for model in population:
                try:
                    model.eval()
                    with torch.no_grad():
                        output = model(test_input)
                        # ä½¿ç”¨comprehensive_reasoningä½œä¸ºè¡Œä¸ºç‰¹å¾
                        if 'comprehensive_reasoning' in output:
                            behavior_score = output['comprehensive_reasoning'].mean().item()
                        else:
                            behavior_score = 0.0
                        behavior_outputs.append(behavior_score)
                except Exception as e:
                    # å¦‚æœæ¨¡å‹æ¨ç†å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    behavior_outputs.append(0.0)
            
            behavior_distances = []
            for i in range(len(behavior_outputs)):
                for j in range(i+1, len(behavior_outputs)):
                    behavior_distances.append(abs(behavior_outputs[i] - behavior_outputs[j]))
            behavior_div = np.mean(behavior_distances) if behavior_distances else 0.0
            
            # åŠ æƒ
            alpha, beta, gamma = 0.3, 0.4, 0.3
            diversity = alpha*structure_div + beta*param_div + gamma*behavior_div
            return diversity
            
        except Exception as e:
            logger.log_warning(f"å¤šæ ·æ€§è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def _adaptive_parameter_adjustment(self, diversity: float, fitness_scores: List[float]):
        """è‡ªé€‚åº”å‚æ•°è°ƒæ•´"""
        # æ ¹æ®å¤šæ ·æ€§è°ƒæ•´å˜å¼‚ç‡
        if diversity < self.diversity_threshold:
            self.adaptive_mutation_rate = min(0.3, self.adaptive_mutation_rate * 1.2)
        else:
            self.adaptive_mutation_rate = max(0.05, self.adaptive_mutation_rate * 0.95)
        
        # æ ¹æ®é€‚åº”åº¦åˆ†å¸ƒè°ƒæ•´äº¤å‰ç‡
        fitness_std = np.std(fitness_scores)
        if fitness_std < 0.1:  # é€‚åº”åº¦é›†ä¸­
            self.adaptive_crossover_rate = min(0.95, self.adaptive_crossover_rate * 1.1)
        else:
            self.adaptive_crossover_rate = max(0.7, self.adaptive_crossover_rate * 0.95)
        
        logger.log_important(f"è‡ªé€‚åº”å‚æ•°è°ƒæ•´: å˜å¼‚ç‡={self.adaptive_mutation_rate:.3f}, "
                           f"äº¤å‰ç‡={self.adaptive_crossover_rate:.3f}, å¤šæ ·æ€§={diversity:.3f}")
    
    def _multi_objective_selection(self, population: List[AdvancedReasoningNet], 
                                 fitness_scores: List[float]) -> List[AdvancedReasoningNet]:
        """å¤šç›®æ ‡é€‰æ‹©"""
        selected = []
        
        # 1. åŸºäºé€‚åº”åº¦çš„é€‰æ‹©
        fitness_selected = self._fitness_based_selection(population, fitness_scores, 
                                                       int(self.population_size * 0.6))
        
        # 2. åŸºäºå¤šæ ·æ€§çš„é€‰æ‹©
        diversity_selected = self._diversity_based_selection(population, fitness_scores,
                                                           int(self.population_size * 0.4))
        
        selected.extend(fitness_selected)
        selected.extend(diversity_selected)
        
        logger.log_important(f"å¤šç›®æ ‡é€‰æ‹©å®Œæˆ: é€‚åº”åº¦é€‰æ‹©={len(fitness_selected)}, "
                           f"å¤šæ ·æ€§é€‰æ‹©={len(diversity_selected)}")
        return selected
    
    def _fitness_based_selection(self, population: List[AdvancedReasoningNet], 
                                fitness_scores: List[float], num_select: int) -> List[AdvancedReasoningNet]:
        """åŸºäºé€‚åº”åº¦çš„é€‰æ‹©"""
        selected = []
        
        for _ in range(num_select):
            # é”¦æ ‡èµ›é€‰æ‹©
            tournament_size = min(5, len(population))
            tournament_indices = random.sample(range(len(population)), tournament_size)
            tournament_fitness = [fitness_scores[i] for i in tournament_indices]
            
            # é€‰æ‹©æœ€ä½³ä¸ªä½“
            winner_idx = tournament_indices[np.argmax(tournament_fitness)]
            selected.append(population[winner_idx])
        
        return selected
    
    def _diversity_based_selection(self, population: List[AdvancedReasoningNet], 
                                 fitness_scores: List[float], num_select: int) -> List[AdvancedReasoningNet]:
        """åŸºäºå¤šæ ·æ€§çš„é€‰æ‹©"""
        selected = []
        
        # è®¡ç®—æ¯ä¸ªä¸ªä½“çš„å¤šæ ·æ€§è´¡çŒ®
        diversity_scores = []
        for i, model in enumerate(population):
            # è®¡ç®—ä¸å…¶ä»–ä¸ªä½“çš„å¹³å‡è·ç¦»
            distances = []
            for j, other_model in enumerate(population):
                if i != j:
                    try:
                        # ä½¿ç”¨ç»“æ„å‚æ•°è®¡ç®—è·ç¦»ï¼Œé¿å…å‚æ•°ç»´åº¦ä¸åŒ¹é…
                        structure_dist = abs(model.hidden_size - other_model.hidden_size) + \
                                      abs(model.reasoning_layers - other_model.reasoning_layers) + \
                                      abs(model.attention_heads - other_model.attention_heads) + \
                                      abs(model.memory_size - other_model.memory_size) + \
                                      abs(model.reasoning_types - other_model.reasoning_types)
                        distances.append(structure_dist)
                    except Exception as e:
                        # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è·ç¦»
                        distances.append(1.0)
            
            diversity_scores.append(np.mean(distances) if distances else 0)
        
        # é€‰æ‹©å¤šæ ·æ€§æœ€é«˜çš„ä¸ªä½“
        diversity_indices = np.argsort(diversity_scores)[::-1]
        for i in range(min(num_select, len(diversity_indices))):
            selected.append(population[diversity_indices[i]])
        
        return selected
    
    async def _advanced_crossover(self, selected: List[AdvancedReasoningNet]) -> List[AdvancedReasoningNet]:
        """é«˜çº§äº¤å‰æ“ä½œ"""
        offspring = []
        
        for i in range(0, len(selected), 2):
            if i + 1 < len(selected):
                parent1 = selected[i]
                parent2 = selected[i + 1]
                
                if random.random() < self.adaptive_crossover_rate:
                    # æ‰§è¡Œé«˜çº§äº¤å‰
                    child1, child2 = self._advanced_parameter_crossover(parent1, parent2)
                    offspring.extend([child1, child2])
                else:
                    # ç›´æ¥å¤åˆ¶
                    offspring.extend([parent1, parent2])
            else:
                offspring.append(selected[i])
        
        logger.log_important(f"é«˜çº§äº¤å‰å®Œæˆï¼Œç”Ÿæˆäº† {len(offspring)} ä¸ªåä»£")
        return offspring
    
    def _advanced_parameter_crossover(self, parent1: AdvancedReasoningNet, parent2: AdvancedReasoningNet) -> Tuple[AdvancedReasoningNet, AdvancedReasoningNet]:
        """å¼‚æ„ç»“æ„ä¸‹çš„é«˜çº§å‚æ•°äº¤å‰"""
        # éšæœºé€‰æ‹©çˆ¶ä»£ç»“æ„å‚æ•°
        def pick_structure(p1, p2):
            return np.random.choice([p1, p2])
        
        # ç¡®ä¿hidden_sizeèƒ½è¢«attention_headsæ•´é™¤
        def adjust_hidden_size(hidden_size, attention_heads):
            return (hidden_size // attention_heads) * attention_heads
        
        # åˆ›å»ºå­ä»£ï¼Œä½¿ç”¨ç›¸åŒçš„ç»“æ„ä»¥é¿å…ç»´åº¦ä¸åŒ¹é…
        child1_hidden = adjust_hidden_size(
            pick_structure(parent1.hidden_size, parent2.hidden_size),
            pick_structure(parent1.attention_heads, parent2.attention_heads)
        )
        child2_hidden = adjust_hidden_size(
            pick_structure(parent1.hidden_size, parent2.hidden_size),
            pick_structure(parent1.attention_heads, parent2.attention_heads)
        )
        
        child1 = type(parent1)(
            parent1.input_size,
            child1_hidden,
            pick_structure(parent1.reasoning_layers, parent2.reasoning_layers),
            pick_structure(parent1.attention_heads, parent2.attention_heads),
            pick_structure(parent1.memory_size, parent2.memory_size),
            pick_structure(parent1.reasoning_types, parent2.reasoning_types)
        )
        child2 = type(parent1)(
            parent2.input_size,
            child2_hidden,
            pick_structure(parent1.reasoning_layers, parent2.reasoning_layers),
            pick_structure(parent1.attention_heads, parent2.attention_heads),
            pick_structure(parent1.memory_size, parent2.memory_size),
            pick_structure(parent1.reasoning_types, parent2.reasoning_types)
        )
        
        # å‚æ•°äº¤å‰ - åªå¤„ç†å½¢çŠ¶å…¼å®¹çš„å‚æ•°
        parent1_params = list(parent1.parameters())
        parent2_params = list(parent2.parameters())
        child1_params = list(child1.parameters())
        child2_params = list(child2.parameters())
        
        for i in range(min(len(child1_params), len(parent1_params), len(parent2_params))):
            param1, param2 = parent1_params[i], parent2_params[i]
            child_param1, child_param2 = child1_params[i], child2_params[i]
            
            with torch.no_grad():
                # åªå¤„ç†å½¢çŠ¶å®Œå…¨åŒ¹é…çš„å‚æ•°
                if param1.shape == param2.shape and param1.shape == child_param1.shape:
                    crossover_point = np.random.rand()
                    noise1 = torch.randn_like(param1) * 0.01
                    noise2 = torch.randn_like(param2) * 0.01
                    child_param1.copy_(crossover_point * (param1 + noise1) + (1 - crossover_point) * (param2 + noise2))
                    child_param2.copy_((1 - crossover_point) * (param1 + noise1) + crossover_point * (param2 + noise2))
                else:
                    # å½¢çŠ¶ä¸å…¼å®¹æ—¶ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–
                    # è¿™æ ·å¯ä»¥é¿å…ç»´åº¦ä¸åŒ¹é…é—®é¢˜
                    pass  # ä¿æŒé»˜è®¤åˆå§‹åŒ–
        
        return child1, child2

    def _intelligent_mutation(self, offspring: List[AdvancedReasoningNet]) -> List[AdvancedReasoningNet]:
        """æ™ºèƒ½å˜å¼‚æ“ä½œ"""
        mutated = []
        
        for individual in offspring:
            if random.random() < self.adaptive_mutation_rate:
                # æ‰§è¡Œæ™ºèƒ½å˜å¼‚
                mutated_individual = self._intelligent_parameter_mutation(individual)
                mutated.append(mutated_individual)
            else:
                mutated.append(individual)
        
        logger.log_important(f"æ™ºèƒ½å˜å¼‚å®Œæˆï¼Œå˜å¼‚äº† {len([m for m in mutated if m != offspring[mutated.index(m)]])} ä¸ªä¸ªä½“")
        return mutated
    
    def _intelligent_parameter_mutation(self, individual: AdvancedReasoningNet) -> AdvancedReasoningNet:
        """å¼‚æ„ç»“æ„ä¸‹çš„æ™ºèƒ½å‚æ•°å˜å¼‚ï¼Œå…è®¸ç»“æ„å‚æ•°å°æ¦‚ç‡å˜å¼‚"""
        # ç»“æ„å‚æ•°å°æ¦‚ç‡å˜å¼‚
        def maybe_mutate(val, choices, prob=0.05):  # é™ä½ç»“æ„å˜å¼‚æ¦‚ç‡
            return int(np.random.choice(choices)) if np.random.rand() < prob else val
        
        # ç¡®ä¿hidden_sizeèƒ½è¢«attention_headsæ•´é™¤
        def adjust_hidden_size(hidden_size, attention_heads):
            return (hidden_size // attention_heads) * attention_heads
        
        mutated_hidden = adjust_hidden_size(
            maybe_mutate(individual.hidden_size, [128, 192, 256, 320, 384, 512]),
            maybe_mutate(individual.attention_heads, [4, 8, 16])
        )
        
        mutated = type(individual)(
            individual.input_size,
            mutated_hidden,
            maybe_mutate(individual.reasoning_layers, [3, 4, 5, 6]),
            maybe_mutate(individual.attention_heads, [4, 8, 16]),
            maybe_mutate(individual.memory_size, [10, 15, 20, 25, 30]),
            maybe_mutate(individual.reasoning_types, [8, 10, 12, 15])
        )
        
        individual_params = list(individual.parameters())
        mutated_params = list(mutated.parameters())
        
        for i in range(min(len(individual_params), len(mutated_params))):
            param, mutated_param = individual_params[i], mutated_params[i]
            
            with torch.no_grad():
                # åªå¤„ç†å½¢çŠ¶åŒ¹é…çš„å‚æ•°
                if param.shape == mutated_param.shape:
                    mutation_strength = 0.01 * (1 + np.random.rand()) * (1 + param.std().item())
                    noise = torch.randn_like(param) * mutation_strength
                    mutated_param.copy_(param + noise)
                else:
                    # å½¢çŠ¶ä¸å…¼å®¹æ—¶ï¼Œä¿æŒé»˜è®¤åˆå§‹åŒ–
                    pass  # é¿å…å¤æ‚çš„æˆªæ–­å’Œå¡«å……æ“ä½œ
        
        return mutated
    
    def _elitism_with_diversity(self, population: List[AdvancedReasoningNet], 
                               fitness_scores: List[float], 
                               offspring: List[AdvancedReasoningNet]) -> List[AdvancedReasoningNet]:
        """ç²¾è‹±ä¿ç•™ä¸å¤šæ ·æ€§ç»´æŠ¤"""
        # æ’åºç§ç¾¤
        sorted_indices = np.argsort(fitness_scores)[::-1]  # é™åº
        
        # ä¿ç•™ç²¾è‹±
        elite = [population[i] for i in sorted_indices[:self.elite_size]]
        
        # ä»åä»£ä¸­é€‰æ‹©å‰©ä½™ä¸ªä½“ï¼Œè€ƒè™‘å¤šæ ·æ€§
        remaining_size = self.population_size - self.elite_size
        selected_offspring = self._diversity_based_selection(offspring, 
                                                          [0.5] * len(offspring), 
                                                          remaining_size)
        
        new_population = elite + selected_offspring
        
        logger.log_important(f"ç²¾è‹±ä¿ç•™ä¸å¤šæ ·æ€§ç»´æŠ¤å®Œæˆï¼Œä¿ç•™äº† {len(elite)} ä¸ªç²¾è‹±ä¸ªä½“")
        return new_population
    
    def _record_advanced_evolution(self, old_population: List[AdvancedReasoningNet], 
                                 fitness_scores: List[float], 
                                 new_population: List[AdvancedReasoningNet],
                                 diversity_score: float):
        """è®°å½•é«˜çº§è¿›åŒ–å†å²"""
        generation_info = {
            'generation': len(self.evolution_history) + 1,
            'timestamp': time.time(),
            'best_fitness': max(fitness_scores),
            'avg_fitness': np.mean(fitness_scores),
            'fitness_std': np.std(fitness_scores),
            'population_size': len(new_population),
            'diversity_score': diversity_score,
            'adaptive_mutation_rate': self.adaptive_mutation_rate,
            'adaptive_crossover_rate': self.adaptive_crossover_rate
        }
        
        self.evolution_history.append(generation_info)
        
        logger.log_important(f"é«˜çº§è¿›åŒ–å†å²è®°å½•: ç¬¬{generation_info['generation']}ä»£, "
                           f"æœ€ä½³é€‚åº”åº¦: {generation_info['best_fitness']:.3f}, "
                           f"å¹³å‡é€‚åº”åº¦: {generation_info['avg_fitness']:.3f}, "
                           f"å¤šæ ·æ€§: {generation_info['diversity_score']:.3f}")

class MultiObjectiveAdvancedEvolution:
    """å¤šç›®æ ‡é«˜çº§è¿›åŒ–ç®—æ³•"""
    
    def __init__(self, population_size: int = 15):
        self.population_size = population_size
        self.evolution = AdvancedEvolution(population_size)
        
    async def evolve_multi_objective(self, population: List[AdvancedReasoningNet], 
                                   objectives: Dict[str, List[float]]) -> List[AdvancedReasoningNet]:
        """å¤šç›®æ ‡é«˜çº§è¿›åŒ–"""
        logger.log_important("ğŸ¯ å¼€å§‹å¤šç›®æ ‡é«˜çº§è¿›åŒ–...")
        
        # è®¡ç®—å¸•ç´¯æ‰˜å‰æ²¿
        pareto_front = self._calculate_pareto_front(objectives)
        
        # è®¡ç®—æ‹¥æŒ¤åº¦è·ç¦»
        crowding_distances = self._calculate_crowding_distance(objectives, pareto_front)
        
        # åŸºäºæ‹¥æŒ¤åº¦è·ç¦»çš„é€‰æ‹©
        selected_indices = self._advanced_tournament_selection(
            objectives, crowding_distances, self.population_size
        )
        
        # é€‰æ‹©ä¸ªä½“
        selected_population = [population[i] for i in selected_indices]
        
        # æ‰§è¡Œè¿›åŒ–
        evolved_population = await self.evolution.evolve_population(
            selected_population, 
            [crowding_distances[i] for i in selected_indices]
        )
        
        return evolved_population
    
    def _calculate_pareto_front(self, objectives: Dict[str, List[float]]) -> List[int]:
        """è®¡ç®—å¸•ç´¯æ‰˜å‰æ²¿"""
        pareto_front = []
        num_individuals = len(list(objectives.values())[0])
        
        for i in range(num_individuals):
            dominated = False
            
            for j in range(num_individuals):
                if i != j:
                    # æ£€æŸ¥æ˜¯å¦è¢«æ”¯é…
                    if self._dominates(objectives, j, i):
                        dominated = True
                        break
            
            if not dominated:
                pareto_front.append(i)
        
        return pareto_front
    
    def _dominates(self, objectives: Dict[str, List[float]], i: int, j: int) -> bool:
        """æ£€æŸ¥ä¸ªä½“iæ˜¯å¦æ”¯é…ä¸ªä½“j"""
        at_least_one_better = False
        
        for objective_name, values in objectives.items():
            if values[i] < values[j]:  # å‡è®¾æ‰€æœ‰ç›®æ ‡éƒ½æ˜¯æœ€å°åŒ–
                return False
            elif values[i] > values[j]:
                at_least_one_better = True
        
        return at_least_one_better
    
    def _calculate_crowding_distance(self, objectives: Dict[str, List[float]], 
                                   pareto_front: List[int]) -> List[float]:
        """è®¡ç®—æ‹¥æŒ¤åº¦è·ç¦»"""
        num_individuals = len(list(objectives.values())[0])
        crowding_distances = [0.0] * num_individuals
        
        for objective_name, values in objectives.items():
            # å¯¹æ¯ä¸ªç›®æ ‡æ’åº
            sorted_indices = sorted(range(len(values)), key=lambda k: values[k])
            
            # è¾¹ç•Œä¸ªä½“çš„æ‹¥æŒ¤åº¦è·ç¦»è®¾ä¸ºæ— ç©·å¤§
            crowding_distances[sorted_indices[0]] = float('inf')
            crowding_distances[sorted_indices[-1]] = float('inf')
            
            # è®¡ç®—ä¸­é—´ä¸ªä½“çš„æ‹¥æŒ¤åº¦è·ç¦»
            for i in range(1, len(sorted_indices) - 1):
                distance = (values[sorted_indices[i + 1]] - values[sorted_indices[i - 1]]) / \
                          (max(values) - min(values) + 1e-10)
                crowding_distances[sorted_indices[i]] += distance
        
        return crowding_distances
    
    def _advanced_tournament_selection(self, objectives: Dict[str, List[float]], 
                                     crowding_distances: List[float], 
                                     selection_size: int) -> List[int]:
        """é«˜çº§é”¦æ ‡èµ›é€‰æ‹©"""
        selected_indices = []
        
        for _ in range(selection_size):
            # éšæœºé€‰æ‹©å¤šä¸ªä¸ªä½“
            tournament_size = min(7, len(crowding_distances))
            tournament_indices = random.sample(range(len(crowding_distances)), tournament_size)
            tournament_distances = [crowding_distances[i] for i in tournament_indices]
            
            # é€‰æ‹©æ‹¥æŒ¤åº¦è·ç¦»æœ€å¤§çš„ä¸ªä½“
            winner_idx = tournament_indices[np.argmax(tournament_distances)]
            selected_indices.append(winner_idx)
        
        return selected_indices 