#!/usr/bin/env python3
"""
æŒç»­è¿›åŒ–ç‰ˆæ¡†æ¶èåˆç³»ç»Ÿ
æ”¯æŒæ¨¡å‹æŒä¹…åŒ–ã€è¿›åŒ–å†å²ä¿å­˜ã€æ–­ç‚¹ç»­ä¼ çš„å®Œæ•´AIè¿›åŒ–ç³»ç»Ÿ
"""

import asyncio
import torch
import time
import logging
import traceback
import os
import random
import numpy as np
import json
import pickle
from datetime import datetime
from pathlib import Path
from typing import List, Tuple, Dict, Optional

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['EVOLVE_AI_DEBUG'] = 'false'

# è®¾ç½®ç®€å•çš„æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('main.log')
    ]
)

logger = logging.getLogger(__name__)

# ä¸´æ—¶ç¦ç”¨å¤æ‚æ—¥å¿—
logging.disable(logging.CRITICAL)

# å¯¼å…¥ç³»ç»Ÿæ¡†æ¶ç»„ä»¶
from evolution.population import create_initial_population
from evaluators.realworld_evaluator import RealWorldEvaluator
from evaluators.symbolic_evaluator import SymbolicEvaluator
from config.global_constants import POPULATION_SIZE, NUM_GENERATIONS, LEVEL_DESCRIPTIONS
from models.modular_net import ModularMathReasoningNet
from utils.visualization import EvolutionVisualizer
from evolution.stagnation_detector import detect_stagnation

class PersistentEvolutionManager:
    """æŒç»­è¿›åŒ–ç®¡ç†å™¨"""
    
    def __init__(self, save_dir: str = "evolution_persistence"):
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(exist_ok=True)
        
        # è¿›åŒ–çŠ¶æ€æ–‡ä»¶
        self.state_file = self.save_dir / "evolution_state.json"
        self.models_dir = self.save_dir / "models"
        self.models_dir.mkdir(exist_ok=True)
        
        # è¿›åŒ–å†å²æ–‡ä»¶
        self.history_file = self.save_dir / "evolution_history.json"
        
        # æ£€æŸ¥ç‚¹æ–‡ä»¶
        self.checkpoint_file = self.save_dir / "checkpoint.pkl"
        
        print(f"ğŸ“ æŒç»­è¿›åŒ–ç®¡ç†å™¨åˆå§‹åŒ–: {self.save_dir}")
    
    def save_evolution_state(self, generation: int, population: List[ModularMathReasoningNet], 
                           evaluation_results: List[Dict], scores: List[float]):
        """ä¿å­˜è¿›åŒ–çŠ¶æ€"""
        try:
            # ä¿å­˜æ¨¡å‹
            for i, model in enumerate(population):
                model_path = self.models_dir / f"model_gen_{generation}_id_{i}.pth"
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'model_config': model.get_config() if hasattr(model, 'get_config') else {},
                    'generation': generation,
                    'model_id': i
                }, model_path)
            
            # ä¿å­˜è¿›åŒ–çŠ¶æ€
            state = {
                'generation': generation,
                'population_size': len(population),
                'evaluation_results': evaluation_results,
                'scores': scores,
                'timestamp': datetime.now().isoformat(),
                'model_paths': [f"model_gen_{generation}_id_{i}.pth" for i in range(len(population))]
            }
            
            with open(self.state_file, 'w') as f:
                json.dump(state, f, indent=2)
            
            print(f"ğŸ’¾ ä¿å­˜è¿›åŒ–çŠ¶æ€: ç¬¬ {generation} ä»£")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜è¿›åŒ–çŠ¶æ€å¤±è´¥: {e}")
    
    def load_evolution_state(self) -> Optional[Tuple[int, List[ModularMathReasoningNet], List[Dict], List[float]]]:
        """åŠ è½½è¿›åŒ–çŠ¶æ€"""
        try:
            if not self.state_file.exists():
                print("ğŸ“‚ æœªæ‰¾åˆ°ä¿å­˜çš„è¿›åŒ–çŠ¶æ€ï¼Œå°†ä»å¤´å¼€å§‹")
                return None
            
            with open(self.state_file, 'r') as f:
                state = json.load(f)
            
            generation = state['generation']
            population_size = state['population_size']
            evaluation_results = state['evaluation_results']
            scores = state['scores']
            
            # åŠ è½½æ¨¡å‹
            population = []
            for i in range(population_size):
                model_path = self.models_dir / f"model_gen_{generation}_id_{i}.pth"
                if model_path.exists():
                    checkpoint = torch.load(model_path)
                    model = ModularMathReasoningNet()
                    model.load_state_dict(checkpoint['model_state_dict'])
                    population.append(model)
                else:
                    print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ç¼ºå¤±: {model_path}")
                    return None
            
            print(f"ğŸ“‚ åŠ è½½è¿›åŒ–çŠ¶æ€: ç¬¬ {generation} ä»£ï¼Œ{len(population)} ä¸ªæ¨¡å‹")
            return generation, population, evaluation_results, scores
            
        except Exception as e:
            print(f"âŒ åŠ è½½è¿›åŒ–çŠ¶æ€å¤±è´¥: {e}")
            return None
    
    def save_evolution_history(self, history: Dict):
        """ä¿å­˜è¿›åŒ–å†å²"""
        try:
            with open(self.history_file, 'w') as f:
                json.dump(history, f, indent=2)
            print(f"ğŸ“Š ä¿å­˜è¿›åŒ–å†å²: {len(history.get('generations', []))} ä»£")
        except Exception as e:
            print(f"âŒ ä¿å­˜è¿›åŒ–å†å²å¤±è´¥: {e}")
    
    def load_evolution_history(self) -> Dict:
        """åŠ è½½è¿›åŒ–å†å²"""
        try:
            if self.history_file.exists():
                with open(self.history_file, 'r') as f:
                    history = json.load(f)
                print(f"ğŸ“Š åŠ è½½è¿›åŒ–å†å²: {len(history.get('generations', []))} ä»£")
                return history
            else:
                return {'generations': [], 'best_scores': [], 'avg_scores': []}
        except Exception as e:
            print(f"âŒ åŠ è½½è¿›åŒ–å†å²å¤±è´¥: {e}")
            return {'generations': [], 'best_scores': [], 'avg_scores': []}
    
    def save_checkpoint(self, evolution_system, generation: int):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        try:
            checkpoint = {
                'generation': generation,
                'evolution_system_state': {
                    'stagnation_history': evolution_system.stagnation_history,
                    'visualizer_data': evolution_system.visualizer.get_data() if hasattr(evolution_system.visualizer, 'get_data') else {}
                },
                'timestamp': datetime.now().isoformat()
            }
            
            with open(self.checkpoint_file, 'wb') as f:
                pickle.dump(checkpoint, f)
            
            print(f"ğŸ”’ ä¿å­˜æ£€æŸ¥ç‚¹: ç¬¬ {generation} ä»£")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    def load_checkpoint(self, evolution_system) -> Optional[int]:
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        try:
            if not self.checkpoint_file.exists():
                return None
            
            with open(self.checkpoint_file, 'rb') as f:
                checkpoint = pickle.load(f)
            
            generation = checkpoint['generation']
            system_state = checkpoint['evolution_system_state']
            
            # æ¢å¤ç³»ç»ŸçŠ¶æ€
            evolution_system.stagnation_history = system_state.get('stagnation_history', [])
            
            print(f"ğŸ”“ åŠ è½½æ£€æŸ¥ç‚¹: ç¬¬ {generation} ä»£")
            return generation
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return None
    
    def cleanup_old_models(self, keep_generations: int = 3):
        """æ¸…ç†æ—§æ¨¡å‹æ–‡ä»¶"""
        try:
            model_files = list(self.models_dir.glob("*.pth"))
            if len(model_files) > keep_generations * POPULATION_SIZE:
                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„
                model_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
                files_to_delete = model_files[keep_generations * POPULATION_SIZE:]
                
                for file in files_to_delete:
                    file.unlink()
                
                print(f"ğŸ§¹ æ¸…ç†æ—§æ¨¡å‹æ–‡ä»¶: åˆ é™¤ {len(files_to_delete)} ä¸ªæ–‡ä»¶")
                
        except Exception as e:
            print(f"âŒ æ¸…ç†æ—§æ¨¡å‹å¤±è´¥: {e}")

class EnhancedFrameworkEvolution:
    """å¢å¼ºç‰ˆæ¡†æ¶èåˆè¿›åŒ–ç³»ç»Ÿ - æ”¯æŒæŒç»­è¿›åŒ–"""
    
    def __init__(self, enable_persistence: bool = True):
        self.realworld_evaluator = RealWorldEvaluator()
        self.symbolic_evaluator = SymbolicEvaluator()
        self.visualizer = EvolutionVisualizer()
        self.stagnation_history = []
        
        # æŒç»­è¿›åŒ–ç®¡ç†å™¨
        self.persistence_manager = PersistentEvolutionManager() if enable_persistence else None
        self.evolution_history = self.persistence_manager.load_evolution_history() if self.persistence_manager else {'generations': [], 'best_scores': [], 'avg_scores': []}
        
        print(f"ğŸš€ å¢å¼ºæ¡†æ¶èåˆç³»ç»Ÿåˆå§‹åŒ– - æŒç»­è¿›åŒ–: {'å¯ç”¨' if enable_persistence else 'ç¦ç”¨'}")
    
    def evaluate_population_enhanced(self, population: List[ModularMathReasoningNet], generation: int) -> List[Dict]:
        """å¢å¼ºçš„ç§ç¾¤è¯„ä¼° - å¤šç»´åº¦è¯„ä¼°"""
        results = []
        
        for i, model in enumerate(population):
            try:
                # åŸºç¡€æ¨ç†æµ‹è¯•
                test_input = torch.randn(1, 4)
                with torch.no_grad():
                    model.eval()
                    output = model(test_input)
                
                # å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡
                output_mean = torch.mean(output).item()
                output_std = torch.std(output).item()
                output_max = torch.max(output).item()
                output_min = torch.min(output).item()
                
                # è®¡ç®—å¤šæ ·æ€§æŒ‡æ ‡
                diversity_score = abs(output_max - output_min)
                stability_score = 1.0 / (1.0 + abs(output_std))
                complexity_score = abs(output_mean) * output_std
                
                # ç»¼åˆè¯„åˆ†
                base_score = (abs(output_mean) * 0.3 + 
                             output_std * 0.3 + 
                             diversity_score * 0.4)
                
                # æ ¹æ®ä»£æ•°è°ƒæ•´è¯„åˆ†ï¼ˆæ¨¡æ‹Ÿè¿›åŒ–å‹åŠ›ï¼‰
                generation_bonus = min(generation * 0.05, 0.2)
                final_score = base_score * (1 + generation_bonus)
                
                result = {
                    'model_id': i,
                    'base_score': base_score,
                    'final_score': final_score,
                    'diversity': diversity_score,
                    'stability': stability_score,
                    'complexity': complexity_score,
                    'output_stats': {
                        'mean': output_mean,
                        'std': output_std,
                        'max': output_max,
                        'min': output_min
                    }
                }
                
                results.append(result)
                
            except Exception as e:
                print(f"âŒ æ¨¡å‹ {i} è¯„ä¼°å¤±è´¥: {e}")
                # è¿”å›æœ€ä½åˆ†æ•°
                results.append({
                    'model_id': i,
                    'base_score': 0.1,
                    'final_score': 0.1,
                    'diversity': 0.0,
                    'stability': 0.1,
                    'complexity': 0.0,
                    'output_stats': {'mean': 0.0, 'std': 0.0, 'max': 0.0, 'min': 0.0}
                })
        
        return results
    
    def evolve_population_enhanced(self, population: List[ModularMathReasoningNet], 
                                 evaluation_results: List[Dict], 
                                 generation: int) -> List[ModularMathReasoningNet]:
        """å¢å¼ºçš„ç§ç¾¤è¿›åŒ– - å¤šç­–ç•¥è¿›åŒ–"""
        new_population = []
        
        # æŒ‰è¯„åˆ†æ’åº
        sorted_results = sorted(evaluation_results, key=lambda x: x['final_score'], reverse=True)
        
        # ç²¾è‹±ä¿ç•™ç­–ç•¥
        elite_size = max(2, len(population) // 4)
        for i in range(elite_size):
            elite_idx = sorted_results[i]['model_id']
            new_population.append(population[elite_idx])
            print(f"  ä¿ç•™ç²¾è‹±ä¸ªä½“ {elite_idx+1}: è¯„åˆ†={sorted_results[i]['final_score']:.4f}")
        
        # è‡ªé€‚åº”å˜å¼‚ç‡
        base_mutation_rate = 0.3
        mutation_rate = base_mutation_rate * (1 - generation * 0.1)  # éšä»£æ•°é€’å‡
        mutation_rate = max(0.1, mutation_rate)
        
        # ç”Ÿæˆæ–°ä¸ªä½“
        while len(new_population) < len(population):
            # é”¦æ ‡èµ›é€‰æ‹©
            tournament_size = 3
            parent1_idx = self._tournament_selection(evaluation_results, tournament_size)
            parent2_idx = self._tournament_selection(evaluation_results, tournament_size)
            
            parent1 = population[parent1_idx]
            parent2 = population[parent2_idx]
            
            # åˆ›å»ºå­ä»£
            child = ModularMathReasoningNet(
                modules_config=parent1.modules_config.copy(),
                epigenetic_markers=parent1.epigenetic_markers.clone()
            )
            
            # æ™ºèƒ½å˜å¼‚ç­–ç•¥
            if random.random() < mutation_rate:
                # ç»“æ„å˜å¼‚
                if random.random() < 0.3:
                    self._structural_mutation(child)
                    print(f"  ç”Ÿæˆç»“æ„å˜å¼‚ä¸ªä½“")
                else:
                    # æƒé‡å˜å¼‚
                    self._weight_mutation(child, strength=0.1)
                    print(f"  ç”Ÿæˆæƒé‡å˜å¼‚ä¸ªä½“")
            else:
                # äº¤å‰æ“ä½œ
                self._crossover_operation(child, parent1, parent2)
                print(f"  ç”Ÿæˆäº¤å‰ä¸ªä½“")
            
            new_population.append(child)
        
        return new_population
    
    def _tournament_selection(self, evaluation_results: List[Dict], tournament_size: int) -> int:
        """é”¦æ ‡èµ›é€‰æ‹©"""
        tournament = random.sample(evaluation_results, tournament_size)
        winner = max(tournament, key=lambda x: x['final_score'])
        return winner['model_id']
    
    def _structural_mutation(self, model: ModularMathReasoningNet):
        """ç»“æ„å˜å¼‚"""
        # éšæœºè°ƒæ•´ç½‘ç»œç»“æ„å‚æ•°
        for param in model.parameters():
            if random.random() < 0.2:  # 20%çš„å‚æ•°è¿›è¡Œç»“æ„å˜å¼‚
                noise = torch.randn_like(param) * 0.2
                param.data += noise
    
    def _weight_mutation(self, model: ModularMathReasoningNet, strength: float):
        """æƒé‡å˜å¼‚"""
        for param in model.parameters():
            if random.random() < 0.15:  # 15%çš„å‚æ•°å˜å¼‚
                noise = torch.randn_like(param) * strength
                param.data += noise
    
    def _crossover_operation(self, child: ModularMathReasoningNet, 
                           parent1: ModularMathReasoningNet, 
                           parent2: ModularMathReasoningNet):
        """äº¤å‰æ“ä½œ"""
        # æ··åˆçˆ¶ä»£å‚æ•°
        for child_param, p1_param, p2_param in zip(child.parameters(), 
                                                   parent1.parameters(), 
                                                   parent2.parameters()):
            if random.random() < 0.5:
                child_param.data = p1_param.data.clone()
            else:
                child_param.data = p2_param.data.clone()
    
    def run_enhanced_evolution(self):
        """è¿è¡Œå¢å¼ºè¿›åŒ– - æ”¯æŒæŒç»­è¿›åŒ–"""
        try:
            print("ğŸš€ å¯åŠ¨æŒç»­è¿›åŒ–ç³»ç»Ÿ...")
            
            # æ­¥éª¤1ï¼šå°è¯•åŠ è½½ç°æœ‰è¿›åŒ–çŠ¶æ€
            population = None
            current_generation = 0
            all_evaluation_results = []
            all_avg_scores = []
            all_best_scores = []
            
            if self.persistence_manager:
                # å°è¯•åŠ è½½æ£€æŸ¥ç‚¹
                checkpoint_generation = self.persistence_manager.load_checkpoint(self)
                if checkpoint_generation is not None:
                    current_generation = checkpoint_generation
                    print(f"ğŸ”“ ä»æ£€æŸ¥ç‚¹æ¢å¤: ç¬¬ {current_generation} ä»£")
                
                # å°è¯•åŠ è½½è¿›åŒ–çŠ¶æ€
                state_result = self.persistence_manager.load_evolution_state()
                if state_result is not None:
                    loaded_generation, population, evaluation_results, scores = state_result
                    current_generation = loaded_generation
                    all_evaluation_results.append(evaluation_results)
                    all_avg_scores.append(np.mean(scores))
                    all_best_scores.append(max(scores))
                    print(f"ğŸ“‚ ä»ä¿å­˜çŠ¶æ€æ¢å¤: ç¬¬ {current_generation} ä»£")
                    
                    # åŠ è½½è¿›åŒ–å†å²
                    if self.evolution_history['generations']:
                        all_avg_scores = self.evolution_history['avg_scores']
                        all_best_scores = self.evolution_history['best_scores']
                        print(f"ğŸ“Š åŠ è½½è¿›åŒ–å†å²: {len(all_avg_scores)} ä»£æ•°æ®")
            
            # å¦‚æœæ²¡æœ‰åŠ è½½åˆ°çŠ¶æ€ï¼Œåˆ›å»ºåˆå§‹ç§ç¾¤
            if population is None:
                print("ğŸ†• åˆ›å»ºåˆå§‹ç§ç¾¤...")
                population = create_initial_population(POPULATION_SIZE)
                current_generation = 0
            
            print(f"ğŸ¯ å¼€å§‹è¿›åŒ–: ç¬¬ {current_generation + 1} ä»£ï¼Œç§ç¾¤å¤§å°: {len(population)}")
            
            # æ­¥éª¤2ï¼šè¿›åŒ–å¾ªç¯
            for generation in range(current_generation, NUM_GENERATIONS):
                print(f"\n{'='*50}")
                print(f"ğŸ”„ ç¬¬ {generation + 1} ä»£è¿›åŒ–")
                print(f"{'='*50}")
                
                # è¯„ä¼°ç§ç¾¤
                print("ğŸ“Š è¯„ä¼°ç§ç¾¤...")
                evaluation_results = self.evaluate_population_enhanced(population, generation + 1)
                all_evaluation_results.append(evaluation_results)
                
                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                scores = [result['final_score'] for result in evaluation_results]
                avg_score = np.mean(scores)
                best_score = max(scores)
                all_avg_scores.append(avg_score)
                all_best_scores.append(best_score)
                
                print(f"ğŸ“ˆ ç¬¬ {generation + 1} ä»£ç»“æœ:")
                print(f"  å¹³å‡è¯„åˆ†: {avg_score:.4f}")
                print(f"  æœ€ä½³è¯„åˆ†: {best_score:.4f}")
                print(f"  ç§ç¾¤å¤šæ ·æ€§: {np.mean([r['diversity'] for r in evaluation_results]):.4f}")
                
                # ä¿å­˜è¿›åŒ–çŠ¶æ€
                if self.persistence_manager:
                    self.persistence_manager.save_evolution_state(generation + 1, population, evaluation_results, scores)
                    
                    # æ›´æ–°è¿›åŒ–å†å²
                    self.evolution_history['generations'].append(generation + 1)
                    self.evolution_history['avg_scores'].append(avg_score)
                    self.evolution_history['best_scores'].append(best_score)
                    self.persistence_manager.save_evolution_history(self.evolution_history)
                    
                    # ä¿å­˜æ£€æŸ¥ç‚¹
                    self.persistence_manager.save_checkpoint(self, generation + 1)
                    
                    # å®šæœŸæ¸…ç†æ—§æ–‡ä»¶
                    if (generation + 1) % 5 == 0:
                        self.persistence_manager.cleanup_old_models()
                
                # åœæ»æ£€æµ‹
                if len(all_avg_scores) > 3:
                    is_stagnated = detect_stagnation(all_avg_scores[-3:])
                    if is_stagnated:
                        print("âš ï¸  æ£€æµ‹åˆ°åœæ»ï¼Œå¢åŠ è¿›åŒ–å‹åŠ›")
                        # å¢åŠ å˜å¼‚å¼ºåº¦
                        for model in population:
                            for param in model.parameters():
                                if random.random() < 0.3:
                                    noise = torch.randn_like(param) * 0.2
                                    param.data += noise
                
                if generation < NUM_GENERATIONS - 1:  # ä¸æ˜¯æœ€åä¸€ä»£
                    # è¿›åŒ–ç§ç¾¤
                    print("ğŸ§¬ è¿›åŒ–ç§ç¾¤...")
                    population = self.evolve_population_enhanced(population, evaluation_results, generation + 1)
            
            # æ­¥éª¤3ï¼šç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            print(f"\n{'='*60}")
            print(f"ğŸ‰ æŒç»­è¿›åŒ–å®Œæˆ! æ€»å…± {len(all_evaluation_results)} ä¸ªä¸–ä»£")
            
            if len(all_avg_scores) > 1:
                initial_avg = all_avg_scores[0]
                final_avg = all_avg_scores[-1]
                initial_best = all_best_scores[0]
                final_best = all_best_scores[-1]
                
                print(f"ğŸ“Š è¿›åŒ–ç»Ÿè®¡:")
                print(f"  åˆå§‹å¹³å‡è¯„åˆ†: {initial_avg:.4f}")
                print(f"  æœ€ç»ˆå¹³å‡è¯„åˆ†: {final_avg:.4f}")
                print(f"  åˆå§‹æœ€ä½³è¯„åˆ†: {initial_best:.4f}")
                print(f"  æœ€ç»ˆæœ€ä½³è¯„åˆ†: {final_best:.4f}")
                
                if initial_avg != 0:
                    avg_improvement = (final_avg - initial_avg) / initial_avg * 100
                    best_improvement = (final_best - initial_best) / initial_best * 100
                    print(f"  å¹³å‡è¯„åˆ†æ”¹è¿›: {avg_improvement:.2f}%")
                    print(f"  æœ€ä½³è¯„åˆ†æ”¹è¿›: {best_improvement:.2f}%")
                
                # æ˜¾ç¤ºè¿›åŒ–è¶‹åŠ¿
                print(f"\nğŸ“ˆ è¿›åŒ–è¶‹åŠ¿:")
                for i, (avg, best) in enumerate(zip(all_avg_scores, all_best_scores)):
                    print(f"  ä¸–ä»£ {i+1}: å¹³å‡={avg:.4f}, æœ€ä½³={best:.4f}")
                
                # åˆ†æè¿›åŒ–æ•ˆæœ
                if final_best > initial_best:
                    print(f"âœ… æŒç»­è¿›åŒ–æˆåŠŸï¼æœ€ä½³è¯„åˆ†ä» {initial_best:.4f} æå‡åˆ° {final_best:.4f}")
                    print(f"ğŸ¯ è¿™è¡¨æ˜æŒç»­è¿›åŒ–ç³»ç»Ÿæœ‰æ•ˆï¼ŒAIæ¨¡å‹åœ¨é•¿æœŸè¿›åŒ–ä¸­æŒç»­æ”¹è¿›")
                    print(f"ğŸš€ ç³»ç»Ÿæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œè¿›åŒ–æˆæœå¾—åˆ°å®Œæ•´ä¿å­˜")
                else:
                    print(f"âš ï¸  è¿›åŒ–æ•ˆæœæœ‰é™ï¼Œæœ€ä½³è¯„åˆ†ä» {initial_best:.4f} å˜åŒ–åˆ° {final_best:.4f}")
                    print(f"ğŸ’¡ å¯èƒ½éœ€è¦è°ƒæ•´å‚æ•°æˆ–å¢åŠ è¿›åŒ–ä»£æ•°")
                
                # åˆ†æå¤šæ ·æ€§
                final_diversity = np.mean([result['diversity'] for result in all_evaluation_results[-1]])
                final_stability = np.mean([result['stability'] for result in all_evaluation_results[-1]])
                print(f"  æœ€ç»ˆå¤šæ ·æ€§æŒ‡æ ‡: {final_diversity:.4f}")
                print(f"  æœ€ç»ˆç¨³å®šæ€§æŒ‡æ ‡: {final_stability:.4f}")
            else:
                print("æ²¡æœ‰è¶³å¤Ÿçš„è¿›åŒ–å†å²è¿›è¡Œåˆ†æ")
            
            # ä¿å­˜æœ€ç»ˆçŠ¶æ€
            if self.persistence_manager:
                print(f"\nğŸ’¾ ä¿å­˜æœ€ç»ˆè¿›åŒ–çŠ¶æ€...")
                self.persistence_manager.save_evolution_state(NUM_GENERATIONS, population, 
                                                           all_evaluation_results[-1], 
                                                           [r['final_score'] for r in all_evaluation_results[-1]])
                
                # ç”Ÿæˆè¿›åŒ–æŠ¥å‘Š
                report = {
                    'total_generations': len(all_evaluation_results),
                    'final_best_score': all_best_scores[-1] if all_best_scores else 0,
                    'final_avg_score': all_avg_scores[-1] if all_avg_scores else 0,
                    'improvement_percentage': ((all_best_scores[-1] - all_best_scores[0]) / all_best_scores[0] * 100) if len(all_best_scores) > 1 and all_best_scores[0] != 0 else 0,
                    'evolution_history': self.evolution_history,
                    'timestamp': datetime.now().isoformat()
                }
                
                report_file = self.persistence_manager.save_dir / "evolution_report.json"
                with open(report_file, 'w') as f:
                    json.dump(report, f, indent=2)
                
                print(f"ğŸ“„ è¿›åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
            print("=" * 60)
            
        except Exception as e:
            print(f"âŒ æŒç»­è¿›åŒ–æ‰§è¡Œå¤±è´¥: {e}")
            print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            raise

def main():
    """ä¸»å‡½æ•° - æŒç»­è¿›åŒ–ç‰ˆæœ¬"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æŒç»­è¿›åŒ–AIç³»ç»Ÿ')
    parser.add_argument('--disable-persistence', action='store_true', 
                       help='ç¦ç”¨æŒç»­è¿›åŒ–åŠŸèƒ½ï¼ˆä¸€æ¬¡æ€§è¿è¡Œï¼‰')
    parser.add_argument('--clean-start', action='store_true',
                       help='æ¸…ç†æ‰€æœ‰ä¿å­˜çš„çŠ¶æ€ï¼Œä»å¤´å¼€å§‹')
    parser.add_argument('--show-status', action='store_true',
                       help='æ˜¾ç¤ºå½“å‰è¿›åŒ–çŠ¶æ€')
    
    args = parser.parse_args()
    
    # å¦‚æœè¦æ±‚æ¸…ç†ï¼Œåˆ é™¤æ‰€æœ‰ä¿å­˜æ–‡ä»¶
    if args.clean_start:
        import shutil
        persistence_dir = Path("evolution_persistence")
        if persistence_dir.exists():
            shutil.rmtree(persistence_dir)
            print("ğŸ§¹ å·²æ¸…ç†æ‰€æœ‰ä¿å­˜çš„è¿›åŒ–çŠ¶æ€")
    
    # å¦‚æœè¦æ±‚æ˜¾ç¤ºçŠ¶æ€
    if args.show_status:
        persistence_dir = Path("evolution_persistence")
        if persistence_dir.exists():
            state_file = persistence_dir / "evolution_state.json"
            history_file = persistence_dir / "evolution_history.json"
            
            print("ğŸ“Š å½“å‰è¿›åŒ–çŠ¶æ€:")
            if state_file.exists():
                with open(state_file, 'r') as f:
                    state = json.load(f)
                print(f"  å½“å‰ä»£æ•°: {state['generation']}")
                print(f"  ç§ç¾¤å¤§å°: {state['population_size']}")
                print(f"  æœ€åä¿å­˜: {state['timestamp']}")
            
            if history_file.exists():
                with open(history_file, 'r') as f:
                    history = json.load(f)
                print(f"  è¿›åŒ–å†å²: {len(history.get('generations', []))} ä»£")
                if history.get('best_scores'):
                    print(f"  æœ€ä½³è¯„åˆ†: {max(history['best_scores']):.4f}")
                    print(f"  å¹³å‡è¯„åˆ†: {np.mean(history['avg_scores']):.4f}")
        else:
            print("ğŸ“‚ æœªæ‰¾åˆ°ä¿å­˜çš„è¿›åŒ–çŠ¶æ€")
        return
    
    # åˆ›å»ºè¿›åŒ–ç³»ç»Ÿ
    enable_persistence = not args.disable_persistence
    evolution_system = EnhancedFrameworkEvolution(enable_persistence=enable_persistence)
    
    print(f"\nğŸ¯ æŒç»­è¿›åŒ–ç³»ç»Ÿå¯åŠ¨")
    print(f"ğŸ“ æŒä¹…åŒ–: {'å¯ç”¨' if enable_persistence else 'ç¦ç”¨'}")
    print(f"ğŸ”„ è¿›åŒ–ä»£æ•°: {NUM_GENERATIONS}")
    print(f"ğŸ‘¥ ç§ç¾¤å¤§å°: {POPULATION_SIZE}")
    print("=" * 60)
    
    # è¿è¡Œè¿›åŒ–
    evolution_system.run_enhanced_evolution()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        print("ğŸ’¾ å½“å‰è¿›åŒ–çŠ¶æ€å·²è‡ªåŠ¨ä¿å­˜")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}") 