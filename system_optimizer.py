#!/usr/bin/env python3
"""
ç³»ç»Ÿä¼˜åŒ–è„šæœ¬
ç”¨äºç³»ç»Ÿå‚æ•°è°ƒä¼˜å’Œèµ„æºä¼˜åŒ–
"""

import asyncio
import time
import psutil
import gc
import torch
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from config.logging_setup import setup_logging

logger = setup_logging()

@dataclass
class OptimizationConfig:
    """ä¼˜åŒ–é…ç½®"""
    # è¿›åŒ–å‚æ•°
    population_size: int = 20
    mutation_rate: float = 0.8
    crossover_rate: float = 0.8
    num_generations: int = 10
    
    # è¯„ä¼°å‚æ•°
    evaluation_batch_size: int = 5
    max_evaluation_time: float = 30.0
    
    # èµ„æºå‚æ•°
    max_cpu_percent: float = 80.0
    max_memory_percent: float = 85.0
    max_gpu_memory_percent: float = 90.0
    
    # æ€§èƒ½å‚æ•°
    target_evaluation_speed: float = 10.0  # è¯„ä¼°/ç§’
    target_evolution_speed: float = 2.0    # è¿›åŒ–/ç§’

class SystemOptimizer:
    """ç³»ç»Ÿä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.logger = logger
        self.optimization_history: List[Dict[str, Any]] = []
        self.current_config = OptimizationConfig()
        
    async def optimize_system_parameters(self) -> Dict[str, Any]:
        """ä¼˜åŒ–ç³»ç»Ÿå‚æ•°"""
        self.logger.info("ğŸ”§ å¼€å§‹ç³»ç»Ÿå‚æ•°ä¼˜åŒ–...")
        
        # æ£€æŸ¥å½“å‰ç³»ç»ŸçŠ¶æ€
        system_status = await self._check_system_status()
        self.logger.info(f"å½“å‰ç³»ç»ŸçŠ¶æ€: {system_status}")
        
        # ä¼˜åŒ–è¿›åŒ–å‚æ•°
        evolution_config = await self._optimize_evolution_parameters()
        
        # ä¼˜åŒ–è¯„ä¼°å‚æ•°
        evaluation_config = await self._optimize_evaluation_parameters()
        
        # ä¼˜åŒ–èµ„æºå‚æ•°
        resource_config = await self._optimize_resource_parameters()
        
        # åˆå¹¶ä¼˜åŒ–ç»“æœ
        optimized_config = OptimizationConfig(
            population_size=evolution_config.get('population_size', 20),
            mutation_rate=evolution_config.get('mutation_rate', 0.8),
            crossover_rate=evolution_config.get('crossover_rate', 0.8),
            num_generations=evolution_config.get('num_generations', 10),
            evaluation_batch_size=evaluation_config.get('batch_size', 5),
            max_evaluation_time=evaluation_config.get('max_time', 30.0),
            max_cpu_percent=resource_config.get('max_cpu', 80.0),
            max_memory_percent=resource_config.get('max_memory', 85.0),
            max_gpu_memory_percent=resource_config.get('max_gpu', 90.0)
        )
        
        self.current_config = optimized_config
        
        # è®°å½•ä¼˜åŒ–å†å²
        optimization_record = {
            "timestamp": time.time(),
            "original_config": system_status,
            "optimized_config": optimized_config.__dict__,
            "improvements": {
                "evolution": evolution_config.get('improvement', 0),
                "evaluation": evaluation_config.get('improvement', 0),
                "resource": resource_config.get('improvement', 0)
            }
        }
        self.optimization_history.append(optimization_record)
        
        self.logger.info("âœ… ç³»ç»Ÿå‚æ•°ä¼˜åŒ–å®Œæˆ")
        return optimization_record
        
    async def _check_system_status(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç³»ç»ŸçŠ¶æ€"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        memory_percent = memory.percent
        
        # æ£€æŸ¥GPUçŠ¶æ€
        gpu_memory_percent = 0
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.memory_allocated()
            gpu_memory_total = torch.cuda.get_device_properties(0).total_memory
            gpu_memory_percent = (gpu_memory / gpu_memory_total) * 100
            
        return {
            "cpu_percent": cpu_percent,
            "memory_percent": memory_percent,
            "gpu_memory_percent": gpu_memory_percent,
            "available_memory_mb": memory.available / (1024 * 1024)
        }
        
    async def _optimize_evolution_parameters(self) -> Dict[str, Any]:
        """ä¼˜åŒ–è¿›åŒ–å‚æ•°"""
        self.logger.info("ä¼˜åŒ–è¿›åŒ–å‚æ•°...")
        
        # æµ‹è¯•ä¸åŒçš„ç§ç¾¤å¤§å°
        population_sizes = [10, 15, 20, 25, 30]
        best_population_size = 20
        best_performance = 0
        
        for size in population_sizes:
            # æ¨¡æ‹Ÿæ€§èƒ½æµ‹è¯•
            performance = await self._simulate_evolution_performance(size)
            if performance > best_performance:
                best_performance = performance
                best_population_size = size
                
        # æµ‹è¯•ä¸åŒçš„å˜å¼‚ç‡
        mutation_rates = [0.6, 0.7, 0.8, 0.9]
        best_mutation_rate = 0.8
        best_mutation_performance = 0
        
        for rate in mutation_rates:
            performance = await self._simulate_mutation_performance(rate)
            if performance > best_mutation_performance:
                best_mutation_performance = performance
                best_mutation_rate = rate
                
        improvement = ((best_performance + best_mutation_performance) / 2) - 0.5
        
        return {
            "population_size": best_population_size,
            "mutation_rate": best_mutation_rate,
            "crossover_rate": 0.8,  # ä¿æŒé»˜è®¤å€¼
            "num_generations": 10,   # ä¿æŒé»˜è®¤å€¼
            "improvement": improvement
        }
        
    async def _optimize_evaluation_parameters(self) -> Dict[str, Any]:
        """ä¼˜åŒ–è¯„ä¼°å‚æ•°"""
        self.logger.info("ä¼˜åŒ–è¯„ä¼°å‚æ•°...")
        
        # æµ‹è¯•ä¸åŒçš„æ‰¹å¤„ç†å¤§å°
        batch_sizes = [3, 5, 8, 10]
        best_batch_size = 5
        best_evaluation_performance = 0
        
        for batch_size in batch_sizes:
            performance = await self._simulate_evaluation_performance(batch_size)
            if performance > best_evaluation_performance:
                best_evaluation_performance = performance
                best_batch_size = batch_size
                
        # æµ‹è¯•ä¸åŒçš„æœ€å¤§è¯„ä¼°æ—¶é—´
        max_times = [20.0, 30.0, 45.0, 60.0]
        best_max_time = 30.0
        best_time_performance = 0
        
        for max_time in max_times:
            performance = await self._simulate_time_performance(max_time)
            if performance > best_time_performance:
                best_time_performance = performance
                best_max_time = max_time
                
        improvement = ((best_evaluation_performance + best_time_performance) / 2) - 0.5
        
        return {
            "batch_size": best_batch_size,
            "max_time": best_max_time,
            "improvement": improvement
        }
        
    async def _optimize_resource_parameters(self) -> Dict[str, Any]:
        """ä¼˜åŒ–èµ„æºå‚æ•°"""
        self.logger.info("ä¼˜åŒ–èµ„æºå‚æ•°...")
        
        system_status = await self._check_system_status()
        
        # æ ¹æ®å½“å‰ç³»ç»ŸçŠ¶æ€è°ƒæ•´èµ„æºé™åˆ¶
        current_cpu = system_status["cpu_percent"]
        current_memory = system_status["memory_percent"]
        current_gpu = system_status["gpu_memory_percent"]
        
        # åŠ¨æ€è°ƒæ•´èµ„æºé™åˆ¶
        if current_cpu > 70:
            max_cpu = min(85.0, current_cpu + 10)
        else:
            max_cpu = 80.0
            
        if current_memory > 70:
            max_memory = min(90.0, current_memory + 10)
        else:
            max_memory = 85.0
            
        if current_gpu > 70:
            max_gpu = min(95.0, current_gpu + 10)
        else:
            max_gpu = 90.0
            
        improvement = 0.1  # èµ„æºä¼˜åŒ–é€šå¸¸å¸¦æ¥å°å¹…æ”¹è¿›
        
        return {
            "max_cpu": max_cpu,
            "max_memory": max_memory,
            "max_gpu": max_gpu,
            "improvement": improvement
        }
        
    async def _simulate_evolution_performance(self, population_size: int) -> float:
        """æ¨¡æ‹Ÿè¿›åŒ–æ€§èƒ½"""
        # ç®€å•çš„æ€§èƒ½æ¨¡æ‹Ÿ
        base_performance = 0.5
        size_factor = min(1.0, population_size / 20.0)
        return base_performance + (size_factor * 0.3)
        
    async def _simulate_mutation_performance(self, mutation_rate: float) -> float:
        """æ¨¡æ‹Ÿå˜å¼‚æ€§èƒ½"""
        # ç®€å•çš„æ€§èƒ½æ¨¡æ‹Ÿ
        base_performance = 0.5
        rate_factor = abs(mutation_rate - 0.8) / 0.2  # 0.8æ˜¯æœ€ä½³å€¼
        return base_performance + ((1 - rate_factor) * 0.3)
        
    async def _simulate_evaluation_performance(self, batch_size: int) -> float:
        """æ¨¡æ‹Ÿè¯„ä¼°æ€§èƒ½"""
        # ç®€å•çš„æ€§èƒ½æ¨¡æ‹Ÿ
        base_performance = 0.5
        batch_factor = min(1.0, batch_size / 8.0)
        return base_performance + (batch_factor * 0.3)
        
    async def _simulate_time_performance(self, max_time: float) -> float:
        """æ¨¡æ‹Ÿæ—¶é—´æ€§èƒ½"""
        # ç®€å•çš„æ€§èƒ½æ¨¡æ‹Ÿ
        base_performance = 0.5
        time_factor = min(1.0, max_time / 45.0)
        return base_performance + (time_factor * 0.2)
        
    def optimize_memory_usage(self) -> Dict[str, Any]:
        """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        self.logger.info("ä¼˜åŒ–å†…å­˜ä½¿ç”¨...")
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        # æ¸…ç†PyTorchç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory_before = psutil.virtual_memory().used
        gc.collect()
        memory_after = psutil.virtual_memory().used
        memory_freed = memory_before - memory_after
        
        self.logger.info(f"é‡Šæ”¾å†…å­˜: {memory_freed / (1024 * 1024):.1f} MB")
        
        return {
            "memory_freed_mb": memory_freed / (1024 * 1024),
            "optimization_success": memory_freed > 0
        }
        
    def optimize_cpu_usage(self) -> Dict[str, Any]:
        """ä¼˜åŒ–CPUä½¿ç”¨"""
        self.logger.info("ä¼˜åŒ–CPUä½¿ç”¨...")
        
        # æ£€æŸ¥å½“å‰CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        
        # æ ¹æ®CPUä½¿ç”¨ç‡æä¾›å»ºè®®
        if cpu_percent > 80:
            recommendation = "å»ºè®®å‡å°‘å¹¶è¡Œä»»åŠ¡æ•°é‡"
        elif cpu_percent > 60:
            recommendation = "å»ºè®®ä¼˜åŒ–ç®—æ³•æ•ˆç‡"
        else:
            recommendation = "CPUä½¿ç”¨ç‡æ­£å¸¸"
            
        return {
            "current_cpu_percent": cpu_percent,
            "recommendation": recommendation,
            "optimization_needed": cpu_percent > 80
        }
        
    def get_optimization_summary(self) -> str:
        """è·å–ä¼˜åŒ–æ‘˜è¦"""
        if not self.optimization_history:
            return "æš‚æ— ä¼˜åŒ–å†å²"
            
        latest_optimization = self.optimization_history[-1]
        improvements = latest_optimization["improvements"]
        
        total_improvement = sum(improvements.values())
        avg_improvement = total_improvement / len(improvements)
        
        summary = f"""
ğŸ”§ ç³»ç»Ÿä¼˜åŒ–æ‘˜è¦
================

ğŸ“Š æœ€æ–°ä¼˜åŒ–æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(latest_optimization['timestamp']))}

ğŸ¯ ä¼˜åŒ–æ”¹è¿›:
   è¿›åŒ–å‚æ•°: {improvements['evolution']:.1%}
   è¯„ä¼°å‚æ•°: {improvements['evaluation']:.1%}
   èµ„æºå‚æ•°: {improvements['resource']:.1%}
   å¹³å‡æ”¹è¿›: {avg_improvement:.1%}

âš™ï¸  å½“å‰é…ç½®:
   ç§ç¾¤å¤§å°: {self.current_config.population_size}
   å˜å¼‚ç‡: {self.current_config.mutation_rate}
   äº¤å‰ç‡: {self.current_config.crossover_rate}
   è¯„ä¼°æ‰¹å¤§å°: {self.current_config.evaluation_batch_size}
   æœ€å¤§è¯„ä¼°æ—¶é—´: {self.current_config.max_evaluation_time}ç§’
   CPUé™åˆ¶: {self.current_config.max_cpu_percent}%
   å†…å­˜é™åˆ¶: {self.current_config.max_memory_percent}%

ğŸ“ˆ ä¼˜åŒ–å†å²: {len(self.optimization_history)} æ¬¡ä¼˜åŒ–
"""
        
        return summary
        
    def apply_optimizations(self) -> Dict[str, Any]:
        """åº”ç”¨ä¼˜åŒ–"""
        self.logger.info("åº”ç”¨ç³»ç»Ÿä¼˜åŒ–...")
        
        # å†…å­˜ä¼˜åŒ–
        memory_result = self.optimize_memory_usage()
        
        # CPUä¼˜åŒ–
        cpu_result = self.optimize_cpu_usage()
        
        # è¿”å›ä¼˜åŒ–ç»“æœ
        return {
            "memory_optimization": memory_result,
            "cpu_optimization": cpu_result,
            "optimization_success": memory_result["optimization_success"] or not cpu_result["optimization_needed"]
        }

async def demo_system_optimization():
    """æ¼”ç¤ºç³»ç»Ÿä¼˜åŒ–åŠŸèƒ½"""
    optimizer = SystemOptimizer()
    
    # æ‰§è¡Œç³»ç»Ÿä¼˜åŒ–
    optimization_result = await optimizer.optimize_system_parameters()
    
    # åº”ç”¨ä¼˜åŒ–
    applied_result = optimizer.apply_optimizations()
    
    # ç”Ÿæˆæ‘˜è¦
    summary = optimizer.get_optimization_summary()
    print(summary)
    
    print(f"\nä¼˜åŒ–ç»“æœ:")
    print(f"å†…å­˜é‡Šæ”¾: {applied_result['memory_optimization']['memory_freed_mb']:.1f} MB")
    print(f"CPUä½¿ç”¨ç‡: {applied_result['cpu_optimization']['current_cpu_percent']:.1f}%")
    print(f"ä¼˜åŒ–å»ºè®®: {applied_result['cpu_optimization']['recommendation']}")

if __name__ == "__main__":
    asyncio.run(demo_system_optimization()) 