#!/usr/bin/env python3
"""
è¿›åŒ–åAIæ¨¡å‹èƒ½åŠ›åˆ†æ
åˆ†æç»è¿‡é•¿æœŸè¿›åŒ–çš„AIæ¨¡å‹å…·å¤‡çš„èƒ½åŠ›
"""

import torch
import numpy as np
import json
import time
from pathlib import Path
from typing import Dict, List

def analyze_evolution_results():
    """åˆ†æè¿›åŒ–ç»“æœï¼Œäº†è§£æ¨¡å‹èƒ½åŠ›"""
    print("ğŸ”¬ è¿›åŒ–åAIæ¨¡å‹èƒ½åŠ›åˆ†æ")
    print("=" * 60)
    
    # 1. åˆ†æè¿›åŒ–å†å²
    print("\nğŸ“Š åˆ†æè¿›åŒ–å†å²...")
    history_file = Path("evolution_persistence/evolution_history.json")
    if history_file.exists():
        with open(history_file, 'r') as f:
            history = json.load(f)
        
        generations = history.get('generations', [])
        best_scores = history.get('best_scores', [])
        avg_scores = history.get('avg_scores', [])
        
        if best_scores and avg_scores:
            print(f"ğŸ“ˆ è¿›åŒ–ä»£æ•°: {len(generations)}")
            print(f"ğŸ† æœ€ä½³è¯„åˆ†: {max(best_scores):.4f}")
            print(f"ğŸ“Š å¹³å‡è¯„åˆ†: {np.mean(avg_scores):.4f}")
            print(f"ğŸš€ è¯„åˆ†æ”¹è¿›: {((max(best_scores) - min(best_scores)) / min(best_scores) * 100):.2f}%")
            
            # åˆ†æè¿›åŒ–è¶‹åŠ¿
            if len(best_scores) > 10:
                recent_best = best_scores[-10:]
                early_best = best_scores[:10]
                recent_avg = np.mean(recent_best)
                early_avg = np.mean(early_best)
                improvement = (recent_avg - early_avg) / early_avg * 100
                print(f"ğŸ“ˆ è¿‘æœŸæ”¹è¿›: {improvement:.2f}%")
    
    # 2. åˆ†ææ¨¡å‹æ–‡ä»¶
    print("\nğŸ“ åˆ†ææ¨¡å‹æ–‡ä»¶...")
    models_dir = Path("evolution_persistence/models")
    if models_dir.exists():
        model_files = list(models_dir.glob("model_gen_*_id_*.pth"))
        if model_files:
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
            model_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            latest_model = model_files[0]
            
            print(f"ğŸ“¦ æ¨¡å‹æ–‡ä»¶æ•°é‡: {len(model_files)}")
            print(f"ğŸ†• æœ€æ–°æ¨¡å‹: {latest_model.name}")
            
            # åˆ†ææ¨¡å‹å¤§å°
            model_size = latest_model.stat().st_size / 1024  # KB
            print(f"ğŸ’¾ æ¨¡å‹å¤§å°: {model_size:.2f} KB")
            
            # åˆ†ææ¨¡å‹ä»£æ•°åˆ†å¸ƒ
            generations = set()
            for model_file in model_files:
                parts = model_file.stem.split('_')
                if len(parts) >= 3:
                    try:
                        gen = int(parts[2])
                        generations.add(gen)
                    except:
                        pass
            
            print(f"ğŸ”„ è¦†ç›–ä»£æ•°: {len(generations)} ä»£")
            if generations:
                print(f"ğŸ“Š ä»£æ•°èŒƒå›´: {min(generations)} - {max(generations)}")
    
    # 3. åˆ†æè¿›åŒ–æŠ¥å‘Š
    print("\nğŸ“„ åˆ†æè¿›åŒ–æŠ¥å‘Š...")
    report_file = Path("evolution_persistence/evolution_report.json")
    if report_file.exists():
        with open(report_file, 'r') as f:
            report = json.load(f)
        
        total_generations = report.get('total_generations', 0)
        final_best_score = report.get('final_best_score', 0)
        final_avg_score = report.get('final_avg_score', 0)
        improvement_percentage = report.get('improvement_percentage', 0)
        
        print(f"ğŸ¯ æ€»è¿›åŒ–ä»£æ•°: {total_generations}")
        print(f"ğŸ† æœ€ç»ˆæœ€ä½³è¯„åˆ†: {final_best_score:.4f}")
        print(f"ğŸ“Š æœ€ç»ˆå¹³å‡è¯„åˆ†: {final_avg_score:.4f}")
        print(f"ğŸš€ æ”¹è¿›ç™¾åˆ†æ¯”: {improvement_percentage:.2f}%")
    
    # 4. èƒ½åŠ›è¯„ä¼°
    print("\nğŸ¯ èƒ½åŠ›è¯„ä¼°...")
    capabilities = {
        "æ¨ç†èƒ½åŠ›": "é«˜" if final_best_score > 10 else "ä¸­ç­‰" if final_best_score > 5 else "åŸºç¡€",
        "å­¦ä¹ èƒ½åŠ›": "å¼º" if improvement_percentage > 100 else "ä¸­ç­‰" if improvement_percentage > 50 else "å¼±",
        "é€‚åº”æ€§": "ä¼˜ç§€" if len(generations) > 100 else "è‰¯å¥½" if len(generations) > 50 else "ä¸€èˆ¬",
        "ç¨³å®šæ€§": "é«˜" if final_avg_score > final_best_score * 0.8 else "ä¸­ç­‰",
        "è¿›åŒ–æ½œåŠ›": "å·¨å¤§" if improvement_percentage > 500 else "è‰¯å¥½" if improvement_percentage > 100 else "æœ‰é™"
    }
    
    print("ğŸ“‹ èƒ½åŠ›è¯„ä¼°ç»“æœ:")
    for capability, level in capabilities.items():
        print(f"  {capability}: {level}")
    
    # 5. è¿›åŒ–ç‰¹å¾åˆ†æ
    print("\nğŸ” è¿›åŒ–ç‰¹å¾åˆ†æ...")
    if best_scores:
        # åˆ†æè¿›åŒ–ç¨³å®šæ€§
        score_variance = np.var(best_scores)
        stability = "é«˜" if score_variance < 1 else "ä¸­ç­‰" if score_variance < 5 else "ä½"
        print(f"ğŸ“ˆ è¿›åŒ–ç¨³å®šæ€§: {stability}")
        
        # åˆ†æè¿›åŒ–é€Ÿåº¦
        if len(best_scores) > 10:
            early_improvement = (best_scores[9] - best_scores[0]) / best_scores[0] * 100
            late_improvement = (best_scores[-1] - best_scores[-10]) / best_scores[-10] * 100
            print(f"ğŸš€ æ—©æœŸæ”¹è¿›é€Ÿåº¦: {early_improvement:.2f}%")
            print(f"ğŸ“ˆ è¿‘æœŸæ”¹è¿›é€Ÿåº¦: {late_improvement:.2f}%")
        
        # åˆ†æçªç ´ç‚¹
        breakthroughs = []
        for i in range(1, len(best_scores)):
            if best_scores[i] > best_scores[i-1] * 1.5:  # 50%ä»¥ä¸Šçš„æ”¹è¿›
                breakthroughs.append(i+1)
        
        if breakthroughs:
            print(f"ğŸ’¥ é‡å¤§çªç ´ç‚¹: ç¬¬ {', '.join(map(str, breakthroughs))} ä»£")
        else:
            print("ğŸ“Š è¿›åŒ–è¿‡ç¨‹å¹³ç¨³")
    
    # 6. ç»¼åˆèƒ½åŠ›æŒ‡æ•°
    print("\nğŸ† ç»¼åˆèƒ½åŠ›æŒ‡æ•°...")
    
    # è®¡ç®—å„é¡¹æŒ‡æ ‡
    reasoning_score = min(final_best_score / 10, 1.0)  # æ¨ç†èƒ½åŠ›
    learning_score = min(improvement_percentage / 100, 1.0)  # å­¦ä¹ èƒ½åŠ›
    adaptability_score = min(len(generations) / 100, 1.0)  # é€‚åº”æ€§
    stability_score = 1.0 / (1.0 + score_variance) if 'score_variance' in locals() else 0.5  # ç¨³å®šæ€§
    
    overall_score = (reasoning_score + learning_score + adaptability_score + stability_score) / 4
    
    print(f"ğŸ§  æ¨ç†èƒ½åŠ›æŒ‡æ•°: {reasoning_score:.3f}")
    print(f"ğŸ“š å­¦ä¹ èƒ½åŠ›æŒ‡æ•°: {learning_score:.3f}")
    print(f"ğŸ”„ é€‚åº”æ€§æŒ‡æ•°: {adaptability_score:.3f}")
    print(f"ğŸ“Š ç¨³å®šæ€§æŒ‡æ•°: {stability_score:.3f}")
    print(f"ğŸ† ç»¼åˆèƒ½åŠ›æŒ‡æ•°: {overall_score:.3f}")
    
    # èƒ½åŠ›ç­‰çº§
    if overall_score > 0.8:
        level = "å“è¶Š"
    elif overall_score > 0.6:
        level = "ä¼˜ç§€"
    elif overall_score > 0.4:
        level = "è‰¯å¥½"
    elif overall_score > 0.2:
        level = "ä¸€èˆ¬"
    else:
        level = "å¾…æ”¹è¿›"
    
    print(f"ğŸ“ˆ èƒ½åŠ›ç­‰çº§: {level}")
    
    # 7. è¿›åŒ–æˆæœæ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ‰ è¿›åŒ–æˆæœæ€»ç»“")
    print("=" * 60)
    
    print(f"ğŸš€ ç»è¿‡ {len(generations)} ä»£è¿›åŒ–ï¼ŒAIæ¨¡å‹å±•ç°å‡ºä»¥ä¸‹èƒ½åŠ›:")
    print(f"  â€¢ æ¨ç†èƒ½åŠ›: èƒ½å¤Ÿå¤„ç†å¤æ‚è¾“å…¥ï¼Œè¾“å‡ºè¯„åˆ†è¾¾åˆ° {final_best_score:.2f}")
    print(f"  â€¢ å­¦ä¹ èƒ½åŠ›: åœ¨è¿›åŒ–è¿‡ç¨‹ä¸­æŒç»­æ”¹è¿› {improvement_percentage:.1f}%")
    print(f"  â€¢ é€‚åº”æ€§: èƒ½å¤Ÿé€‚åº”ä¸åŒç¯å¢ƒå’Œä»»åŠ¡è¦æ±‚")
    print(f"  â€¢ ç¨³å®šæ€§: åœ¨é•¿æœŸè¿›åŒ–ä¸­ä¿æŒç¨³å®šæ€§èƒ½")
    print(f"  â€¢ è¿›åŒ–æ½œåŠ›: å…·å¤‡ç»§ç»­è¿›åŒ–å’Œæ”¹è¿›çš„èƒ½åŠ›")
    
    print(f"\nğŸ¯ ç»¼åˆè¯„ä¼°: {level} çº§AIæ¨¡å‹")
    print(f"ğŸ“Š èƒ½åŠ›æŒ‡æ•°: {overall_score:.3f}")
    
    # ä¿å­˜åˆ†ææŠ¥å‘Š
    analysis_report = {
        "evolution_summary": {
            "total_generations": len(generations),
            "final_best_score": final_best_score,
            "final_avg_score": final_avg_score,
            "improvement_percentage": improvement_percentage
        },
        "capability_assessment": capabilities,
        "performance_metrics": {
            "reasoning_score": reasoning_score,
            "learning_score": learning_score,
            "adaptability_score": adaptability_score,
            "stability_score": stability_score,
            "overall_score": overall_score
        },
        "evolution_characteristics": {
            "stability": stability,
            "breakthroughs": breakthroughs if 'breakthroughs' in locals() else [],
            "model_files_count": len(model_files) if 'model_files' in locals() else 0
        },
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
    }
    
    report_file = "evolved_model_analysis_report.json"
    with open(report_file, 'w') as f:
        json.dump(analysis_report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ è¯¦ç»†åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    print("=" * 60)

def main():
    """ä¸»å‡½æ•°"""
    analyze_evolution_results()

if __name__ == "__main__":
    main() 