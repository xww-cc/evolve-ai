#!/usr/bin/env python3
"""
è§†è§‰æ¨¡å—æµ‹è¯•è„šæœ¬
æµ‹è¯•è§†è§‰ç¼–ç å™¨ã€æ¨ç†ã€ç©ºé—´ç†è§£å’Œè¿›åŒ–åŠŸèƒ½
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List
import time

# å¯¼å…¥è§†è§‰æ¨¡å—
from models.vision.vision_encoder import VisionEncoder, VisionAttention, VisionMemory
from models.vision.visual_reasoning import VisualReasoning
from models.vision.spatial_understanding import SpatialUnderstanding
from models.vision.vision_evolution import VisionEvolution
from evaluators.vision_evaluator import VisionEvaluator

def test_vision_encoder():
    """æµ‹è¯•è§†è§‰ç¼–ç å™¨"""
    print("ğŸ§ª æµ‹è¯•è§†è§‰ç¼–ç å™¨...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    channels = 3
    height = 224
    width = 224
    
    # æ¨¡æ‹Ÿå›¾åƒæ•°æ®
    test_images = torch.randn(batch_size, channels, height, width)
    
    # åˆ›å»ºè§†è§‰ç¼–ç å™¨
    vision_encoder = VisionEncoder(
        input_channels=channels,
        hidden_dim=256,
        num_layers=4,
        num_heads=8,
        dropout=0.1
    )
    
    # å‰å‘ä¼ æ’­
    start_time = time.time()
    outputs = vision_encoder(test_images)
    end_time = time.time()
    
    print(f"âœ… è§†è§‰ç¼–ç å™¨æµ‹è¯•é€šè¿‡")
    print(f"   è¾“å…¥å½¢çŠ¶: {test_images.shape}")
    print(f"   è¾“å‡ºç‰¹å¾å½¢çŠ¶: {outputs['features'].shape}")
    print(f"   æ¨ç†æ—¶é—´: {(end_time - start_time)*1000:.2f}ms")
    
    return outputs

def test_visual_reasoning():
    """æµ‹è¯•è§†è§‰æ¨ç†"""
    print("\nğŸ§ª æµ‹è¯•è§†è§‰æ¨ç†...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 10
    hidden_dim = 256
    
    test_features = torch.randn(batch_size, seq_len, hidden_dim)
    
    # åˆ›å»ºè§†è§‰æ¨ç†æ¨¡å—
    visual_reasoning = VisualReasoning(
        hidden_dim=hidden_dim,
        num_reasoning_layers=4,
        num_heads=8,
        dropout=0.1
    )
    
    # å‰å‘ä¼ æ’­
    start_time = time.time()
    outputs = visual_reasoning(test_features)
    end_time = time.time()
    
    print(f"âœ… è§†è§‰æ¨ç†æµ‹è¯•é€šè¿‡")
    print(f"   è¾“å…¥å½¢çŠ¶: {test_features.shape}")
    print(f"   æ¨ç†è¾“å‡ºå½¢çŠ¶: {outputs['reasoning_output'].shape}")
    print(f"   æ¨ç†æ—¶é—´: {(end_time - start_time)*1000:.2f}ms")
    
    return outputs

def test_spatial_understanding():
    """æµ‹è¯•ç©ºé—´ç†è§£"""
    print("\nğŸ§ª æµ‹è¯•ç©ºé—´ç†è§£...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 10
    hidden_dim = 256
    
    test_features = torch.randn(batch_size, seq_len, hidden_dim)
    
    # åˆ›å»ºç©ºé—´ç†è§£æ¨¡å—
    spatial_understanding = SpatialUnderstanding(
        hidden_dim=hidden_dim,
        num_spatial_relations=8,
        num_geometric_shapes=10,
        dropout=0.1
    )
    
    # å‰å‘ä¼ æ’­
    start_time = time.time()
    outputs = spatial_understanding(test_features)
    end_time = time.time()
    
    print(f"âœ… ç©ºé—´ç†è§£æµ‹è¯•é€šè¿‡")
    print(f"   è¾“å…¥å½¢çŠ¶: {test_features.shape}")
    print(f"   ç©ºé—´ç†è§£è¾“å‡ºå½¢çŠ¶: {outputs['spatial_understanding'].shape}")
    print(f"   æ¨ç†æ—¶é—´: {(end_time - start_time)*1000:.2f}ms")
    
    return outputs

def test_vision_evolution():
    """æµ‹è¯•è§†è§‰è¿›åŒ–"""
    print("\nğŸ§ª æµ‹è¯•è§†è§‰è¿›åŒ–...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 10
    hidden_dim = 256
    
    test_features = torch.randn(batch_size, seq_len, hidden_dim)
    
    # åˆ›å»ºè§†è§‰è¿›åŒ–æ¨¡å—
    vision_evolution = VisionEvolution(
        hidden_dim=hidden_dim,
        evolution_rate=0.01,
        mutation_rate=0.1,
        crossover_rate=0.8
    )
    
    # å‰å‘ä¼ æ’­
    start_time = time.time()
    outputs = vision_evolution(test_features)
    end_time = time.time()
    
    print(f"âœ… è§†è§‰è¿›åŒ–æµ‹è¯•é€šè¿‡")
    print(f"   è¾“å…¥å½¢çŠ¶: {test_features.shape}")
    print(f"   è¿›åŒ–è¾“å‡ºå½¢çŠ¶: {outputs['encoder_evolution'].shape}")
    print(f"   æ¨ç†æ—¶é—´: {(end_time - start_time)*1000:.2f}ms")
    
    # æµ‹è¯•è¿›åŒ–æ“ä½œ
    population = [torch.randn(seq_len, hidden_dim) for _ in range(5)]
    evolved_population = vision_evolution.evolve(population)
    
    print(f"   ç§ç¾¤è¿›åŒ–: {len(population)} -> {len(evolved_population)}")
    
    return outputs

def test_vision_evaluator():
    """æµ‹è¯•è§†è§‰è¯„ä¼°å™¨"""
    print("\nğŸ§ª æµ‹è¯•è§†è§‰è¯„ä¼°å™¨...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 10
    hidden_dim = 256
    
    test_features = torch.randn(batch_size, seq_len, hidden_dim)
    
    # åˆ›å»ºè§†è§‰è¯„ä¼°å™¨
    vision_evaluator = VisionEvaluator(
        hidden_dim=hidden_dim,
        num_classes=10,
        evaluation_dimensions=5
    )
    
    # å‰å‘ä¼ æ’­
    start_time = time.time()
    outputs = vision_evaluator(test_features)
    end_time = time.time()
    
    print(f"âœ… è§†è§‰è¯„ä¼°å™¨æµ‹è¯•é€šè¿‡")
    print(f"   è¾“å…¥å½¢çŠ¶: {test_features.shape}")
    print(f"   ç†è§£è¯„åˆ†: {outputs['understanding_score'].mean().item():.4f}")
    print(f"   æ¨ç†è¯„åˆ†: {outputs['reasoning_score'].mean().item():.4f}")
    print(f"   åˆ›é€ è¯„åˆ†: {outputs['creation_score'].mean().item():.4f}")
    print(f"   ç©ºé—´è¯„åˆ†: {outputs['spatial_score'].mean().item():.4f}")
    print(f"   ç»¼åˆè¯„åˆ†: {outputs['comprehensive_score'].mean().item():.4f}")
    print(f"   æ€»ä½“è¯„åˆ†: {outputs['overall_score'].mean().item():.4f}")
    print(f"   è¯„ä¼°æ—¶é—´: {(end_time - start_time)*1000:.2f}ms")
    
    return outputs

def test_integrated_vision_system():
    """æµ‹è¯•é›†æˆè§†è§‰ç³»ç»Ÿ"""
    print("\nğŸ§ª æµ‹è¯•é›†æˆè§†è§‰ç³»ç»Ÿ...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    channels = 3
    height = 224
    width = 224
    
    test_images = torch.randn(batch_size, channels, height, width)
    
    # åˆ›å»ºè§†è§‰ç³»ç»Ÿç»„ä»¶
    vision_encoder = VisionEncoder(hidden_dim=256)
    visual_reasoning = VisualReasoning(hidden_dim=256)
    spatial_understanding = SpatialUnderstanding(hidden_dim=256)
    vision_evolution = VisionEvolution(hidden_dim=256)
    vision_evaluator = VisionEvaluator(hidden_dim=256)
    
    # é›†æˆå¤„ç†æµç¨‹
    start_time = time.time()
    
    # 1. è§†è§‰ç¼–ç 
    encoder_outputs = vision_encoder(test_images)
    visual_features = encoder_outputs['features']
    
    # 2. è§†è§‰æ¨ç†
    reasoning_outputs = visual_reasoning(visual_features)
    
    # 3. ç©ºé—´ç†è§£
    spatial_outputs = spatial_understanding(visual_features)
    
    # 4. è§†è§‰è¿›åŒ–
    evolution_outputs = vision_evolution(visual_features)
    
    # 5. è§†è§‰è¯„ä¼°
    evaluation_outputs = vision_evaluator(visual_features)
    
    end_time = time.time()
    
    print(f"âœ… é›†æˆè§†è§‰ç³»ç»Ÿæµ‹è¯•é€šè¿‡")
    print(f"   å›¾åƒè¾“å…¥å½¢çŠ¶: {test_images.shape}")
    print(f"   è§†è§‰ç‰¹å¾å½¢çŠ¶: {visual_features.shape}")
    print(f"   æ¨ç†è¾“å‡ºå½¢çŠ¶: {reasoning_outputs['reasoning_output'].shape}")
    print(f"   ç©ºé—´ç†è§£å½¢çŠ¶: {spatial_outputs['spatial_understanding'].shape}")
    print(f"   è¿›åŒ–è¾“å‡ºå½¢çŠ¶: {evolution_outputs['encoder_evolution'].shape}")
    print(f"   æ€»ä½“è¯„åˆ†: {evaluation_outputs['overall_score'].mean().item():.4f}")
    print(f"   æ€»å¤„ç†æ—¶é—´: {(end_time - start_time)*1000:.2f}ms")
    
    return {
        'encoder_outputs': encoder_outputs,
        'reasoning_outputs': reasoning_outputs,
        'spatial_outputs': spatial_outputs,
        'evolution_outputs': evolution_outputs,
        'evaluation_outputs': evaluation_outputs
    }

def test_vision_performance():
    """æµ‹è¯•è§†è§‰æ€§èƒ½"""
    print("\nğŸ§ª æµ‹è¯•è§†è§‰æ€§èƒ½...")
    
    # åˆ›å»ºä¸åŒå¤§å°çš„æµ‹è¯•æ•°æ®
    test_sizes = [
        (1, 3, 224, 224),   # å°æ‰¹é‡
        (4, 3, 224, 224),   # ä¸­ç­‰æ‰¹é‡
        (8, 3, 224, 224),   # å¤§æ‰¹é‡
    ]
    
    vision_encoder = VisionEncoder(hidden_dim=256)
    vision_evaluator = VisionEvaluator(hidden_dim=256)
    
    for batch_size, channels, height, width in test_sizes:
        test_images = torch.randn(batch_size, channels, height, width)
        
        # æµ‹è¯•ç¼–ç å™¨æ€§èƒ½
        start_time = time.time()
        encoder_outputs = vision_encoder(test_images)
        encoder_time = time.time() - start_time
        
        # æµ‹è¯•è¯„ä¼°å™¨æ€§èƒ½
        start_time = time.time()
        evaluation_outputs = vision_evaluator(encoder_outputs['features'])
        evaluator_time = time.time() - start_time
        
        total_time = encoder_time + evaluator_time
        
        print(f"   æ‰¹é‡å¤§å°: {batch_size}")
        print(f"   ç¼–ç æ—¶é—´: {encoder_time*1000:.2f}ms")
        print(f"   è¯„ä¼°æ—¶é—´: {evaluator_time*1000:.2f}ms")
        print(f"   æ€»æ—¶é—´: {total_time*1000:.2f}ms")
        print(f"   è¯„åˆ†: {evaluation_outputs['overall_score'].mean().item():.4f}")
        print()

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è§†è§‰æ¨¡å—æµ‹è¯•")
    print("=" * 50)
    
    try:
        # æµ‹è¯•å„ä¸ªç»„ä»¶
        test_vision_encoder()
        test_visual_reasoning()
        test_spatial_understanding()
        test_vision_evolution()
        test_vision_evaluator()
        
        # æµ‹è¯•é›†æˆç³»ç»Ÿ
        test_integrated_vision_system()
        
        # æµ‹è¯•æ€§èƒ½
        test_vision_performance()
        
        print("\nğŸ‰ æ‰€æœ‰è§†è§‰æ¨¡å—æµ‹è¯•é€šè¿‡!")
        print("=" * 50)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        print("=" * 50)
        raise

if __name__ == "__main__":
    main() 