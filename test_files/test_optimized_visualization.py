#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–çš„å¯è§†åŒ–ç³»ç»Ÿ
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
import numpy as np
import torch
from models.advanced_reasoning_net import AdvancedReasoningNet
from utils.optimized_visualization import create_optimized_visualizer
from config.optimized_logging import setup_optimized_logging

logger = setup_optimized_logging()

async def test_optimized_visualization():
    """æµ‹è¯•ä¼˜åŒ–çš„å¯è§†åŒ–ç³»ç»Ÿ"""
    logger.log_important("ğŸ”” ğŸš€ å¯åŠ¨ä¼˜åŒ–å¯è§†åŒ–ç³»ç»Ÿæµ‹è¯•")
    
    try:
        # 1. åˆ›å»ºä¼˜åŒ–çš„å¯è§†åŒ–å™¨
        visualizer = create_optimized_visualizer(
            output_dir="test_optimized_plots",
            max_files=10,  # åªä¿ç•™10ä¸ªæ–‡ä»¶
            compression=True,  # å¯ç”¨å‹ç¼©
            dpi=120  # é™ä½DPIä»¥å‡å°æ–‡ä»¶å¤§å°
        )
        
        logger.log_important("ğŸ”” åˆ›å»ºä¼˜åŒ–å¯è§†åŒ–å™¨å®Œæˆ")
        
        # 2. åˆ›å»ºæµ‹è¯•ç§ç¾¤
        population = []
        for i in range(4):
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=256 + i * 32,  # ä¸åŒçš„éšè—å±‚å¤§å°
                reasoning_layers=5 + i,    # ä¸åŒçš„æ¨ç†å±‚æ•°
                attention_heads=8 + i,     # ä¸åŒçš„æ³¨æ„åŠ›å¤´æ•°
                memory_size=20,
                reasoning_types=10
            )
            population.append(model)
        
        logger.log_important(f"ğŸ”” åˆ›å»ºæµ‹è¯•ç§ç¾¤å®Œæˆï¼Œå…± {len(population)} ä¸ªä¸ªä½“")
        
        # 3. æ¨¡æ‹Ÿè¿›åŒ–è¿‡ç¨‹å¹¶è®°å½•æ•°æ®
        for generation in range(5):
            # ç”Ÿæˆæ¨¡æ‹Ÿçš„é€‚åº”åº¦åˆ†æ•°
            fitness_scores = []
            for i in range(len(population)):
                # æ¨¡æ‹Ÿè¿›åŒ–æ”¹è¿›
                base_score = 0.1 + generation * 0.05
                individual_score = base_score + np.random.normal(0, 0.02)
                fitness_scores.append(max(0.0, individual_score))
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            best_fitness = max(fitness_scores)
            avg_fitness = np.mean(fitness_scores)
            diversity = np.std(fitness_scores)  # ä½¿ç”¨æ ‡å‡†å·®ä½œä¸ºå¤šæ ·æ€§æŒ‡æ ‡
            
            # è®°å½•æ•°æ®ï¼ˆåŒ…å«æ•°æ®éªŒè¯å’Œæ¸…ç†ï¼‰
            visualizer.record_generation(
                generation=generation + 1,
                population=population,
                fitness_scores=fitness_scores,
                diversity=diversity,
                best_fitness=best_fitness,
                avg_fitness=avg_fitness
            )
            
            logger.log_important(f"ğŸ”” è®°å½•ç¬¬{generation + 1}ä»£æ•°æ®: æœ€ä½³={best_fitness:.4f}, å¹³å‡={avg_fitness:.4f}, å¤šæ ·æ€§={diversity:.4f}")
        
        # 4. ç”Ÿæˆä¼˜åŒ–çš„å¯è§†åŒ–
        logger.log_important("ğŸ”” å¼€å§‹ç”Ÿæˆä¼˜åŒ–å¯è§†åŒ–...")
        
        # ç”Ÿæˆè¿›åŒ–æ›²çº¿
        curves_file = visualizer.plot_evolution_curves_optimized()
        logger.log_important(f"ğŸ“Š ä¼˜åŒ–è¿›åŒ–æ›²çº¿: {curves_file}")
        
        # ç”Ÿæˆå¤šæ ·æ€§çƒ­åŠ›å›¾
        heatmap_file = visualizer.plot_diversity_heatmap_optimized()
        logger.log_important(f"ğŸ“Š ä¼˜åŒ–å¤šæ ·æ€§çƒ­åŠ›å›¾: {heatmap_file}")
        
        # ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
        report_file = visualizer.generate_optimized_evolution_report()
        logger.log_important(f"ğŸ“Š ä¼˜åŒ–è¿›åŒ–æŠ¥å‘Š: {report_file}")
        
        # ä¿å­˜ä¼˜åŒ–æ•°æ®
        data_file = visualizer.save_optimized_visualization_data()
        logger.log_important(f"ğŸ“Š ä¼˜åŒ–å¯è§†åŒ–æ•°æ®: {data_file}")
        
        # 5. è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        stats = visualizer.get_storage_statistics()
        logger.log_important(f"ğŸ“Š å­˜å‚¨ç»Ÿè®¡:")
        logger.log_important(f"   æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        logger.log_important(f"   æ€»å¤§å°: {stats['total_size_mb']:.2f} MB")
        logger.log_important(f"   å¹³å‡æ–‡ä»¶å¤§å°: {stats['avg_file_size_mb']:.2f} MB")
        logger.log_important(f"   å‹ç¼©å¯ç”¨: {stats['compression_enabled']}")
        logger.log_important(f"   æ–‡ä»¶é™åˆ¶: {stats['max_files_limit']}")
        
        # 6. éªŒè¯æ–‡ä»¶å¤§å°ä¼˜åŒ–
        import glob
        test_files = glob.glob("test_optimized_plots/*")
        
        if test_files:
            total_size = sum(os.path.getsize(f) for f in test_files)
            total_size_mb = total_size / (1024 * 1024)
            
            logger.log_important(f"ğŸ“Š æµ‹è¯•æ–‡ä»¶ç»Ÿè®¡:")
            logger.log_important(f"   æ–‡ä»¶æ•°é‡: {len(test_files)}")
            logger.log_important(f"   æ€»å¤§å°: {total_size_mb:.2f} MB")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å‹ç¼©æ–‡ä»¶
            compressed_files = [f for f in test_files if f.endswith('.gz')]
            if compressed_files:
                logger.log_success(f"âœ… å‹ç¼©åŠŸèƒ½æ­£å¸¸ï¼Œå‘ç° {len(compressed_files)} ä¸ªå‹ç¼©æ–‡ä»¶")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦åˆç†
            if total_size_mb < 2.0:  # å°äº2MB
                logger.log_success("âœ… æ–‡ä»¶å¤§å°ä¼˜åŒ–æˆåŠŸ")
            else:
                logger.log_warning(f"âš ï¸ æ–‡ä»¶å¤§å°è¾ƒå¤§: {total_size_mb:.2f} MB")
        
        logger.log_success("âœ… ä¼˜åŒ–å¯è§†åŒ–ç³»ç»Ÿæµ‹è¯•æˆåŠŸï¼")
        return True
        
    except Exception as e:
        logger.log_error(f"âŒ ä¼˜åŒ–å¯è§†åŒ–ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_data_quality_improvements():
    """æµ‹è¯•æ•°æ®è´¨é‡æ”¹è¿›"""
    logger.log_important("ğŸ”” æµ‹è¯•æ•°æ®è´¨é‡æ”¹è¿›...")
    
    try:
        visualizer = create_optimized_visualizer(
            output_dir="test_data_quality",
            max_files=5,
            compression=True,
            dpi=100
        )
        
        # æµ‹è¯•NaNå€¼å¤„ç†
        population = [AdvancedReasoningNet(4, 256, 5, 8, 20, 10) for _ in range(3)]
        
        # æ•…æ„åŒ…å«NaNå€¼çš„æ•°æ®
        fitness_scores_with_nan = [0.5, float('nan'), 0.7]
        best_fitness_with_nan = float('nan')
        avg_fitness_with_nan = 0.6
        diversity_with_nan = float('inf')
        
        # è®°å½•åŒ…å«NaNçš„æ•°æ®
        visualizer.record_generation(
            generation=1,
            population=population,
            fitness_scores=fitness_scores_with_nan,
            diversity=diversity_with_nan,
            best_fitness=best_fitness_with_nan,
            avg_fitness=avg_fitness_with_nan
        )
        
        # è®°å½•æ­£å¸¸æ•°æ®
        visualizer.record_generation(
            generation=2,
            population=population,
            fitness_scores=[0.5, 0.6, 0.7],
            diversity=0.1,
            best_fitness=0.7,
            avg_fitness=0.6
        )
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦è¢«æ­£ç¡®æ¸…ç†
        if len(visualizer.evolution_history) == 1:  # åªæœ‰ç¬¬2ä»£è¢«è®°å½•
            logger.log_success("âœ… NaNå€¼å¤„ç†æ­£å¸¸ï¼Œæ— æ•ˆæ•°æ®è¢«è·³è¿‡")
        else:
            logger.log_warning("âš ï¸ NaNå€¼å¤„ç†å¯èƒ½æœ‰é—®é¢˜")
        
        # æµ‹è¯•é‡å¤æ•°æ®æ£€æµ‹
        visualizer.record_generation(
            generation=3,
            population=population,
            fitness_scores=[0.5, 0.6, 0.7],  # ä¸ç¬¬2ä»£ç›¸åŒ
            diversity=0.1,
            best_fitness=0.7,
            avg_fitness=0.6
        )
        
        if len(visualizer.evolution_history) == 1:  # é‡å¤æ•°æ®è¢«è·³è¿‡
            logger.log_success("âœ… é‡å¤æ•°æ®æ£€æµ‹æ­£å¸¸")
        else:
            logger.log_warning("âš ï¸ é‡å¤æ•°æ®æ£€æµ‹å¯èƒ½æœ‰é—®é¢˜")
        
        return True
        
    except Exception as e:
        logger.log_error(f"âŒ æ•°æ®è´¨é‡æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»å‡½æ•°"""
    logger.log_important("=== ä¼˜åŒ–å¯è§†åŒ–ç³»ç»Ÿæµ‹è¯• ===")
    
    # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
    success1 = await test_optimized_visualization()
    
    # æµ‹è¯•æ•°æ®è´¨é‡æ”¹è¿›
    success2 = await test_data_quality_improvements()
    
    if success1 and success2:
        logger.log_success("ğŸ‰ æ‰€æœ‰ä¼˜åŒ–å¯è§†åŒ–æµ‹è¯•é€šè¿‡ï¼")
    else:
        logger.log_error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")

if __name__ == "__main__":
    asyncio.run(main()) 