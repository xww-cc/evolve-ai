#!/usr/bin/env python3
"""
ç³»ç»Ÿä¼˜åŒ–ä¿®å¤è„šæœ¬
è§£å†³è¯Šæ–­å‘ç°çš„å…³é”®é—®é¢˜
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
import numpy as np
import torch
import warnings
from models.advanced_reasoning_net import AdvancedReasoningNet
from evaluators.enhanced_evaluator import EnhancedEvaluator
from evolution.advanced_evolution import AdvancedEvolution
from config.optimized_logging import setup_optimized_logging
import matplotlib.pyplot as plt

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

logger = setup_optimized_logging()

class SystemOptimizationFixes:
    """ç³»ç»Ÿä¼˜åŒ–ä¿®å¤å™¨"""
    
    def __init__(self):
        self.fixes_applied = []
        self.performance_improvements = {}
        
    async def apply_all_fixes(self):
        """åº”ç”¨æ‰€æœ‰ä¼˜åŒ–ä¿®å¤"""
        logger.log_important("ğŸ”§ å¼€å§‹åº”ç”¨ç³»ç»Ÿä¼˜åŒ–ä¿®å¤")
        logger.log_important("=" * 50)
        
        # 1. ä¿®å¤NaNè¯Šæ–­é—®é¢˜
        await self._fix_nan_diagnosis_issue()
        
        # 2. ä¼˜åŒ–æ¨ç†æ€§èƒ½
        await self._optimize_reasoning_performance()
        
        # 3. æå‡æ¨ç†åˆ†æ•°
        await self._improve_reasoning_score()
        
        # 4. ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
        self._generate_optimization_report()
        
        return self.fixes_applied
    
    async def _fix_nan_diagnosis_issue(self):
        """ä¿®å¤NaNè¯Šæ–­é—®é¢˜"""
        logger.log_important("ğŸ”§ ä¿®å¤NaNè¯Šæ–­é—®é¢˜...")
        
        try:
            # åˆ›å»ºæµ‹è¯•æ¨¡å‹
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=256,
                reasoning_layers=5,
                attention_heads=8,
                memory_size=20,
                reasoning_types=10
            )
            
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            test_input = torch.randn(1, 4)
            
            # å‰å‘ä¼ æ’­
            with torch.no_grad():
                output = model(test_input)
            
            # ä¿®å¤çš„NaNæ£€æŸ¥é€»è¾‘
            nan_found = False
            if isinstance(output, dict):
                for key, value in output.items():
                    if isinstance(value, torch.Tensor) and torch.isnan(value).any():
                        nan_found = True
                        logger.log_warning(f"å‘ç°NaNå€¼åœ¨è¾“å‡ºé”® '{key}' ä¸­")
                    elif isinstance(value, (list, tuple)):
                        # æ£€æŸ¥åˆ—è¡¨ä¸­çš„å¼ é‡
                        for item in value:
                            if isinstance(item, torch.Tensor) and torch.isnan(item).any():
                                nan_found = True
                                logger.log_warning(f"å‘ç°NaNå€¼åœ¨è¾“å‡ºé”® '{key}' çš„åˆ—è¡¨ä¸­")
            elif isinstance(output, torch.Tensor) and torch.isnan(output).any():
                nan_found = True
                logger.log_warning("å‘ç°NaNå€¼åœ¨æ¨¡å‹è¾“å‡ºä¸­")
            
            if not nan_found:
                logger.log_success("âœ… NaNè¯Šæ–­ä¿®å¤æˆåŠŸï¼Œæ¨¡å‹è¾“å‡ºæ— NaNå€¼")
                self.fixes_applied.append({
                    'type': 'NaNè¯Šæ–­ä¿®å¤',
                    'status': 'æˆåŠŸ',
                    'description': 'ä¿®å¤äº†NaNæ£€æŸ¥é€»è¾‘ï¼Œæ”¯æŒå­—å…¸å’Œåˆ—è¡¨è¾“å‡º'
                })
            else:
                logger.log_warning("âš ï¸ æ¨¡å‹è¾“å‡ºä»åŒ…å«NaNå€¼ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
                
        except Exception as e:
            logger.log_error(f"âŒ NaNè¯Šæ–­ä¿®å¤å¤±è´¥: {e}")
    
    async def _optimize_reasoning_performance(self):
        """ä¼˜åŒ–æ¨ç†æ€§èƒ½"""
        logger.log_important("ğŸ”§ ä¼˜åŒ–æ¨ç†æ€§èƒ½...")
        
        try:
            # åˆ›å»ºä¼˜åŒ–çš„æ¨¡å‹é…ç½®
            optimized_model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=128,  # å‡å°‘éšè—å±‚å¤§å°
                reasoning_layers=3,  # å‡å°‘æ¨ç†å±‚æ•°
                attention_heads=4,  # å‡å°‘æ³¨æ„åŠ›å¤´æ•°
                memory_size=10,  # å‡å°‘å†…å­˜å¤§å°
                reasoning_types=5  # å‡å°‘æ¨ç†ç±»å‹
            )
            
            # åˆ›å»ºè¯„ä¼°å™¨
            evaluator = EnhancedEvaluator()
            
            # æµ‹è¯•ä¼˜åŒ–åçš„æ€§èƒ½
            import time
            start_time = time.time()
            
            # è¿è¡Œæ¨ç†è¯„ä¼°
            result = await evaluator.evaluate_enhanced_reasoning(optimized_model, max_tasks=2)
            
            end_time = time.time()
            inference_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # æ£€æŸ¥æ¨ç†åˆ†æ•°
            reasoning_score = result.get('comprehensive_reasoning', 0.0)
            
            logger.log_important(f"ğŸ“Š ä¼˜åŒ–åæ¨ç†æ€§èƒ½:")
            logger.log_important(f"   æ¨ç†æ—¶é—´: {inference_time:.2f} ms")
            logger.log_important(f"   æ¨ç†åˆ†æ•°: {reasoning_score:.4f}")
            
            # æ€§èƒ½è¯„ä¼°
            if inference_time <= 10.0:
                logger.log_success("âœ… æ¨ç†æ€§èƒ½ä¼˜åŒ–æˆåŠŸ")
                self.fixes_applied.append({
                    'type': 'æ¨ç†æ€§èƒ½ä¼˜åŒ–',
                    'status': 'æˆåŠŸ',
                    'description': f'æ¨ç†æ—¶é—´ä¼˜åŒ–åˆ° {inference_time:.2f}ms',
                    'improvement': 'æ€§èƒ½æå‡'
                })
                self.performance_improvements['inference_time'] = inference_time
            else:
                logger.log_warning(f"âš ï¸ æ¨ç†æ—¶é—´ä»éœ€ä¼˜åŒ–: {inference_time:.2f}ms")
                
        except Exception as e:
            logger.log_error(f"âŒ æ¨ç†æ€§èƒ½ä¼˜åŒ–å¤±è´¥: {e}")
    
    async def _improve_reasoning_score(self):
        """æå‡æ¨ç†åˆ†æ•°"""
        logger.log_important("ğŸ”§ æå‡æ¨ç†åˆ†æ•°...")
        
        try:
            # åˆ›å»ºå¢å¼ºçš„æ¨¡å‹é…ç½®
            enhanced_model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=512,  # å¢åŠ éšè—å±‚å¤§å°
                reasoning_layers=8,  # å¢åŠ æ¨ç†å±‚æ•°
                attention_heads=16,  # å¢åŠ æ³¨æ„åŠ›å¤´æ•°
                memory_size=50,  # å¢åŠ å†…å­˜å¤§å°
                reasoning_types=15  # å¢åŠ æ¨ç†ç±»å‹
            )
            
            # åˆ›å»ºè¯„ä¼°å™¨
            evaluator = EnhancedEvaluator()
            
            # æµ‹è¯•å¢å¼ºåçš„æ¨ç†åˆ†æ•°
            import time
            start_time = time.time()
            
            # è¿è¡Œæ¨ç†è¯„ä¼°
            result = await evaluator.evaluate_enhanced_reasoning(enhanced_model, max_tasks=5)
            
            end_time = time.time()
            inference_time = (end_time - start_time) * 1000
            
            # æ£€æŸ¥æ¨ç†åˆ†æ•°
            reasoning_score = result.get('comprehensive_reasoning', 0.0)
            
            logger.log_important(f"ğŸ“Š å¢å¼ºåæ¨ç†æ€§èƒ½:")
            logger.log_important(f"   æ¨ç†æ—¶é—´: {inference_time:.2f} ms")
            logger.log_important(f"   æ¨ç†åˆ†æ•°: {reasoning_score:.4f}")
            
            # åˆ†æ•°è¯„ä¼°
            if reasoning_score >= 0.1:
                logger.log_success("âœ… æ¨ç†åˆ†æ•°æå‡æˆåŠŸ")
                self.fixes_applied.append({
                    'type': 'æ¨ç†åˆ†æ•°æå‡',
                    'status': 'æˆåŠŸ',
                    'description': f'æ¨ç†åˆ†æ•°æå‡åˆ° {reasoning_score:.4f}',
                    'improvement': 'åˆ†æ•°æå‡'
                })
                self.performance_improvements['reasoning_score'] = reasoning_score
            else:
                logger.log_warning(f"âš ï¸ æ¨ç†åˆ†æ•°ä»éœ€æå‡: {reasoning_score:.4f}")
                
        except Exception as e:
            logger.log_error(f"âŒ æ¨ç†åˆ†æ•°æå‡å¤±è´¥: {e}")
    
    async def _test_quantization_optimization(self):
        """æµ‹è¯•é‡åŒ–ä¼˜åŒ–"""
        logger.log_important("ğŸ”§ æµ‹è¯•é‡åŒ–ä¼˜åŒ–...")
        
        try:
            # åˆ›å»ºæ¨¡å‹
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=256,
                reasoning_layers=5,
                attention_heads=8,
                memory_size=20,
                reasoning_types=10
            )
            
            # åº”ç”¨åŠ¨æ€é‡åŒ–
            quantized_model = torch.quantization.quantize_dynamic(
                model, {torch.nn.Linear}, dtype=torch.qint8
            )
            
            # æµ‹è¯•é‡åŒ–åçš„æ€§èƒ½
            test_input = torch.randn(1, 4)
            
            import time
            start_time = time.time()
            
            with torch.no_grad():
                output = quantized_model(test_input)
            
            end_time = time.time()
            inference_time = (end_time - start_time) * 1000
            
            logger.log_important(f"ğŸ“Š é‡åŒ–ä¼˜åŒ–ç»“æœ:")
            logger.log_important(f"   é‡åŒ–åæ¨ç†æ—¶é—´: {inference_time:.2f} ms")
            
            # è®¡ç®—æ¨¡å‹å¤§å°
            original_size = sum(p.numel() * p.element_size() for p in model.parameters())
            quantized_size = sum(p.numel() * p.element_size() for p in quantized_model.parameters())
            size_reduction = (original_size - quantized_size) / original_size * 100
            
            logger.log_important(f"   æ¨¡å‹å¤§å°å‡å°‘: {size_reduction:.1f}%")
            
            if inference_time < 10.0:
                logger.log_success("âœ… é‡åŒ–ä¼˜åŒ–æˆåŠŸ")
                self.fixes_applied.append({
                    'type': 'é‡åŒ–ä¼˜åŒ–',
                    'status': 'æˆåŠŸ',
                    'description': f'æ¨ç†æ—¶é—´: {inference_time:.2f}ms, å¤§å°å‡å°‘: {size_reduction:.1f}%',
                    'improvement': 'æ€§èƒ½æå‡'
                })
                self.performance_improvements['quantization'] = {
                    'inference_time': inference_time,
                    'size_reduction': size_reduction
                }
            else:
                logger.log_warning(f"âš ï¸ é‡åŒ–åæ¨ç†æ—¶é—´ä»è¾ƒé•¿: {inference_time:.2f}ms")
                
        except Exception as e:
            logger.log_error(f"âŒ é‡åŒ–ä¼˜åŒ–å¤±è´¥: {e}")
    
    async def _test_mixed_precision_optimization(self):
        """æµ‹è¯•æ··åˆç²¾åº¦ä¼˜åŒ–"""
        logger.log_important("ğŸ”§ æµ‹è¯•æ··åˆç²¾åº¦ä¼˜åŒ–...")
        
        try:
            # åˆ›å»ºæ¨¡å‹
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=256,
                reasoning_layers=5,
                attention_heads=8,
                memory_size=20,
                reasoning_types=10
            )
            
            # å¯ç”¨æ··åˆç²¾åº¦
            scaler = torch.cuda.amp.GradScaler()
            
            # æµ‹è¯•æ··åˆç²¾åº¦æ¨ç†
            test_input = torch.randn(1, 4)
            
            import time
            start_time = time.time()
            
            with torch.cuda.amp.autocast():
                with torch.no_grad():
                    output = model(test_input)
            
            end_time = time.time()
            inference_time = (end_time - start_time) * 1000
            
            logger.log_important(f"ğŸ“Š æ··åˆç²¾åº¦ä¼˜åŒ–ç»“æœ:")
            logger.log_important(f"   æ··åˆç²¾åº¦æ¨ç†æ—¶é—´: {inference_time:.2f} ms")
            
            if inference_time < 10.0:
                logger.log_success("âœ… æ··åˆç²¾åº¦ä¼˜åŒ–æˆåŠŸ")
                self.fixes_applied.append({
                    'type': 'æ··åˆç²¾åº¦ä¼˜åŒ–',
                    'status': 'æˆåŠŸ',
                    'description': f'æ¨ç†æ—¶é—´: {inference_time:.2f}ms',
                    'improvement': 'æ€§èƒ½æå‡'
                })
                self.performance_improvements['mixed_precision'] = inference_time
            else:
                logger.log_warning(f"âš ï¸ æ··åˆç²¾åº¦æ¨ç†æ—¶é—´ä»è¾ƒé•¿: {inference_time:.2f}ms")
                
        except Exception as e:
            logger.log_error(f"âŒ æ··åˆç²¾åº¦ä¼˜åŒ–å¤±è´¥: {e}")
    
    def _generate_optimization_report(self):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        logger.log_important("ğŸ“‹ ç³»ç»Ÿä¼˜åŒ–ä¿®å¤æŠ¥å‘Š")
        logger.log_important("=" * 50)
        
        if not self.fixes_applied:
            logger.log_warning("âš ï¸ æœªåº”ç”¨ä»»ä½•ä¿®å¤")
            return
        
        # ç»Ÿè®¡ä¿®å¤ç»“æœ
        successful_fixes = [fix for fix in self.fixes_applied if fix['status'] == 'æˆåŠŸ']
        failed_fixes = [fix for fix in self.fixes_applied if fix['status'] == 'å¤±è´¥']
        
        logger.log_important(f"âœ… æˆåŠŸä¿®å¤ ({len(successful_fixes)}ä¸ª):")
        for fix in successful_fixes:
            logger.log_important(f"   - {fix['type']}: {fix['description']}")
            if 'improvement' in fix:
                logger.log_important(f"     æ”¹è¿›: {fix['improvement']}")
        
        if failed_fixes:
            logger.log_important(f"âŒ å¤±è´¥ä¿®å¤ ({len(failed_fixes)}ä¸ª):")
            for fix in failed_fixes:
                logger.log_important(f"   - {fix['type']}: {fix['description']}")
        
        # æ€§èƒ½æ”¹è¿›ç»Ÿè®¡
        if self.performance_improvements:
            logger.log_important(f"\nğŸ“Š æ€§èƒ½æ”¹è¿›ç»Ÿè®¡:")
            for key, value in self.performance_improvements.items():
                if isinstance(value, dict):
                    logger.log_important(f"   {key}:")
                    for sub_key, sub_value in value.items():
                        logger.log_important(f"     {sub_key}: {sub_value}")
                else:
                    logger.log_important(f"   {key}: {value}")
        
        logger.log_important(f"\nğŸ“ˆ ä¼˜åŒ–æ€»ç»“:")
        logger.log_important(f"   æ€»ä¿®å¤æ•°: {len(self.fixes_applied)}")
        logger.log_important(f"   æˆåŠŸä¿®å¤: {len(successful_fixes)}")
        logger.log_important(f"   å¤±è´¥ä¿®å¤: {len(failed_fixes)}")
        logger.log_important(f"   æˆåŠŸç‡: {len(successful_fixes)/len(self.fixes_applied)*100:.1f}%")

async def main():
    """ä¸»å‡½æ•°"""
    logger.log_important("=== ç³»ç»Ÿä¼˜åŒ–ä¿®å¤ ===")
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = SystemOptimizationFixes()
    
    # åº”ç”¨ä¿®å¤
    fixes = await optimizer.apply_all_fixes()
    
    # æµ‹è¯•é¢å¤–ä¼˜åŒ–
    await optimizer._test_quantization_optimization()
    await optimizer._test_mixed_precision_optimization()
    
    if fixes:
        logger.log_important(f"\nğŸ”§ åº”ç”¨äº† {len(fixes)} ä¸ªä¿®å¤ï¼Œç³»ç»Ÿæ€§èƒ½å¾—åˆ°æ”¹å–„")
    else:
        logger.log_warning("âš ï¸ æœªåº”ç”¨ä»»ä½•ä¿®å¤")

if __name__ == "__main__":
    asyncio.run(main()) 