#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–å›å½’æµ‹è¯•ä½“ç³»è„šæœ¬
è‡ªåŠ¨è¯„æµ‹æ¨ç†åˆ†æ•°ã€ç¨³å®šæ€§ã€æ³›åŒ–èƒ½åŠ›ç­‰å¤šç»´åº¦ï¼Œè¾“å‡ºå›å½’æµ‹è¯•æŠ¥å‘Š
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import time
from models.advanced_reasoning_net import AdvancedReasoningNet
from evaluators.enhanced_evaluator import EnhancedEvaluator
from config.optimized_logging import setup_optimized_logging

logger = setup_optimized_logging()

class AutoRegressionTest:
    """è‡ªåŠ¨åŒ–å›å½’æµ‹è¯•ä½“ç³»"""
    def __init__(self):
        self.results = {}

    async def run(self):
        logger.log_important("ğŸ§ª è‡ªåŠ¨åŒ–å›å½’æµ‹è¯•å¼€å§‹")
        logger.log_important("=" * 60)
        evaluator = EnhancedEvaluator()
        # æµ‹è¯•æ¨¡å‹é…ç½®
        configs = [
            {'name': 'baseline', 'hidden_size': 128, 'reasoning_layers': 4, 'attention_heads': 8, 'memory_size': 10, 'reasoning_types': 10},
            {'name': 'best_gnn', 'hidden_size': 128, 'reasoning_layers': 4, 'attention_heads': 8, 'memory_size': 10, 'reasoning_types': 10},
            {'name': 'large', 'hidden_size': 512, 'reasoning_layers': 8, 'attention_heads': 8, 'memory_size': 30, 'reasoning_types': 20}
        ]
        # 1. æ¨ç†åˆ†æ•°æµ‹è¯•
        for cfg in configs:
            logger.log_important(f"\nğŸ”¬ æµ‹è¯•æ¨¡å‹: {cfg['name']}")
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=cfg['hidden_size'],
                reasoning_layers=cfg['reasoning_layers'],
                attention_heads=cfg['attention_heads'],
                memory_size=cfg['memory_size'],
                reasoning_types=cfg['reasoning_types']
            )
            optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
            # ç®€å•è®­ç»ƒ
            for epoch in range(3):
                train_data = torch.randn(20, 4)
                target_data = torch.randn(20)
                optimizer.zero_grad()
                output = model(train_data)
                if isinstance(output, dict):
                    loss = nn.MSELoss()(output['comprehensive_reasoning'], target_data)
                else:
                    loss = nn.MSELoss()(output, target_data)
                loss.backward()
                optimizer.step()
            # å¤šè½®æ¨ç†åˆ†æ•°
            scores = []
            for _ in range(5):
                result = await evaluator.evaluate_enhanced_reasoning(model, max_tasks=6)
                score = result.get('comprehensive_reasoning', 0.0)
                scores.append(score)
            mean_score = np.mean(scores)
            std_score = np.std(scores)
            logger.log_important(f"   å¹³å‡æ¨ç†åˆ†æ•°: {mean_score:.4f}ï¼Œæ ‡å‡†å·®: {std_score:.4f}")
            self.results[cfg['name']] = {'mean_score': mean_score, 'std_score': std_score, 'all_scores': scores}
        # 2. ç¨³å®šæ€§æµ‹è¯•
        logger.log_important("\nğŸ§· ç¨³å®šæ€§æµ‹è¯•")
        for name, res in self.results.items():
            stable = res['std_score'] < 0.01
            logger.log_important(f"   {name}: {'ç¨³å®š' if stable else 'æ³¢åŠ¨'} (std={res['std_score']:.4f})")
            self.results[name]['stable'] = stable
        # 3. æ³›åŒ–èƒ½åŠ›æµ‹è¯•ï¼ˆä¸åŒåˆ†å¸ƒè¾“å…¥ï¼‰
        logger.log_important("\nğŸŒ æ³›åŒ–èƒ½åŠ›æµ‹è¯•")
        for cfg in configs:
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=cfg['hidden_size'],
                reasoning_layers=cfg['reasoning_layers'],
                attention_heads=cfg['attention_heads'],
                memory_size=cfg['memory_size'],
                reasoning_types=cfg['reasoning_types']
            )
            # ä¸åŒåˆ†å¸ƒè¾“å…¥
            test_inputs = [
                torch.randn(10, 4),
                torch.rand(10, 4),
                torch.abs(torch.randn(10, 4)),
                torch.ones(10, 4),
                torch.zeros(10, 4)
            ]
            gen_scores = []
            for inp in test_inputs:
                with torch.no_grad():
                    out = model(inp)
                if isinstance(out, dict):
                    score = out['comprehensive_reasoning'].mean().item()
                else:
                    score = out.mean().item()
                gen_scores.append(score)
            logger.log_important(f"   {cfg['name']} æ³›åŒ–åˆ†å¸ƒè¾“å‡º: {np.round(gen_scores, 4)}")
            self.results[cfg['name']]['generalization'] = gen_scores
        # 4. æ€§èƒ½ä¸æ•ˆç‡æµ‹è¯•
        logger.log_important("\nâš¡ æ€§èƒ½ä¸æ•ˆç‡æµ‹è¯•")
        for cfg in configs:
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=cfg['hidden_size'],
                reasoning_layers=cfg['reasoning_layers'],
                attention_heads=cfg['attention_heads'],
                memory_size=cfg['memory_size'],
                reasoning_types=cfg['reasoning_types']
            )
            test_input = torch.randn(1, 4)
            with torch.no_grad():
                for _ in range(3):
                    _ = model(test_input)
            start_time = time.time()
            with torch.no_grad():
                for _ in range(10):
                    _ = model(test_input)
            end_time = time.time()
            avg_time = (end_time - start_time) / 10 * 1000
            logger.log_important(f"   {cfg['name']} å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.2f}ms")
            self.results[cfg['name']]['inference_time'] = avg_time
        # 5. è¾“å‡ºå›å½’æµ‹è¯•æŠ¥å‘Š
        self._generate_report()
        return self.results

    def _generate_report(self):
        logger.log_important("\nğŸ“‹ è‡ªåŠ¨åŒ–å›å½’æµ‹è¯•æŠ¥å‘Š")
        logger.log_important("=" * 60)
        for name, res in self.results.items():
            logger.log_important(f"\næ¨¡å‹: {name}")
            logger.log_important(f"   å¹³å‡æ¨ç†åˆ†æ•°: {res['mean_score']:.4f}")
            logger.log_important(f"   åˆ†æ•°æ ‡å‡†å·®: {res['std_score']:.4f}")
            logger.log_important(f"   ç¨³å®šæ€§: {'ç¨³å®š' if res['stable'] else 'æ³¢åŠ¨'}")
            logger.log_important(f"   æ³›åŒ–åˆ†å¸ƒè¾“å‡º: {np.round(res['generalization'], 4)}")
            logger.log_important(f"   å¹³å‡æ¨ç†æ—¶é—´: {res['inference_time']:.2f}ms")
        logger.log_important("\nğŸ¯ å›å½’æµ‹è¯•å®Œæˆï¼")

async def main():
    logger.log_important("=== è‡ªåŠ¨åŒ–å›å½’æµ‹è¯•ä½“ç³» ===")
    tester = AutoRegressionTest()
    results = await tester.run()
    logger.log_important(f"\nğŸ‰ è‡ªåŠ¨åŒ–å›å½’æµ‹è¯•å…¨éƒ¨å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main()) 