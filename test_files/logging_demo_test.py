#!/usr/bin/env python3
"""
æ—¥å¿—ç³»ç»Ÿæ¼”ç¤ºæµ‹è¯• - å±•ç¤ºä¼˜åŒ–çš„æ—¥å¿—è¾“å‡º
"""

import asyncio
import time
import torch
import numpy as np
from evolution.population import create_initial_population
from evaluators.realworld_evaluator import RealWorldEvaluator
from evaluators.symbolic_evaluator import SymbolicEvaluator
from evaluators.complex_reasoning_evaluator import ComplexReasoningEvaluator
from config.optimized_logging import setup_optimized_logging

# è®¾ç½®ä¼˜åŒ–çš„æ—¥å¿—ç³»ç»Ÿ
logger = setup_optimized_logging()

async def logging_demo_test():
    """æ—¥å¿—ç³»ç»Ÿæ¼”ç¤ºæµ‹è¯•"""
    logger.log_important("ğŸ§¬ æ—¥å¿—ç³»ç»Ÿæ¼”ç¤ºæµ‹è¯•å¼€å§‹")
    logger.log_important("=" * 50)
    
    start_time = time.time()
    
    try:
        # 1. ç³»ç»Ÿåˆå§‹åŒ–
        logger.log_important("ğŸ”§ åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")
        population = create_initial_population(4)
        realworld_evaluator = RealWorldEvaluator()
        symbolic_evaluator = SymbolicEvaluator()
        complex_evaluator = ComplexReasoningEvaluator()
        
        # 2. åˆå§‹è¯„ä¼°
        logger.log_important("ğŸ“Š æ‰§è¡Œåˆå§‹è¯„ä¼°...")
        initial_results = await evaluate_population_with_logging(
            population, symbolic_evaluator, realworld_evaluator, complex_evaluator, 0
        )
        
        # è®°å½•åˆå§‹ç»“æœ
        log_comprehensive_results("åˆå§‹", initial_results)
        
        # 3. è¿›åŒ–æµ‹è¯•
        logger.log_important("ğŸ”„ æ‰§è¡Œè¿›åŒ–æµ‹è¯•...")
        
        # æ‰‹åŠ¨æ¨¡æ‹Ÿè¿›åŒ–è¿‡ç¨‹
        evolved_population = []
        for i, model in enumerate(population):
            # ç®€å•çš„æ¨¡å‹å¤åˆ¶å’Œè½»å¾®ä¿®æ”¹
            evolved_model = copy_model_with_slight_modification(model)
            evolved_population.append(evolved_model)
        
        # è¿›åŒ–åè¯„ä¼°
        evolved_results = await evaluate_population_with_logging(
            evolved_population, symbolic_evaluator, realworld_evaluator, complex_evaluator, 1
        )
        
        # è®°å½•è¿›åŒ–ç»“æœ
        log_comprehensive_results("è¿›åŒ–å", evolved_results)
        
        # è®¡ç®—æ”¹è¿›
        improvements = calculate_improvements(initial_results, evolved_results)
        logger.log_evolution_summary(1, improvements)
        
        # 4. ç³»ç»Ÿæ€§èƒ½ç›‘æ§
        system_metrics = get_system_metrics()
        logger.log_performance_metrics(system_metrics)
        
        # 5. æ€»ç»“
        total_time = time.time() - start_time
        logger.log_success(f"æµ‹è¯•å®Œæˆï¼æ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        # è®¡ç®—æ€»ä½“æ”¹è¿›
        total_improvements = calculate_improvements(initial_results, evolved_results)
        logger.log_evolution_summary(-1, total_improvements)
        
        return True
        
    except Exception as e:
        logger.log_error(f"æµ‹è¯•å¤±è´¥: {e}", "æ—¥å¿—æ¼”ç¤ºæµ‹è¯•")
        return False

def copy_model_with_slight_modification(model):
    """å¤åˆ¶æ¨¡å‹å¹¶è¿›è¡Œè½»å¾®ä¿®æ”¹"""
    try:
        # åˆ›å»ºæ–°æ¨¡å‹å®ä¾‹
        new_model = type(model)(model.modules_config, model.epigenetic_markers)
        
        # å¤åˆ¶å‚æ•°å¹¶æ·»åŠ è½»å¾®å™ªå£°
        for param, new_param in zip(model.parameters(), new_model.parameters()):
            with torch.no_grad():
                noise = torch.randn_like(param) * 0.01  # 1%çš„å™ªå£°
                new_param.copy_(param + noise)
        
        return new_model
    except Exception as e:
        logger.log_warning(f"æ¨¡å‹å¤åˆ¶å¤±è´¥: {e}")
        return model

async def evaluate_population_with_logging(population, symbolic_evaluator, 
                                         realworld_evaluator, complex_evaluator, level):
    """å¸¦æ—¥å¿—çš„ç§ç¾¤è¯„ä¼°"""
    results = {
        'symbolic_scores': [],
        'realworld_scores': [],
        'complex_scores': {
            'mathematical_logic': [],
            'symbolic_reasoning': [],
            'abstract_reasoning': [],
            'pattern_recognition': [],
            'reasoning_chain': []
        },
        'model_ids': []
    }
    
    for i, model in enumerate(population):
        model_id = f"M{i+1:02d}"
        results['model_ids'].append(model_id)
        
        try:
            # åŸºç¡€è¯„ä¼°
            symbolic_score = await symbolic_evaluator.evaluate(model, level)
            realworld_score = await realworld_evaluator.evaluate(model)
            
            results['symbolic_scores'].append(symbolic_score)
            results['realworld_scores'].append(realworld_score)
            
            # å¤æ‚æ¨ç†è¯„ä¼°
            complex_scores = await complex_evaluator.evaluate_complex_reasoning(model, level)
            
            for key in results['complex_scores']:
                results['complex_scores'][key].append(complex_scores.get(key, 0.0))
            
            # è®°å½•å•ä¸ªæ¨¡å‹ç»“æœ - ä½¿ç”¨ä¼˜åŒ–çš„æ—¥å¿—
            logger.log_evaluation_results(model_id, symbolic_score, realworld_score, complex_scores)
            
        except Exception as e:
            logger.log_warning(f"æ¨¡å‹ {model_id} è¯„ä¼°å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤å€¼
            results['symbolic_scores'].append(0.0)
            results['realworld_scores'].append(0.0)
            for key in results['complex_scores']:
                results['complex_scores'][key].append(0.0)
    
    return results

def log_comprehensive_results(stage: str, results: dict):
    """è®°å½•ç»¼åˆè¯„ä¼°ç»“æœ"""
    # è®¡ç®—å¹³å‡åˆ†
    avg_symbolic = np.mean(results['symbolic_scores'])
    avg_realworld = np.mean(results['realworld_scores'])
    
    avg_complex = {}
    for key, scores in results['complex_scores'].items():
        avg_complex[key] = np.mean(scores)
    
    # è®°å½•ç»“æœ - ä½¿ç”¨ä¼˜åŒ–çš„æ—¥å¿—
    logger.log_important(f"ğŸ“Š {stage}è¯„ä¼°ç»“æœ:")
    logger.log_important(f"   ç¬¦å·æ¨ç†: {avg_symbolic:.3f}")
    logger.log_important(f"   çœŸå®ä¸–ç•Œ: {avg_realworld:.3f}")
    
    complex_str = " | ".join([f"{k}: {v:.3f}" for k, v in avg_complex.items()])
    logger.log_important(f"   å¤æ‚æ¨ç†: {complex_str}")

def calculate_improvements(initial_results: dict, final_results: dict) -> dict:
    """è®¡ç®—æ”¹è¿›å¹…åº¦"""
    improvements = {}
    
    # åŸºç¡€æŒ‡æ ‡æ”¹è¿›
    initial_symbolic = np.mean(initial_results['symbolic_scores'])
    final_symbolic = np.mean(final_results['symbolic_scores'])
    improvements['ç¬¦å·æ¨ç†'] = final_symbolic - initial_symbolic
    
    initial_realworld = np.mean(initial_results['realworld_scores'])
    final_realworld = np.mean(final_results['realworld_scores'])
    improvements['çœŸå®ä¸–ç•Œ'] = final_realworld - initial_realworld
    
    # å¤æ‚æ¨ç†æ”¹è¿›
    for key in initial_results['complex_scores']:
        initial_avg = np.mean(initial_results['complex_scores'][key])
        final_avg = np.mean(final_results['complex_scores'][key])
        improvements[f'å¤æ‚æ¨ç†_{key}'] = final_avg - initial_avg
    
    return improvements

def get_system_metrics() -> dict:
    """è·å–ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
    try:
        import psutil
        # å†…å­˜ä½¿ç”¨ç‡
        memory = psutil.virtual_memory()
        memory_usage = memory.percent
        
        # CPUä½¿ç”¨ç‡
        cpu_usage = psutil.cpu_percent(interval=1)
        
        # å…¶ä»–æŒ‡æ ‡
        metrics = {
            'memory_usage': memory_usage,
            'cpu_usage': cpu_usage,
            'available_memory_gb': memory.available / (1024**3),
            'total_memory_gb': memory.total / (1024**3)
        }
        
        return metrics
    except Exception as e:
        logger.log_warning(f"æ— æ³•è·å–ç³»ç»ŸæŒ‡æ ‡: {e}")
        return {'memory_usage': 0.0, 'cpu_usage': 0.0}

async def main():
    """ä¸»å‡½æ•°"""
    logger.log_important("ğŸš€ å¯åŠ¨æ—¥å¿—ç³»ç»Ÿæ¼”ç¤ºæµ‹è¯•")
    
    success = await logging_demo_test()
    
    if success:
        logger.log_success("ğŸ‰ æ—¥å¿—ç³»ç»Ÿæ¼”ç¤ºæµ‹è¯•æˆåŠŸå®Œæˆï¼")
        logger.log_important("âœ… ä¼˜åŒ–æ—¥å¿—ç³»ç»Ÿå·¥ä½œæ­£å¸¸")
        logger.log_important("âœ… å…³é”®ä¿¡æ¯è¾“å‡ºæ¸…æ™°")
        logger.log_important("âœ… æ€§èƒ½ç›‘æ§æœ‰æ•ˆ")
    else:
        logger.log_error("âš ï¸ æ—¥å¿—ç³»ç»Ÿæ¼”ç¤ºæµ‹è¯•éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")

if __name__ == "__main__":
    asyncio.run(main()) 