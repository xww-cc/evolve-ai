#!/usr/bin/env python3
"""
æ·±åº¦é—®é¢˜åˆ†æè„šæœ¬
æ·±å…¥åˆ†ææ¨ç†åˆ†æ•°ä½çš„åŸå› å’Œæ ¹æœ¬é—®é¢˜
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import time
from models.advanced_reasoning_net import AdvancedReasoningNet
from evaluators.enhanced_evaluator import EnhancedEvaluator
from config.optimized_logging import setup_optimized_logging
import matplotlib.pyplot as plt

logger = setup_optimized_logging()

class DeepProblemAnalysis:
    """æ·±åº¦é—®é¢˜åˆ†æå™¨"""
    
    def __init__(self):
        self.analysis_results = {}
        self.problems_found = []
        self.solutions_proposed = []
        
    async def run_deep_analysis(self):
        """è¿è¡Œæ·±åº¦é—®é¢˜åˆ†æ"""
        logger.log_important("ğŸ” å¼€å§‹æ·±åº¦é—®é¢˜åˆ†æ")
        logger.log_important("=" * 60)
        
        # 1. æ¨¡å‹æ¶æ„åˆ†æ
        await self._analyze_model_architecture()
        
        # 2. è¯„ä¼°å™¨åˆ†æ
        await self._analyze_evaluator()
        
        # 3. è®­ç»ƒç­–ç•¥åˆ†æ
        await self._analyze_training_strategy()
        
        # 4. æ•°æ®æµåˆ†æ
        await self._analyze_data_flow()
        
        # 5. æ€§èƒ½ç“¶é¢ˆåˆ†æ
        await self._analyze_performance_bottlenecks()
        
        # 6. ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š
        self._generate_deep_analysis_report()
        
        return self.analysis_results
    
    async def _analyze_model_architecture(self):
        """åˆ†ææ¨¡å‹æ¶æ„é—®é¢˜"""
        logger.log_important("ğŸ—ï¸ 1. æ¨¡å‹æ¶æ„åˆ†æ")
        logger.log_important("-" * 40)
        
        architecture_issues = []
        
        # åˆ†æ1: æ£€æŸ¥æ¨¡å‹è¾“å‡ºç»“æ„
        try:
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=512,
                reasoning_layers=6,
                attention_heads=8,
                memory_size=50,
                reasoning_types=15
            )
            
            test_input = torch.randn(1, 4)
            with torch.no_grad():
                output = model(test_input)
            
            # åˆ†æè¾“å‡ºç»“æ„
            if isinstance(output, dict):
                output_keys = list(output.keys())
                logger.log_important(f"   æ¨¡å‹è¾“å‡ºé”®: {output_keys}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰comprehensive_reasoningé”®
                if 'comprehensive_reasoning' in output:
                    reasoning_output = output['comprehensive_reasoning']
                    logger.log_important(f"   æ¨ç†è¾“å‡ºå½¢çŠ¶: {reasoning_output.shape}")
                    logger.log_important(f"   æ¨ç†è¾“å‡ºå€¼èŒƒå›´: [{reasoning_output.min():.4f}, {reasoning_output.max():.4f}]")
                    logger.log_important(f"   æ¨ç†è¾“å‡ºå‡å€¼: {reasoning_output.mean():.4f}")
                    logger.log_important(f"   æ¨ç†è¾“å‡ºæ ‡å‡†å·®: {reasoning_output.std():.4f}")
                    
                    # æ£€æŸ¥è¾“å‡ºæ˜¯å¦è¿‡äºé›†ä¸­
                    if reasoning_output.std() < 0.01:
                        architecture_issues.append("æ¨ç†è¾“å‡ºæ–¹å·®è¿‡å°ï¼Œæ¨¡å‹å¯èƒ½æ¬ æ‹Ÿåˆ")
                    
                    if abs(reasoning_output.mean()) > 0.5:
                        architecture_issues.append("æ¨ç†è¾“å‡ºå‡å€¼åç¦»0ï¼Œå¯èƒ½å­˜åœ¨åå·®")
                else:
                    architecture_issues.append("æ¨¡å‹è¾“å‡ºç¼ºå°‘comprehensive_reasoningé”®")
            else:
                logger.log_important(f"   æ¨¡å‹è¾“å‡ºç±»å‹: {type(output)}")
                logger.log_important(f"   æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}")
                architecture_issues.append("æ¨¡å‹è¾“å‡ºä¸æ˜¯å­—å…¸æ ¼å¼ï¼Œå¯èƒ½å½±å“è¯„ä¼°")
            
        except Exception as e:
            architecture_issues.append(f"æ¨¡å‹æ¶æ„åˆ†æå¤±è´¥: {e}")
        
        # åˆ†æ2: æ£€æŸ¥æ¨¡å‹å‚æ•°
        try:
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            
            logger.log_important(f"   æ€»å‚æ•°æ•°é‡: {total_params:,}")
            logger.log_important(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
            
            if total_params < 10000:
                architecture_issues.append("æ¨¡å‹å‚æ•°è¿‡å°‘ï¼Œå¯èƒ½å®¹é‡ä¸è¶³")
            elif total_params > 1000000:
                architecture_issues.append("æ¨¡å‹å‚æ•°è¿‡å¤šï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆé£é™©")
                
        except Exception as e:
            architecture_issues.append(f"å‚æ•°åˆ†æå¤±è´¥: {e}")
        
        # åˆ†æ3: æ£€æŸ¥æ¢¯åº¦æµ
        try:
            test_input = torch.randn(1, 4)
            output = model(test_input)
            
            if isinstance(output, dict):
                loss = nn.MSELoss()(output['comprehensive_reasoning'], torch.tensor([0.5]))
            else:
                loss = nn.MSELoss()(output, torch.randn_like(output))
            
            loss.backward()
            
            # æ£€æŸ¥æ¢¯åº¦
            grad_norms = []
            for name, param in model.named_parameters():
                if param.grad is not None:
                    grad_norm = param.grad.norm().item()
                    grad_norms.append(grad_norm)
                    if grad_norm < 1e-6:
                        logger.log_warning(f"   å‚æ•° {name} æ¢¯åº¦è¿‡å°: {grad_norm:.2e}")
            
            if grad_norms:
                avg_grad_norm = np.mean(grad_norms)
                logger.log_important(f"   å¹³å‡æ¢¯åº¦èŒƒæ•°: {avg_grad_norm:.2e}")
                
                if avg_grad_norm < 1e-4:
                    architecture_issues.append("æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œæ¨¡å‹å¯èƒ½æ— æ³•æœ‰æ•ˆå­¦ä¹ ")
                elif avg_grad_norm > 10:
                    architecture_issues.append("æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œè®­ç»ƒå¯èƒ½ä¸ç¨³å®š")
                    
        except Exception as e:
            architecture_issues.append(f"æ¢¯åº¦åˆ†æå¤±è´¥: {e}")
        
        self.analysis_results['model_architecture'] = {
            'issues': architecture_issues,
            'total_issues': len(architecture_issues)
        }
        
        logger.log_important(f"ğŸ“Š æ¨¡å‹æ¶æ„é—®é¢˜: {len(architecture_issues)} ä¸ª")
        for issue in architecture_issues:
            logger.log_warning(f"   âš ï¸ {issue}")
    
    async def _analyze_evaluator(self):
        """åˆ†æè¯„ä¼°å™¨é—®é¢˜"""
        logger.log_important("\nğŸ“Š 2. è¯„ä¼°å™¨åˆ†æ")
        logger.log_important("-" * 40)
        
        evaluator_issues = []
        
        try:
            evaluator = EnhancedEvaluator()
            
            # åˆ†æ1: æ£€æŸ¥è¯„ä¼°ä»»åŠ¡
            logger.log_important("   åˆ†æè¯„ä¼°ä»»åŠ¡...")
            
            # åˆ›å»ºæµ‹è¯•æ¨¡å‹
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=256,
                reasoning_layers=4,
                attention_heads=8,
                memory_size=20,
                reasoning_types=10
            )
            
            # æµ‹è¯•å•ä¸ªä»»åŠ¡
            start_time = time.time()
            result = await evaluator.evaluate_enhanced_reasoning(model, max_tasks=1)
            end_time = time.time()
            
            logger.log_important(f"   å•ä¸ªä»»åŠ¡è¯„ä¼°æ—¶é—´: {(end_time - start_time)*1000:.2f}ms")
            logger.log_important(f"   è¯„ä¼°ç»“æœ: {result}")
            
            # åˆ†æç»“æœç»“æ„
            if isinstance(result, dict):
                result_keys = list(result.keys())
                logger.log_important(f"   è¯„ä¼°ç»“æœé”®: {result_keys}")
                
                # æ£€æŸ¥comprehensive_reasoning
                if 'comprehensive_reasoning' in result:
                    reasoning_score = result['comprehensive_reasoning']
                    logger.log_important(f"   æ¨ç†åˆ†æ•°: {reasoning_score:.4f}")
                    
                    # åˆ†æåˆ†æ•°åˆ†å¸ƒ
                    if reasoning_score < 0.01:
                        evaluator_issues.append("æ¨ç†åˆ†æ•°è¿‡ä½ï¼Œå¯èƒ½è¯„ä¼°æ ‡å‡†è¿‡äºä¸¥æ ¼")
                    elif reasoning_score > 0.9:
                        evaluator_issues.append("æ¨ç†åˆ†æ•°è¿‡é«˜ï¼Œå¯èƒ½è¯„ä¼°æ ‡å‡†è¿‡äºå®½æ¾")
                else:
                    evaluator_issues.append("è¯„ä¼°ç»“æœç¼ºå°‘comprehensive_reasoningé”®")
            else:
                evaluator_issues.append("è¯„ä¼°ç»“æœä¸æ˜¯å­—å…¸æ ¼å¼")
            
            # åˆ†æ2: æ£€æŸ¥ä»»åŠ¡å¤šæ ·æ€§
            logger.log_important("   åˆ†æä»»åŠ¡å¤šæ ·æ€§...")
            
            # å¤šæ¬¡è¯„ä¼°æ£€æŸ¥ä¸€è‡´æ€§
            scores = []
            for i in range(5):
                result = await evaluator.evaluate_enhanced_reasoning(model, max_tasks=1)
                if isinstance(result, dict) and 'comprehensive_reasoning' in result:
                    scores.append(result['comprehensive_reasoning'])
            
            if scores:
                score_std = np.std(scores)
                logger.log_important(f"   å¤šæ¬¡è¯„ä¼°åˆ†æ•°: {[f'{s:.4f}' for s in scores]}")
                logger.log_important(f"   åˆ†æ•°æ ‡å‡†å·®: {score_std:.4f}")
                
                if score_std < 0.001:
                    evaluator_issues.append("è¯„ä¼°ç»“æœè¿‡äºä¸€è‡´ï¼Œå¯èƒ½ä»»åŠ¡ç¼ºä¹å¤šæ ·æ€§")
                elif score_std > 0.1:
                    evaluator_issues.append("è¯„ä¼°ç»“æœæ³¢åŠ¨è¿‡å¤§ï¼Œå¯èƒ½ä»»åŠ¡è¿‡äºéšæœº")
            
        except Exception as e:
            evaluator_issues.append(f"è¯„ä¼°å™¨åˆ†æå¤±è´¥: {e}")
        
        self.analysis_results['evaluator'] = {
            'issues': evaluator_issues,
            'total_issues': len(evaluator_issues)
        }
        
        logger.log_important(f"ğŸ“Š è¯„ä¼°å™¨é—®é¢˜: {len(evaluator_issues)} ä¸ª")
        for issue in evaluator_issues:
            logger.log_warning(f"   âš ï¸ {issue}")
    
    async def _analyze_training_strategy(self):
        """åˆ†æè®­ç»ƒç­–ç•¥é—®é¢˜"""
        logger.log_important("\nğŸ“ 3. è®­ç»ƒç­–ç•¥åˆ†æ")
        logger.log_important("-" * 40)
        
        training_issues = []
        
        try:
            # åˆ›å»ºæ¨¡å‹
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=256,
                reasoning_layers=4,
                attention_heads=8,
                memory_size=20,
                reasoning_types=10
            )
            
            # åˆ†æ1: æŸå¤±å‡½æ•°åˆ†æ
            logger.log_important("   åˆ†ææŸå¤±å‡½æ•°...")
            
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            train_data = torch.randn(10, 4)
            target_data = torch.randn(10, 4)
            
            # æµ‹è¯•ä¸åŒæŸå¤±å‡½æ•°
            loss_functions = [
                ('MSE', nn.MSELoss()),
                ('MAE', nn.L1Loss()),
                ('Huber', nn.HuberLoss()),
                ('SmoothL1', nn.SmoothL1Loss())
            ]
            
            for loss_name, loss_fn in loss_functions:
                output = model(train_data)
                
                if isinstance(output, dict):
                    loss = loss_fn(output['comprehensive_reasoning'], target_data[:, 0])
                else:
                    loss = loss_fn(output, target_data)
                
                logger.log_important(f"   {loss_name} æŸå¤±: {loss.item():.4f}")
            
            # åˆ†æ2: ä¼˜åŒ–å™¨åˆ†æ
            logger.log_important("   åˆ†æä¼˜åŒ–å™¨...")
            
            optimizers = [
                ('Adam', optim.Adam(model.parameters(), lr=0.001)),
                ('AdamW', optim.AdamW(model.parameters(), lr=0.001)),
                ('SGD', optim.SGD(model.parameters(), lr=0.01)),
                ('RMSprop', optim.RMSprop(model.parameters(), lr=0.001))
            ]
            
            for opt_name, optimizer in optimizers:
                optimizer.zero_grad()
                output = model(train_data)
                
                if isinstance(output, dict):
                    loss = nn.MSELoss()(output['comprehensive_reasoning'], target_data[:, 0])
                else:
                    loss = nn.MSELoss()(output, target_data)
                
                loss.backward()
                
                # æ£€æŸ¥æ¢¯åº¦
                total_grad_norm = 0
                param_count = 0
                for param in model.parameters():
                    if param.grad is not None:
                        total_grad_norm += param.grad.norm().item() ** 2
                        param_count += 1
                
                if param_count > 0:
                    avg_grad_norm = (total_grad_norm / param_count) ** 0.5
                    logger.log_important(f"   {opt_name} å¹³å‡æ¢¯åº¦èŒƒæ•°: {avg_grad_norm:.2e}")
                
                optimizer.step()
            
            # åˆ†æ3: å­¦ä¹ ç‡åˆ†æ
            logger.log_important("   åˆ†æå­¦ä¹ ç‡...")
            
            learning_rates = [0.0001, 0.001, 0.01, 0.1]
            
            for lr in learning_rates:
                optimizer = optim.Adam(model.parameters(), lr=lr)
                optimizer.zero_grad()
                
                output = model(train_data)
                if isinstance(output, dict):
                    loss = nn.MSELoss()(output['comprehensive_reasoning'], target_data[:, 0])
                else:
                    loss = nn.MSELoss()(output, target_data)
                
                loss.backward()
                optimizer.step()
                
                logger.log_important(f"   å­¦ä¹ ç‡ {lr}: æŸå¤± {loss.item():.4f}")
                
                if loss.item() > 10:
                    training_issues.append(f"å­¦ä¹ ç‡ {lr} å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®š")
            
        except Exception as e:
            training_issues.append(f"è®­ç»ƒç­–ç•¥åˆ†æå¤±è´¥: {e}")
        
        self.analysis_results['training_strategy'] = {
            'issues': training_issues,
            'total_issues': len(training_issues)
        }
        
        logger.log_important(f"ğŸ“Š è®­ç»ƒç­–ç•¥é—®é¢˜: {len(training_issues)} ä¸ª")
        for issue in training_issues:
            logger.log_warning(f"   âš ï¸ {issue}")
    
    async def _analyze_data_flow(self):
        """åˆ†ææ•°æ®æµé—®é¢˜"""
        logger.log_important("\nğŸ”„ 4. æ•°æ®æµåˆ†æ")
        logger.log_important("-" * 40)
        
        data_flow_issues = []
        
        try:
            # åˆ†æ1: è¾“å…¥æ•°æ®åˆ†å¸ƒ
            logger.log_important("   åˆ†æè¾“å…¥æ•°æ®åˆ†å¸ƒ...")
            
            # ç”Ÿæˆä¸åŒåˆ†å¸ƒçš„è¾“å…¥æ•°æ®
            data_distributions = [
                ('æ­£æ€åˆ†å¸ƒ', torch.randn(100, 4)),
                ('å‡åŒ€åˆ†å¸ƒ', torch.rand(100, 4)),
                ('åæ€åˆ†å¸ƒ', torch.abs(torch.randn(100, 4))),
                ('ç¨€ç–åˆ†å¸ƒ', torch.sparse_coo_tensor(
                    torch.randint(0, 4, (2, 50)), 
                    torch.randn(50), 
                    (100, 4)
                ).to_dense())
            ]
            
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=256,
                reasoning_layers=4,
                attention_heads=8,
                memory_size=20,
                reasoning_types=10
            )
            
            for dist_name, data in data_distributions:
                logger.log_important(f"   {dist_name}:")
                logger.log_important(f"     å‡å€¼: {data.mean():.4f}")
                logger.log_important(f"     æ ‡å‡†å·®: {data.std():.4f}")
                logger.log_important(f"     èŒƒå›´: [{data.min():.4f}, {data.max():.4f}]")
                
                # æµ‹è¯•æ¨¡å‹å¯¹ä¸åŒæ•°æ®åˆ†å¸ƒçš„ååº”
                with torch.no_grad():
                    output = model(data)
                
                if isinstance(output, dict):
                    reasoning_output = output['comprehensive_reasoning']
                    logger.log_important(f"     æ¨ç†è¾“å‡ºå‡å€¼: {reasoning_output.mean():.4f}")
                    logger.log_important(f"     æ¨ç†è¾“å‡ºæ ‡å‡†å·®: {reasoning_output.std():.4f}")
                    
                    # æ£€æŸ¥è¾“å‡ºæ˜¯å¦å¯¹è¾“å…¥æ•æ„Ÿ
                    if reasoning_output.std() < 0.001:
                        data_flow_issues.append(f"{dist_name}æ•°æ®ä¸‹æ¨¡å‹è¾“å‡ºç¼ºä¹å˜åŒ–")
                else:
                    logger.log_important(f"     è¾“å‡ºå‡å€¼: {output.mean():.4f}")
                    logger.log_important(f"     è¾“å‡ºæ ‡å‡†å·®: {output.std():.4f}")
            
            # åˆ†æ2: æ•°æ®é¢„å¤„ç†
            logger.log_important("   åˆ†ææ•°æ®é¢„å¤„ç†...")
            
            # æµ‹è¯•æ ‡å‡†åŒ–æ•ˆæœ
            raw_data = torch.randn(100, 4)
            normalized_data = (raw_data - raw_data.mean()) / raw_data.std()
            
            with torch.no_grad():
                raw_output = model(raw_data)
                norm_output = model(normalized_data)
            
            if isinstance(raw_output, dict) and isinstance(norm_output, dict):
                raw_score = raw_output['comprehensive_reasoning'].mean()
                norm_score = norm_output['comprehensive_reasoning'].mean()
                
                logger.log_important(f"   åŸå§‹æ•°æ®æ¨ç†åˆ†æ•°: {raw_score:.4f}")
                logger.log_important(f"   æ ‡å‡†åŒ–æ•°æ®æ¨ç†åˆ†æ•°: {norm_score:.4f}")
                
                if abs(raw_score - norm_score) < 0.001:
                    data_flow_issues.append("æ•°æ®æ ‡å‡†åŒ–å¯¹æ¨¡å‹è¾“å‡ºå½±å“å¾ˆå°")
            
        except Exception as e:
            data_flow_issues.append(f"æ•°æ®æµåˆ†æå¤±è´¥: {e}")
        
        self.analysis_results['data_flow'] = {
            'issues': data_flow_issues,
            'total_issues': len(data_flow_issues)
        }
        
        logger.log_important(f"ğŸ“Š æ•°æ®æµé—®é¢˜: {len(data_flow_issues)} ä¸ª")
        for issue in data_flow_issues:
            logger.log_warning(f"   âš ï¸ {issue}")
    
    async def _analyze_performance_bottlenecks(self):
        """åˆ†ææ€§èƒ½ç“¶é¢ˆ"""
        logger.log_important("\nâš¡ 5. æ€§èƒ½ç“¶é¢ˆåˆ†æ")
        logger.log_important("-" * 40)
        
        performance_issues = []
        
        try:
            # åˆ†æ1: è®¡ç®—å¤æ‚åº¦
            logger.log_important("   åˆ†æè®¡ç®—å¤æ‚åº¦...")
            
            model_sizes = [128, 256, 512, 1024]
            inference_times = []
            
            for hidden_size in model_sizes:
                model = AdvancedReasoningNet(
                    input_size=4,
                    hidden_size=hidden_size,
                    reasoning_layers=4,
                    attention_heads=8,
                    memory_size=20,
                    reasoning_types=10
                )
                
                test_input = torch.randn(1, 4)
                
                # é¢„çƒ­
                with torch.no_grad():
                    for _ in range(3):
                        _ = model(test_input)
                
                # æµ‹è¯•æ¨ç†æ—¶é—´
                start_time = time.time()
                with torch.no_grad():
                    for _ in range(10):
                        _ = model(test_input)
                end_time = time.time()
                
                avg_time = (end_time - start_time) / 10 * 1000  # ms
                inference_times.append(avg_time)
                
                logger.log_important(f"   éšè—å±‚å¤§å° {hidden_size}: {avg_time:.2f}ms")
            
            # åˆ†ææ—¶é—´å¢é•¿è¶‹åŠ¿
            if len(inference_times) >= 2:
                time_growth = inference_times[-1] / inference_times[0]
                logger.log_important(f"   æ—¶é—´å¢é•¿å€æ•°: {time_growth:.2f}")
                
                if time_growth > 10:
                    performance_issues.append("æ¨¡å‹è§„æ¨¡å¢é•¿å¯¼è‡´æ¨ç†æ—¶é—´æ€¥å‰§å¢åŠ ")
            
            # åˆ†æ2: å†…å­˜ä½¿ç”¨
            logger.log_important("   åˆ†æå†…å­˜ä½¿ç”¨...")
            
            import psutil
            process = psutil.Process()
            
            for hidden_size in [256, 512, 1024]:
                initial_memory = process.memory_info().rss / 1024 / 1024  # MB
                
                model = AdvancedReasoningNet(
                    input_size=4,
                    hidden_size=hidden_size,
                    reasoning_layers=4,
                    attention_heads=8,
                    memory_size=20,
                    reasoning_types=10
                )
                
                final_memory = process.memory_info().rss / 1024 / 1024  # MB
                memory_increase = final_memory - initial_memory
                
                logger.log_important(f"   éšè—å±‚å¤§å° {hidden_size}: å†…å­˜å¢åŠ  {memory_increase:.1f}MB")
                
                if memory_increase > 500:
                    performance_issues.append(f"éšè—å±‚å¤§å° {hidden_size} å†…å­˜ä½¿ç”¨è¿‡é«˜")
                
                # æ¸…ç†å†…å­˜
                del model
                torch.cuda.empty_cache() if torch.cuda.is_available() else None
            
            # åˆ†æ3: å¹¶è¡Œæ€§èƒ½
            logger.log_important("   åˆ†æå¹¶è¡Œæ€§èƒ½...")
            
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=512,
                reasoning_layers=4,
                attention_heads=8,
                memory_size=20,
                reasoning_types=10
            )
            
            # æµ‹è¯•æ‰¹é‡å¤„ç†
            batch_sizes = [1, 4, 8, 16]
            
            for batch_size in batch_sizes:
                batch_input = torch.randn(batch_size, 4)
                
                start_time = time.time()
                with torch.no_grad():
                    _ = model(batch_input)
                end_time = time.time()
                
                total_time = (end_time - start_time) * 1000  # ms
                avg_time_per_sample = total_time / batch_size
                
                logger.log_important(f"   æ‰¹é‡å¤§å° {batch_size}: æ€»æ—¶é—´ {total_time:.2f}ms, å¹³å‡ {avg_time_per_sample:.2f}ms/æ ·æœ¬")
                
                if batch_size > 1 and avg_time_per_sample > inference_times[2]:  # 512 hidden_sizeçš„æ—¶é—´
                    performance_issues.append(f"æ‰¹é‡å¤§å° {batch_size} å¹¶è¡Œæ•ˆç‡ä½")
            
        except Exception as e:
            performance_issues.append(f"æ€§èƒ½ç“¶é¢ˆåˆ†æå¤±è´¥: {e}")
        
        self.analysis_results['performance_bottlenecks'] = {
            'issues': performance_issues,
            'total_issues': len(performance_issues)
        }
        
        logger.log_important(f"ğŸ“Š æ€§èƒ½ç“¶é¢ˆé—®é¢˜: {len(performance_issues)} ä¸ª")
        for issue in performance_issues:
            logger.log_warning(f"   âš ï¸ {issue}")
    
    def _generate_deep_analysis_report(self):
        """ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š"""
        logger.log_important("\nğŸ“‹ æ·±åº¦é—®é¢˜åˆ†ææŠ¥å‘Š")
        logger.log_important("=" * 60)
        
        # ç»Ÿè®¡æ‰€æœ‰é—®é¢˜
        all_issues = []
        total_issues = 0
        
        for category, result in self.analysis_results.items():
            if isinstance(result, dict) and 'issues' in result:
                issues = result['issues']
                all_issues.extend([(category, issue) for issue in issues])
                total_issues += len(issues)
        
        logger.log_important(f"ğŸ“Š é—®é¢˜ç»Ÿè®¡:")
        logger.log_important(f"   æ€»é—®é¢˜æ•°é‡: {total_issues}")
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        for category, result in self.analysis_results.items():
            if isinstance(result, dict) and 'issues' in result:
                issue_count = len(result['issues'])
                logger.log_important(f"   {category}: {issue_count} ä¸ªé—®é¢˜")
        
        # åˆ†æå…³é”®é—®é¢˜
        logger.log_important(f"\nğŸ” å…³é”®é—®é¢˜åˆ†æ:")
        
        # æ‰¾å‡ºæœ€ä¸¥é‡çš„é—®é¢˜
        critical_issues = []
        for category, issue in all_issues:
            if any(keyword in issue.lower() for keyword in ['å¤±è´¥', 'é”™è¯¯', 'å´©æºƒ', 'æ— æ³•']):
                critical_issues.append((category, issue))
            elif any(keyword in issue.lower() for keyword in ['è¿‡ä½', 'è¿‡å°', 'ä¸è¶³', 'ç¼ºä¹']):
                critical_issues.append((category, issue))
        
        logger.log_important(f"   ä¸¥é‡é—®é¢˜: {len(critical_issues)} ä¸ª")
        for category, issue in critical_issues[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            logger.log_warning(f"   ğŸ”´ {category}: {issue}")
        
        # ç”Ÿæˆè§£å†³æ–¹æ¡ˆå»ºè®®
        logger.log_important(f"\nğŸ’¡ è§£å†³æ–¹æ¡ˆå»ºè®®:")
        
        solutions = []
        
        # åŸºäºé—®é¢˜ç±»å‹æå‡ºè§£å†³æ–¹æ¡ˆ
        if any('æ¨ç†åˆ†æ•°è¿‡ä½' in issue for _, issue in all_issues):
            solutions.append("1. ä¼˜åŒ–æ¨¡å‹æ¶æ„ï¼Œå¢åŠ æ¨¡å‹å¤æ‚åº¦")
            solutions.append("2. æ”¹è¿›è®­ç»ƒç­–ç•¥ï¼Œä½¿ç”¨æ›´åˆé€‚çš„æŸå¤±å‡½æ•°")
            solutions.append("3. å¢åŠ è®­ç»ƒæ•°æ®é‡å’Œå¤šæ ·æ€§")
        
        if any('æ¢¯åº¦' in issue for _, issue in all_issues):
            solutions.append("4. è§£å†³æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸é—®é¢˜ï¼Œè°ƒæ•´å­¦ä¹ ç‡")
            solutions.append("5. ä½¿ç”¨æ›´å¥½çš„æ¿€æ´»å‡½æ•°å’Œåˆå§‹åŒ–æ–¹æ³•")
        
        if any('å†…å­˜' in issue for _, issue in all_issues):
            solutions.append("6. ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œå®ç°æ¢¯åº¦æ£€æŸ¥ç‚¹")
            solutions.append("7. ä½¿ç”¨æ¨¡å‹é‡åŒ–å’Œå‹ç¼©æŠ€æœ¯")
        
        if any('è¯„ä¼°' in issue for _, issue in all_issues):
            solutions.append("8. é‡æ–°è®¾è®¡è¯„ä¼°æ ‡å‡†ï¼Œç¡®ä¿åˆç†æ€§")
            solutions.append("9. å¢åŠ è¯„ä¼°ä»»åŠ¡çš„å¤šæ ·æ€§")
        
        if any('æ•°æ®' in issue for _, issue in all_issues):
            solutions.append("10. æ”¹è¿›æ•°æ®é¢„å¤„ç†å’Œå¢å¼º")
            solutions.append("11. ä½¿ç”¨æ›´å¥½çš„æ•°æ®åˆ†å¸ƒ")
        
        for solution in solutions:
            logger.log_important(f"   ğŸ’¡ {solution}")
        
        # ä¼˜å…ˆçº§æ’åº
        logger.log_important(f"\nğŸ¯ ä¼˜å…ˆçº§æ’åº:")
        logger.log_important(f"   é«˜ä¼˜å…ˆçº§: æ¨ç†åˆ†æ•°ä¼˜åŒ–ã€æ¨¡å‹æ¶æ„æ”¹è¿›")
        logger.log_important(f"   ä¸­ä¼˜å…ˆçº§: è®­ç»ƒç­–ç•¥ä¼˜åŒ–ã€è¯„ä¼°æ ‡å‡†è°ƒæ•´")
        logger.log_important(f"   ä½ä¼˜å…ˆçº§: æ€§èƒ½ä¼˜åŒ–ã€å†…å­˜ç®¡ç†")
        
        # æ—¶é—´è§„åˆ’
        logger.log_important(f"\nâ° æ—¶é—´è§„åˆ’:")
        logger.log_important(f"   ç«‹å³è¡ŒåŠ¨ (1-2å¤©): ä¿®å¤ä¸¥é‡é”™è¯¯ï¼Œè°ƒæ•´è¯„ä¼°æ ‡å‡†")
        logger.log_important(f"   çŸ­æœŸæ”¹è¿› (1å‘¨): ä¼˜åŒ–æ¨¡å‹æ¶æ„ï¼Œæ”¹è¿›è®­ç»ƒç­–ç•¥")
        logger.log_important(f"   ä¸­æœŸä¼˜åŒ– (1ä¸ªæœˆ): å…¨é¢é‡æ„ï¼Œæ€§èƒ½ä¼˜åŒ–")
        
        self.analysis_results['summary'] = {
            'total_issues': total_issues,
            'critical_issues': len(critical_issues),
            'solutions': solutions
        }

async def main():
    """ä¸»å‡½æ•°"""
    logger.log_important("=== æ·±åº¦é—®é¢˜åˆ†æ ===")
    
    # åˆ›å»ºæ·±åº¦é—®é¢˜åˆ†æå™¨
    analyzer = DeepProblemAnalysis()
    
    # è¿è¡Œæ·±åº¦é—®é¢˜åˆ†æ
    results = await analyzer.run_deep_analysis()
    
    logger.log_important(f"\nğŸ‰ æ·±åº¦é—®é¢˜åˆ†æå®Œæˆï¼")
    logger.log_important(f"å‘ç° {results.get('summary', {}).get('total_issues', 0)} ä¸ªé—®é¢˜")
    logger.log_important(f"å…¶ä¸­ {results.get('summary', {}).get('critical_issues', 0)} ä¸ªä¸¥é‡é—®é¢˜")

if __name__ == "__main__":
    asyncio.run(main()) 