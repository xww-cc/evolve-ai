#!/usr/bin/env python3
"""
è½»é‡çº§ä¼˜åŒ–æµ‹è¯•è„šæœ¬
é¿å…å†…å­˜ä¸è¶³é—®é¢˜ï¼Œé‡ç‚¹æµ‹è¯•å…³é”®åŠŸèƒ½
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import time
from models.advanced_reasoning_net import AdvancedReasoningNet
from evaluators.enhanced_evaluator import EnhancedEvaluator
from config.optimized_logging import setup_optimized_logging

logger = setup_optimized_logging()

class LightweightOptimizationTest:
    """è½»é‡çº§ä¼˜åŒ–æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.optimization_results = {}
        self.best_score = 0.0
        
    async def run_lightweight_optimization(self):
        """è¿è¡Œè½»é‡çº§ä¼˜åŒ–æµ‹è¯•"""
        logger.log_important("ğŸš€ å¼€å§‹è½»é‡çº§ä¼˜åŒ–æµ‹è¯•")
        logger.log_important("=" * 50)
        
        # 1. æ¨ç†åˆ†æ•°ä¼˜åŒ–ï¼ˆè½»é‡çº§ï¼‰
        await self._optimize_reasoning_score_lightweight()
        
        # 2. ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•
        await self._test_system_stability()
        
        # 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
        await self._benchmark_performance()
        
        # 4. ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
        self._generate_optimization_report()
        
        return self.optimization_results
    
    async def _optimize_reasoning_score_lightweight(self):
        """è½»é‡çº§æ¨ç†åˆ†æ•°ä¼˜åŒ–"""
        logger.log_important("ğŸ§  1. è½»é‡çº§æ¨ç†åˆ†æ•°ä¼˜åŒ–")
        logger.log_important("-" * 40)
        
        # ä½¿ç”¨ä¸­ç­‰è§„æ¨¡çš„é…ç½®ï¼Œé¿å…å†…å­˜ä¸è¶³
        lightweight_configs = [
            # ä¸­ç­‰é…ç½®
            {
                'name': 'ä¸­ç­‰é…ç½®',
                'hidden_size': 1024,
                'reasoning_layers': 8,
                'attention_heads': 16,
                'memory_size': 100,
                'reasoning_types': 20
            },
            # å¹³è¡¡é…ç½®
            {
                'name': 'å¹³è¡¡é…ç½®',
                'hidden_size': 1536,
                'reasoning_layers': 10,
                'attention_heads': 24,
                'memory_size': 150,
                'reasoning_types': 25
            },
            # å¢å¼ºé…ç½®
            {
                'name': 'å¢å¼ºé…ç½®',
                'hidden_size': 2048,
                'reasoning_layers': 12,
                'attention_heads': 32,
                'memory_size': 200,
                'reasoning_types': 30
            }
        ]
        
        evaluator = EnhancedEvaluator()
        
        for i, config in enumerate(lightweight_configs, 1):
            logger.log_important(f"ğŸ”§ æµ‹è¯•é…ç½® {i}: {config['name']}")
            
            try:
                # åˆ›å»ºæ¨¡å‹
                model = AdvancedReasoningNet(
                    input_size=4,
                    hidden_size=config['hidden_size'],
                    reasoning_layers=config['reasoning_layers'],
                    attention_heads=config['attention_heads'],
                    memory_size=config['memory_size'],
                    reasoning_types=config['reasoning_types']
                )
                
                # æµ‹è¯•æ¨ç†æ€§èƒ½
                start_time = time.time()
                result = await evaluator.evaluate_enhanced_reasoning(model, max_tasks=5)
                end_time = time.time()
                
                inference_time = (end_time - start_time) * 1000
                reasoning_score = result.get('comprehensive_reasoning', 0.0)
                
                logger.log_important(f"   æ¨ç†åˆ†æ•°: {reasoning_score:.4f}")
                logger.log_important(f"   æ¨ç†æ—¶é—´: {inference_time:.2f}ms")
                
                # æ›´æ–°æœ€ä½³åˆ†æ•°
                if reasoning_score > self.best_score:
                    self.best_score = reasoning_score
                    logger.log_success(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨ç†åˆ†æ•°: {reasoning_score:.4f}")
                
                # æ¸…ç†å†…å­˜
                del model
                torch.cuda.empty_cache() if torch.cuda.is_available() else None
                
                logger.log_important("")
                
            except Exception as e:
                logger.log_error(f"âŒ é…ç½® {config['name']} æµ‹è¯•å¤±è´¥: {e}")
                continue
        
        # å°è¯•è®­ç»ƒä¼˜åŒ–
        await self._try_lightweight_training()
        
        self.optimization_results['reasoning_optimization'] = {
            'best_score': self.best_score,
            'target_achieved': self.best_score >= 0.1,
            'configs_tested': len(lightweight_configs)
        }
        
        return self.best_score
    
    async def _try_lightweight_training(self):
        """å°è¯•è½»é‡çº§è®­ç»ƒä¼˜åŒ–"""
        logger.log_important("\nğŸ“ å°è¯•è½»é‡çº§è®­ç»ƒä¼˜åŒ–")
        logger.log_important("-" * 40)
        
        try:
            # ä½¿ç”¨æœ€ä½³é…ç½®è¿›è¡Œè®­ç»ƒ
            best_config = {
                'hidden_size': 1024,
                'reasoning_layers': 8,
                'attention_heads': 16,
                'memory_size': 100,
                'reasoning_types': 20
            }
            
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=best_config['hidden_size'],
                reasoning_layers=best_config['reasoning_layers'],
                attention_heads=best_config['attention_heads'],
                memory_size=best_config['memory_size'],
                reasoning_types=best_config['reasoning_types']
            )
            
            # åˆ›å»ºä¼˜åŒ–å™¨
            optimizer = optim.Adam(model.parameters(), lr=0.001)
            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)
            
            evaluator = EnhancedEvaluator()
            
            # è½»é‡çº§è®­ç»ƒå¾ªç¯
            training_epochs = 10
            logger.log_important(f"å¼€å§‹è½»é‡çº§è®­ç»ƒ {training_epochs} ä¸ªepoch...")
            
            for epoch in range(training_epochs):
                # ç”Ÿæˆè®­ç»ƒæ•°æ®
                train_data = torch.randn(10, 4)
                target_data = torch.randn(10, 4)
                
                # å‰å‘ä¼ æ’­
                optimizer.zero_grad()
                output = model(train_data)
                
                # è®¡ç®—æŸå¤±
                if isinstance(output, dict):
                    loss = nn.MSELoss()(output['comprehensive_reasoning'], target_data[:, 0])
                else:
                    loss = nn.MSELoss()(output, target_data)
                
                # åå‘ä¼ æ’­
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                scheduler.step()
                
                # è¯„ä¼°å½“å‰æ€§èƒ½
                with torch.no_grad():
                    result = await evaluator.evaluate_enhanced_reasoning(model, max_tasks=3)
                    current_score = result.get('comprehensive_reasoning', 0.0)
                
                logger.log_important(f"Epoch {epoch+1}: æŸå¤±={loss.item():.4f}, æ¨ç†åˆ†æ•°={current_score:.4f}")
                
                # æ›´æ–°æœ€ä½³åˆ†æ•°
                if current_score > self.best_score:
                    self.best_score = current_score
                    logger.log_success(f"ğŸ‰ è®­ç»ƒåæ–°çš„æœ€ä½³æ¨ç†åˆ†æ•°: {current_score:.4f}")
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
                if current_score >= 0.1:
                    logger.log_success("ğŸ¯ è®­ç»ƒåç›®æ ‡è¾¾æˆï¼æ¨ç†åˆ†æ•°å·²è¶…è¿‡0.1")
                    break
            
            logger.log_important(f"\nâœ… è½»é‡çº§è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆæœ€ä½³æ¨ç†åˆ†æ•°: {self.best_score:.4f}")
            
        except Exception as e:
            logger.log_error(f"âŒ è½»é‡çº§è®­ç»ƒä¼˜åŒ–å¤±è´¥: {e}")
    
    async def _test_system_stability(self):
        """æµ‹è¯•ç³»ç»Ÿç¨³å®šæ€§"""
        logger.log_important("\nğŸ”§ 2. ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•")
        logger.log_important("-" * 40)
        
        stability_tests = []
        
        # æµ‹è¯•1: æ¨¡å‹åˆ›å»ºç¨³å®šæ€§
        try:
            models = []
            for i in range(3):
                model = AdvancedReasoningNet(
                    input_size=4,
                    hidden_size=256 + i * 100,
                    reasoning_layers=5 + i,
                    attention_heads=8 + i * 2,
                    memory_size=20 + i * 10,
                    reasoning_types=10 + i
                )
                models.append(model)
            
            # æ¸…ç†å†…å­˜
            del models
            torch.cuda.empty_cache() if torch.cuda.is_available() else None
            
            stability_tests.append(('æ¨¡å‹åˆ›å»º', True, 'æˆåŠŸåˆ›å»º3ä¸ªä¸åŒé…ç½®çš„æ¨¡å‹'))
        except Exception as e:
            stability_tests.append(('æ¨¡å‹åˆ›å»º', False, f'å¤±è´¥: {e}'))
        
        # æµ‹è¯•2: æ¨ç†ç¨³å®šæ€§
        try:
            model = AdvancedReasoningNet(input_size=4, hidden_size=256, reasoning_layers=5)
            test_input = torch.randn(5, 4)
            
            outputs = []
            for _ in range(5):
                with torch.no_grad():
                    output = model(test_input)
                    outputs.append(output)
            
            # æ£€æŸ¥è¾“å‡ºä¸€è‡´æ€§
            if isinstance(outputs[0], dict):
                output_keys = outputs[0].keys()
                consistency_check = all(
                    all(key in output.keys() for key in output_keys) 
                    for output in outputs
                )
            else:
                consistency_check = all(
                    output.shape == outputs[0].shape 
                    for output in outputs
                )
            
            stability_tests.append(('æ¨ç†ç¨³å®šæ€§', consistency_check, 'è¿ç»­æ¨ç†è¾“å‡ºä¸€è‡´'))
        except Exception as e:
            stability_tests.append(('æ¨ç†ç¨³å®šæ€§', False, f'å¤±è´¥: {e}'))
        
        # æµ‹è¯•3: å†…å­˜ç¨³å®šæ€§
        try:
            import psutil
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # åˆ›å»ºæ¨¡å‹æµ‹è¯•å†…å­˜
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=512,
                reasoning_layers=6,
                attention_heads=12,
                memory_size=30,
                reasoning_types=15
            )
            
            final_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_increase = final_memory - initial_memory
            
            # æ¸…ç†å†…å­˜
            del model
            torch.cuda.empty_cache() if torch.cuda.is_available() else None
            
            stability_tests.append(('å†…å­˜ç¨³å®šæ€§', memory_increase < 500, f'å†…å­˜å¢åŠ : {memory_increase:.1f}MB'))
        except Exception as e:
            stability_tests.append(('å†…å­˜ç¨³å®šæ€§', False, f'å¤±è´¥: {e}'))
        
        # ç»Ÿè®¡ç»“æœ
        passed_tests = sum(1 for test in stability_tests if test[1])
        total_tests = len(stability_tests)
        stability_rate = passed_tests / total_tests * 100
        
        self.optimization_results['system_stability'] = {
            'stability_rate': stability_rate,
            'passed_tests': passed_tests,
            'total_tests': total_tests,
            'test_details': stability_tests
        }
        
        logger.log_important(f"ğŸ“Š ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•ç»“æœ:")
        for test_name, passed, description in stability_tests:
            status = "âœ…" if passed else "âŒ"
            logger.log_important(f"   {status} {test_name}: {description}")
        
        logger.log_important(f"   ç¨³å®šæ€§é€šè¿‡ç‡: {stability_rate:.1f}% ({passed_tests}/{total_tests})")
        
        if stability_rate >= 90:
            logger.log_success("âœ… ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•é€šè¿‡")
        else:
            logger.log_warning(f"âš ï¸ ç³»ç»Ÿç¨³å®šæ€§éœ€è¦æ”¹è¿›")
    
    async def _benchmark_performance(self):
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        logger.log_important("\nâš¡ 3. æ€§èƒ½åŸºå‡†æµ‹è¯•")
        logger.log_important("-" * 40)
        
        # æµ‹è¯•ä¸åŒè§„æ¨¡çš„æ¨¡å‹æ€§èƒ½
        benchmark_configs = [
            {'name': 'å°å‹æ¨¡å‹', 'hidden_size': 128, 'reasoning_layers': 3},
            {'name': 'ä¸­å‹æ¨¡å‹', 'hidden_size': 512, 'reasoning_layers': 6},
            {'name': 'å¤§å‹æ¨¡å‹', 'hidden_size': 1024, 'reasoning_layers': 8}
        ]
        
        benchmark_results = []
        
        for config in benchmark_configs:
            try:
                model = AdvancedReasoningNet(
                    input_size=4,
                    hidden_size=config['hidden_size'],
                    reasoning_layers=config['reasoning_layers'],
                    attention_heads=8,
                    memory_size=20,
                    reasoning_types=10
                )
                
                # æµ‹è¯•æ¨ç†æ—¶é—´
                test_input = torch.randn(1, 4)
                
                # é¢„çƒ­
                with torch.no_grad():
                    for _ in range(3):
                        _ = model(test_input)
                
                # æ­£å¼æµ‹è¯•
                times = []
                for _ in range(5):
                    start_time = time.time()
                    with torch.no_grad():
                        _ = model(test_input)
                    end_time = time.time()
                    times.append((end_time - start_time) * 1000)
                
                avg_time = np.mean(times)
                std_time = np.std(times)
                
                # æµ‹è¯•å†…å­˜ä½¿ç”¨
                import psutil
                process = psutil.Process()
                memory_usage = process.memory_info().rss / 1024 / 1024  # MB
                
                benchmark_results.append({
                    'name': config['name'],
                    'avg_time': avg_time,
                    'std_time': std_time,
                    'memory_usage': memory_usage,
                    'success': True
                })
                
                logger.log_important(f"   {config['name']}: {avg_time:.2f}ms Â± {std_time:.2f}ms, {memory_usage:.1f}MB")
                
                # æ¸…ç†å†…å­˜
                del model
                torch.cuda.empty_cache() if torch.cuda.is_available() else None
                
            except Exception as e:
                benchmark_results.append({
                    'name': config['name'],
                    'avg_time': 0,
                    'std_time': 0,
                    'memory_usage': 0,
                    'success': False,
                    'error': str(e)
                })
                logger.log_error(f"   {config['name']}: æµ‹è¯•å¤±è´¥ - {e}")
        
        self.optimization_results['performance_benchmark'] = {
            'configs': benchmark_results,
            'success_rate': sum(1 for r in benchmark_results if r['success']) / len(benchmark_results) * 100
        }
        
        logger.log_important(f"ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸç‡: {self.optimization_results['performance_benchmark']['success_rate']:.1f}%")
    
    def _generate_optimization_report(self):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        logger.log_important("\nğŸ“‹ è½»é‡çº§ä¼˜åŒ–æµ‹è¯•æŠ¥å‘Š")
        logger.log_important("=" * 50)
        
        # ç»Ÿè®¡ä¼˜åŒ–ç»“æœ
        total_optimizations = len(self.optimization_results)
        successful_optimizations = sum(1 for result in self.optimization_results.values() 
                                     if isinstance(result, dict) and result.get('success', True))
        
        overall_success_rate = successful_optimizations / total_optimizations * 100
        
        logger.log_important(f"ğŸ“Š ä¼˜åŒ–æ€»ä½“ç»“æœ:")
        logger.log_important(f"   æ€»ä¼˜åŒ–é¡¹ç›®: {total_optimizations}")
        logger.log_important(f"   æˆåŠŸä¼˜åŒ–: {successful_optimizations}")
        logger.log_important(f"   æˆåŠŸç‡: {overall_success_rate:.1f}%")
        
        # è¯¦ç»†ä¼˜åŒ–ç»“æœ
        logger.log_important(f"\nğŸ“‹ è¯¦ç»†ä¼˜åŒ–ç»“æœ:")
        
        for optimization_name, result in self.optimization_results.items():
            if isinstance(result, dict):
                success = result.get('success', True)
                status = "âœ…" if success else "âŒ"
                logger.log_important(f"   {status} {optimization_name}")
                
                # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                if optimization_name == 'reasoning_optimization':
                    best_score = result.get('best_score', 0)
                    target_achieved = result.get('target_achieved', False)
                    logger.log_important(f"      æ¨ç†åˆ†æ•°: {best_score:.4f} {'âœ…' if target_achieved else 'âŒ'}")
                
                elif optimization_name == 'system_stability':
                    stability_rate = result.get('stability_rate', 0)
                    logger.log_important(f"      ç¨³å®šæ€§: {stability_rate:.1f}%")
                
                elif optimization_name == 'performance_benchmark':
                    success_rate = result.get('success_rate', 0)
                    logger.log_important(f"      æˆåŠŸç‡: {success_rate:.1f}%")
        
        # æ¨ç†åˆ†æ•°ç›®æ ‡è¾¾æˆæƒ…å†µ
        reasoning_result = self.optimization_results.get('reasoning_optimization', {})
        best_score = reasoning_result.get('best_score', 0)
        target_achieved = reasoning_result.get('target_achieved', False)
        
        logger.log_important(f"\nğŸ¯ æ¨ç†åˆ†æ•°ç›®æ ‡è¾¾æˆæƒ…å†µ:")
        logger.log_important(f"   æœ€ä½³æ¨ç†åˆ†æ•°: {best_score:.4f}")
        logger.log_important(f"   ç›®æ ‡è¾¾æˆ: {'âœ… æ˜¯' if target_achieved else 'âŒ å¦'}")
        
        if target_achieved:
            logger.log_success("ğŸ‰ æ­å–œï¼æ¨ç†åˆ†æ•°ç›®æ ‡å·²è¾¾æˆï¼")
        else:
            improvement_needed = 0.1 - best_score
            improvement_percentage = (improvement_needed / 0.1) * 100
            logger.log_warning(f"âš ï¸ ä»éœ€æ”¹è¿›: {improvement_needed:.4f} ({improvement_percentage:.1f}%)")
        
        # æœ€ç»ˆè¯„ä¼°
        if overall_success_rate >= 90:
            logger.log_success("ğŸ‰ è½»é‡çº§ä¼˜åŒ–æµ‹è¯•ä¼˜ç§€ï¼")
        elif overall_success_rate >= 80:
            logger.log_important("âœ… è½»é‡çº§ä¼˜åŒ–æµ‹è¯•è‰¯å¥½ï¼Œéƒ¨åˆ†é¡¹ç›®éœ€è¦æ”¹è¿›")
        else:
            logger.log_warning("âš ï¸ è½»é‡çº§ä¼˜åŒ–æµ‹è¯•å‘ç°é—®é¢˜ï¼Œéœ€è¦é‡ç‚¹æ”¹è¿›")

async def main():
    """ä¸»å‡½æ•°"""
    logger.log_important("=== è½»é‡çº§ä¼˜åŒ–æµ‹è¯• ===")
    
    # åˆ›å»ºè½»é‡çº§ä¼˜åŒ–æµ‹è¯•å™¨
    optimizer = LightweightOptimizationTest()
    
    # è¿è¡Œè½»é‡çº§ä¼˜åŒ–æµ‹è¯•
    results = await optimizer.run_lightweight_optimization()
    
    logger.log_important(f"\nğŸ‰ è½»é‡çº§ä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")
    logger.log_important(f"ä¼˜åŒ–ç»“æœå·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š")

if __name__ == "__main__":
    asyncio.run(main()) 