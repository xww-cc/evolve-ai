#!/usr/bin/env python3
"""
æ¨ç†èƒ½åŠ›ä¼˜åŒ–æµ‹è¯•è„šæœ¬
ä¸“é—¨é’ˆå¯¹æ¨ç†åˆ†æ•°å’Œæ¨ç†èƒ½åŠ›è¿›è¡Œä¼˜åŒ–
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from models.advanced_reasoning_net import AdvancedReasoningNet
from evaluators.enhanced_evaluator import EnhancedEvaluator
from config.optimized_logging import setup_optimized_logging
import time

logger = setup_optimized_logging()

class ReasoningOptimizer:
    """æ¨ç†èƒ½åŠ›ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.best_score = 0.0
        self.optimization_history = []
        
    async def optimize_reasoning_models(self):
        """ä¼˜åŒ–æ¨ç†æ¨¡å‹"""
        logger.log_important("ğŸ§  å¼€å§‹æ¨ç†èƒ½åŠ›ä¼˜åŒ–")
        logger.log_important("=" * 50)
        
        # æµ‹è¯•ä¸åŒçš„æ¨¡å‹é…ç½®
        configs = [
            # é…ç½®1: åŸºç¡€é…ç½®
            {
                'name': 'åŸºç¡€é…ç½®',
                'hidden_size': 256,
                'reasoning_layers': 5,
                'attention_heads': 8,
                'memory_size': 20,
                'reasoning_types': 10
            },
            # é…ç½®2: å¢å¼ºé…ç½®
            {
                'name': 'å¢å¼ºé…ç½®',
                'hidden_size': 512,
                'reasoning_layers': 8,
                'attention_heads': 16,
                'memory_size': 50,
                'reasoning_types': 15
            },
            # é…ç½®3: æ·±åº¦é…ç½®
            {
                'name': 'æ·±åº¦é…ç½®',
                'hidden_size': 1024,
                'reasoning_layers': 12,
                'attention_heads': 32,
                'memory_size': 100,
                'reasoning_types': 20
            },
            # é…ç½®4: å¹³è¡¡é…ç½®
            {
                'name': 'å¹³è¡¡é…ç½®',
                'hidden_size': 384,
                'reasoning_layers': 6,
                'attention_heads': 12,
                'memory_size': 30,
                'reasoning_types': 12
            },
            # é…ç½®5: é«˜æ•ˆé…ç½®
            {
                'name': 'é«˜æ•ˆé…ç½®',
                'hidden_size': 768,
                'reasoning_layers': 10,
                'attention_heads': 24,
                'memory_size': 60,
                'reasoning_types': 18
            }
        ]
        
        evaluator = EnhancedEvaluator()
        
        for i, config in enumerate(configs, 1):
            logger.log_important(f"ğŸ”§ æµ‹è¯•é…ç½® {i}: {config['name']}")
            
            # åˆ›å»ºæ¨¡å‹
            model = AdvancedReasoningNet(
                input_size=4,
                hidden_size=config['hidden_size'],
                reasoning_layers=config['reasoning_layers'],
                attention_heads=config['attention_heads'],
                memory_size=config['memory_size'],
                reasoning_types=config['reasoning_types']
            )
            
            # æµ‹è¯•æ¨ç†æ€§èƒ½
            start_time = time.time()
            result = await evaluator.evaluate_enhanced_reasoning(model, max_tasks=8)
            end_time = time.time()
            
            inference_time = (end_time - start_time) * 1000
            reasoning_score = result.get('comprehensive_reasoning', 0.0)
            
            # è®°å½•ç»“æœ
            config_result = {
                'config_name': config['name'],
                'reasoning_score': reasoning_score,
                'inference_time': inference_time,
                'config': config
            }
            
            self.optimization_history.append(config_result)
            
            logger.log_important(f"ğŸ“Š é…ç½® {i} ç»“æœ:")
            logger.log_important(f"   æ¨ç†åˆ†æ•°: {reasoning_score:.4f}")
            logger.log_important(f"   æ¨ç†æ—¶é—´: {inference_time:.2f} ms")
            
            # æ›´æ–°æœ€ä½³åˆ†æ•°
            if reasoning_score > self.best_score:
                self.best_score = reasoning_score
                logger.log_success(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨ç†åˆ†æ•°: {reasoning_score:.4f}")
            
            logger.log_important("")
        
        # åˆ†æç»“æœ
        self._analyze_optimization_results()
        
        # å°è¯•æ¨¡å‹è®­ç»ƒä¼˜åŒ–
        await self._try_training_optimization()
        
        return self.best_score
    
    def _analyze_optimization_results(self):
        """åˆ†æä¼˜åŒ–ç»“æœ"""
        logger.log_important("ğŸ“Š ä¼˜åŒ–ç»“æœåˆ†æ")
        logger.log_important("=" * 30)
        
        # æŒ‰æ¨ç†åˆ†æ•°æ’åº
        sorted_results = sorted(self.optimization_history, 
                               key=lambda x: x['reasoning_score'], reverse=True)
        
        logger.log_important("ğŸ† é…ç½®æ’å:")
        for i, result in enumerate(sorted_results, 1):
            logger.log_important(f"   {i}. {result['config_name']}: {result['reasoning_score']:.4f}")
        
        # æ‰¾åˆ°æœ€ä½³é…ç½®
        best_config = sorted_results[0]
        logger.log_important(f"\nğŸ¯ æœ€ä½³é…ç½®: {best_config['config_name']}")
        logger.log_important(f"   æ¨ç†åˆ†æ•°: {best_config['reasoning_score']:.4f}")
        logger.log_important(f"   æ¨ç†æ—¶é—´: {best_config['inference_time']:.2f} ms")
        
        # åˆ†æé…ç½®å‚æ•°å¯¹æ€§èƒ½çš„å½±å“
        self._analyze_parameter_impact()
    
    def _analyze_parameter_impact(self):
        """åˆ†æå‚æ•°å¯¹æ€§èƒ½çš„å½±å“"""
        logger.log_important("\nğŸ” å‚æ•°å½±å“åˆ†æ:")
        
        # åˆ†æéšè—å±‚å¤§å°çš„å½±å“
        hidden_sizes = [r['config']['hidden_size'] for r in self.optimization_history]
        scores = [r['reasoning_score'] for r in self.optimization_history]
        
        # è®¡ç®—ç›¸å…³æ€§
        correlation = np.corrcoef(hidden_sizes, scores)[0, 1]
        logger.log_important(f"   éšè—å±‚å¤§å°ä¸æ¨ç†åˆ†æ•°ç›¸å…³æ€§: {correlation:.3f}")
        
        # åˆ†ææ¨ç†å±‚æ•°çš„å½±å“
        reasoning_layers = [r['config']['reasoning_layers'] for r in self.optimization_history]
        correlation = np.corrcoef(reasoning_layers, scores)[0, 1]
        logger.log_important(f"   æ¨ç†å±‚æ•°ä¸æ¨ç†åˆ†æ•°ç›¸å…³æ€§: {correlation:.3f}")
        
        # åˆ†ææ³¨æ„åŠ›å¤´æ•°çš„å½±å“
        attention_heads = [r['config']['attention_heads'] for r in self.optimization_history]
        correlation = np.corrcoef(attention_heads, scores)[0, 1]
        logger.log_important(f"   æ³¨æ„åŠ›å¤´æ•°ä¸æ¨ç†åˆ†æ•°ç›¸å…³æ€§: {correlation:.3f}")
    
    async def _try_training_optimization(self):
        """å°è¯•è®­ç»ƒä¼˜åŒ–"""
        logger.log_important("\nğŸ“ å°è¯•è®­ç»ƒä¼˜åŒ–")
        logger.log_important("=" * 30)
        
        # é€‰æ‹©æœ€ä½³é…ç½®è¿›è¡Œè®­ç»ƒ
        best_config = max(self.optimization_history, key=lambda x: x['reasoning_score'])
        
        logger.log_important(f"ä½¿ç”¨æœ€ä½³é…ç½®è¿›è¡Œè®­ç»ƒ: {best_config['config_name']}")
        
        # åˆ›å»ºæ¨¡å‹
        model = AdvancedReasoningNet(
            input_size=4,
            hidden_size=best_config['config']['hidden_size'],
            reasoning_layers=best_config['config']['reasoning_layers'],
            attention_heads=best_config['config']['attention_heads'],
            memory_size=best_config['config']['memory_size'],
            reasoning_types=best_config['config']['reasoning_types']
        )
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        # åˆ›å»ºè¯„ä¼°å™¨
        evaluator = EnhancedEvaluator()
        
        # è®­ç»ƒå¾ªç¯
        training_epochs = 5
        logger.log_important(f"å¼€å§‹è®­ç»ƒ {training_epochs} ä¸ªepoch...")
        
        for epoch in range(training_epochs):
            # ç”Ÿæˆè®­ç»ƒæ•°æ®
            train_data = torch.randn(10, 4)
            target_data = torch.randn(10, 4)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            output = model(train_data)
            
            # è®¡ç®—æŸå¤±ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            if isinstance(output, dict):
                loss = nn.MSELoss()(output['comprehensive_reasoning'], target_data[:, 0])
            else:
                loss = nn.MSELoss()(output, target_data)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            # è¯„ä¼°å½“å‰æ€§èƒ½
            with torch.no_grad():
                result = await evaluator.evaluate_enhanced_reasoning(model, max_tasks=3)
                current_score = result.get('comprehensive_reasoning', 0.0)
            
            logger.log_important(f"Epoch {epoch+1}: æŸå¤±={loss.item():.4f}, æ¨ç†åˆ†æ•°={current_score:.4f}")
            
            # æ›´æ–°æœ€ä½³åˆ†æ•°
            if current_score > self.best_score:
                self.best_score = current_score
                logger.log_success(f"ğŸ‰ è®­ç»ƒåæ–°çš„æœ€ä½³æ¨ç†åˆ†æ•°: {current_score:.4f}")
        
        logger.log_important(f"\nâœ… è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆæœ€ä½³æ¨ç†åˆ†æ•°: {self.best_score:.4f}")
    
    async def _test_advanced_reasoning_tasks(self):
        """æµ‹è¯•é«˜çº§æ¨ç†ä»»åŠ¡"""
        logger.log_important("\nğŸ§© æµ‹è¯•é«˜çº§æ¨ç†ä»»åŠ¡")
        logger.log_important("=" * 30)
        
        # é€‰æ‹©æœ€ä½³é…ç½®
        best_config = max(self.optimization_history, key=lambda x: x['reasoning_score'])
        
        model = AdvancedReasoningNet(
            input_size=4,
            hidden_size=best_config['config']['hidden_size'],
            reasoning_layers=best_config['config']['reasoning_layers'],
            attention_heads=best_config['config']['attention_heads'],
            memory_size=best_config['config']['memory_size'],
            reasoning_types=best_config['config']['reasoning_types']
        )
        
        evaluator = EnhancedEvaluator()
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„æ¨ç†ä»»åŠ¡
        task_types = [
            'mathematical_logic',
            'symbolic_reasoning', 
            'abstract_reasoning',
            'pattern_recognition',
            'reasoning_chains',
            'mathematical_proofs',
            'logical_chains',
            'abstract_concepts',
            'creative_reasoning',
            'multi_step_reasoning',
            'nested_reasoning',
            'symbolic_induction',
            'graph_reasoning'
        ]
        
        task_scores = {}
        
        for task_type in task_types:
            try:
                # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„è¯„ä¼°å™¨æ¥å£è°ƒæ•´
                result = await evaluator.evaluate_enhanced_reasoning(model, max_tasks=2)
                score = result.get('comprehensive_reasoning', 0.0)
                task_scores[task_type] = score
                
                logger.log_important(f"   {task_type}: {score:.4f}")
            except Exception as e:
                logger.log_warning(f"   {task_type}: æµ‹è¯•å¤±è´¥ - {e}")
                task_scores[task_type] = 0.0
        
        # è®¡ç®—å¹³å‡åˆ†æ•°
        avg_score = np.mean(list(task_scores.values()))
        logger.log_important(f"\nğŸ“Š å¹³å‡æ¨ç†åˆ†æ•°: {avg_score:.4f}")
        
        return task_scores
    
    def generate_optimization_report(self):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        logger.log_important("\nğŸ“‹ æ¨ç†èƒ½åŠ›ä¼˜åŒ–æŠ¥å‘Š")
        logger.log_important("=" * 50)
        
        logger.log_important(f"ğŸ¯ ä¼˜åŒ–ç›®æ ‡: æ¨ç†åˆ†æ•° > 0.1")
        logger.log_important(f"ğŸ† æœ€ä½³æ¨ç†åˆ†æ•°: {self.best_score:.4f}")
        
        if self.best_score >= 0.1:
            logger.log_success("âœ… ç›®æ ‡è¾¾æˆï¼æ¨ç†åˆ†æ•°å·²è¶…è¿‡0.1")
        else:
            improvement_needed = 0.1 - self.best_score
            improvement_percentage = (improvement_needed / 0.1) * 100
            logger.log_warning(f"âš ï¸ ä»éœ€æ”¹è¿›: {improvement_needed:.4f} ({improvement_percentage:.1f}%)")
        
        # é…ç½®å¯¹æ¯”
        logger.log_important(f"\nğŸ“Š é…ç½®å¯¹æ¯”:")
        for result in self.optimization_history:
            status = "âœ…" if result['reasoning_score'] >= 0.1 else "âš ï¸"
            logger.log_important(f"   {status} {result['config_name']}: {result['reasoning_score']:.4f}")
        
        return {
            'best_score': self.best_score,
            'target_achieved': self.best_score >= 0.1,
            'optimization_history': self.optimization_history
        }

async def main():
    """ä¸»å‡½æ•°"""
    logger.log_important("=== æ¨ç†èƒ½åŠ›ä¼˜åŒ–æµ‹è¯• ===")
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = ReasoningOptimizer()
    
    # è¿è¡Œä¼˜åŒ–
    best_score = await optimizer.optimize_reasoning_models()
    
    # æµ‹è¯•é«˜çº§æ¨ç†ä»»åŠ¡
    await optimizer._test_advanced_reasoning_tasks()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = optimizer.generate_optimization_report()
    
    logger.log_important(f"\nğŸ‰ æ¨ç†èƒ½åŠ›ä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")
    logger.log_important(f"æœ€ç»ˆæœ€ä½³æ¨ç†åˆ†æ•°: {best_score:.4f}")

if __name__ == "__main__":
    asyncio.run(main()) 